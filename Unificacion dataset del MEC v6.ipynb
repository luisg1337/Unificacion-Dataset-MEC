{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6586356-9ad7-487f-ba29-c8960e737711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar un archivo CSV en un DataFrame\n",
    "df1 = pd.read_csv('registros_titulos.csv',low_memory=False)\n",
    "df2 = pd.read_csv('catastro_carreras_20241009.csv',low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f1771-14f9-4b20-a669-88822641eb6f",
   "metadata": {
    "panel-layout": {
     "height": 60.59375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Función para imprimir los shape de todos los df en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc7455-fb30-4d56-90e4-2eefb0709e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_df_shapes():\n",
    "    # Obtener todos los nombres de los DataFrames en memoria\n",
    "    df_names = [name for name in globals() if isinstance(globals()[name], pd.DataFrame)]\n",
    "\n",
    "    # Iterar sobre los nombres de los DataFrames y imprimir su shape\n",
    "    for name in df_names:\n",
    "        df = globals()[name]\n",
    "        print(f\"Shape del DataFrame {name}: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2db3e8-dc93-4d9e-bf7d-04d7e69c0224",
   "metadata": {
    "panel-layout": {
     "height": 60.59375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Función para imprimir los valores únicos de todos los df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1bca1-c0e3-4dff-b7f1-2baac8f79bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_unique_values():\n",
    "    # Obtener todos los nombres de los DataFrames en memoria\n",
    "    df_names = [name for name in globals() if isinstance(globals()[name], pd.DataFrame)]\n",
    "\n",
    "    # Iterar sobre los nombres de los DataFrames y imprimir los valores únicos de cada columna\n",
    "    for name in df_names:\n",
    "        df = globals()[name]\n",
    "        unique_counts = df.nunique()\n",
    "        print(f\"Valores únicos del DataFrame {name}:\")\n",
    "        print(unique_counts)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239fdcf2-8cd2-45c3-90ce-a6b28235b1ef",
   "metadata": {
    "panel-layout": {
     "height": 60.59375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Función de limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147163a-24b8-43a4-bbbd-904cc0d1c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63409166-00b9-4264-b089-9c39ca267659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import re\n",
    "\n",
    "# Función para limpiar y estandarizar los nombres\n",
    "def clean_and_standardize(name):\n",
    "    if isinstance(name, str):\n",
    "        # Eliminar espacios en blanco al inicio y al final\n",
    "        name = name.strip()\n",
    "        # Convertir a minúsculas\n",
    "        name = name.lower()\n",
    "        # Eliminar acentos\n",
    "        name = unidecode.unidecode(name)\n",
    "        # Eliminar comillas simples, dobles, guiones, barras, puntos, dos puntos, paréntesis y comas\n",
    "        \n",
    "        name = re.sub(r\"['\\\":(),.-]\", \"\", name)\n",
    "\n",
    "\n",
    "        # Eliminar dobles espacios en el medio de los nombres\n",
    "        name = re.sub(r'\\s+', ' ', name)\n",
    "    return name\n",
    "# Diccionario ampliado de abreviaturas comunes en el contexto educativo\n",
    "ABREVIATURAS = {\n",
    "    \"dr\": \"doctor\",\n",
    "    \"dra\": \"doctora\",\n",
    "    \"gral\": \"general\",\n",
    "    \"cnel\": \"coronel\",\n",
    "    \"tte\": \"teniente\",\n",
    "    \"tec\": \"tecnico\",\n",
    "    \"mcal\": \"mariscal\",\n",
    "    \"educ\": \"educacion\",\n",
    "    \"inst\": \"instituto\",\n",
    "    \"nac\": \"nacional\",\n",
    "    \"dir\": \"direccion\",\n",
    "    \"prof\": \"profesor\",\n",
    "    \"priv\": \"privado\",\n",
    "    \"reg\": \"regional\",\n",
    "    \"univ\": \"universidad\",\n",
    "    \"esc\": \"escuela\",\n",
    "    \"adm\": \"administracion\",\n",
    "    # Agrega más términos según las necesidades específicas del dataset\n",
    "}\n",
    "\n",
    "def expand_abbreviations(name):\n",
    "    # Reemplazo de abreviaturas por sus equivalentes completos\n",
    "    for abbr, full in ABREVIATURAS.items():\n",
    "        name = re.sub(rf\"\\b{abbr}\\b\", full, name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918ddf7-3925-431d-bc4d-a8d60c80fd90",
   "metadata": {
    "panel-layout": {
     "height": 60.59375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Aplicar limpieza a todos los campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f74da-115c-40f8-915c-0923794089ec",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"valores únicos antes de la limpieza\")\n",
    "print_unique_values()\n",
    "\n",
    "# Aplicar la función de limpieza a todos los valores de df1\n",
    "tqdm.pandas(desc=\"Limpiando df1\")\n",
    "df1 = df1.map(clean_and_standardize)\n",
    "\n",
    "# Expandir abreviaturas solo en columnas de tipo string\n",
    "tqdm.pandas(desc=\"expandiendo abreviaturas en df1\")\n",
    "df1[df1.select_dtypes(include=\"object\").columns] = df1.select_dtypes(include=\"object\").map(\n",
    "    lambda x: expand_abbreviations(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Aplicar la función de limpieza a todos los valores de df2\n",
    "tqdm.pandas(desc=\"Limpiando df2\")\n",
    "df2 = df2.map(clean_and_standardize)\n",
    "\n",
    "# Expandir abreviaturas solo en columnas de tipo string\n",
    "tqdm.pandas(desc=\"expandiendo abreviaturas en df2\")\n",
    "df2[df2.select_dtypes(include=\"object\").columns] = df2.select_dtypes(include=\"object\").map(\n",
    "    lambda x: expand_abbreviations(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "print(\"valores únicos después de la limpieza\")\n",
    "print_unique_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f20193-298b-438f-b24a-b7a708e7e603",
   "metadata": {},
   "source": [
    "# MAYUSCULAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edcc5a-f779-4bd4-8c12-4672c335db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir todos los textos a mayúsculas en df1 y df2\n",
    "df1 = df1.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "df2 = df2.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "\n",
    "# Ahora, revisa si se han convertido correctamente\n",
    "print(df1.head())\n",
    "print(df2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea1217-bd03-43e9-b06d-93f7fe6aa4db",
   "metadata": {
    "panel-layout": {
     "height": 60.59375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Trabajar con valores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18eef0-518e-4894-b26e-21e6874af422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener valores únicos y ordenados alfabéticamente de las columnas de instituciones en ambos DataFrames\n",
    "unique_institutions_df1 = pd.DataFrame(sorted(df1['institucion'].unique()), columns=['institucion'])\n",
    "unique_institutions_df2 = pd.DataFrame(sorted(df2['nombre_institucion'].unique()), columns=['nombre_institucion'])\n",
    "\n",
    "# Exportar a archivos Excel\n",
    "unique_institutions_df1.to_excel(\"unique_institutions_df1.xlsx\", index=False)\n",
    "unique_institutions_df2.to_excel(\"unique_institutions_df2.xlsx\", index=False)\n",
    "\n",
    "print(\"Archivos exportados: 'unique_institutions_df1.xlsx' y 'unique_institutions_df2.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e88be-6ffe-41de-9fa4-d36817fbb4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "\n",
    "# Configuración de coincidencia aproximada con umbral de similitud\n",
    "similarity_threshold = 90  # Nivel de similitud; puedes ajustar este valor según los resultados\n",
    "\n",
    "# Encontrar coincidencias aproximadas\n",
    "def find_fuzzy_matches(df1, df2, col1, col2, threshold):\n",
    "    matches = []\n",
    "    for name in df1[col1]:\n",
    "        match = process.extractOne(name, df2[col2], scorer=fuzz.ratio)\n",
    "        if match and match[1] >= threshold:\n",
    "            matches.append((name, match[0]))\n",
    "        else:\n",
    "            matches.append((name, \"#N/D\"))\n",
    "    return matches\n",
    "\n",
    "# DataFrames con coincidencias\n",
    "coincidencias_df1 = pd.DataFrame(find_fuzzy_matches(unique_institutions_df1, unique_institutions_df2, 'institucion', 'nombre_institucion', similarity_threshold), columns=['institucion', 'coincidencia_en_nombre'])\n",
    "coincidencias_df2 = pd.DataFrame(find_fuzzy_matches(unique_institutions_df2, unique_institutions_df1, 'nombre_institucion', 'institucion', similarity_threshold), columns=['nombre_institucion', 'coincidencia_en_institucion'])\n",
    "\n",
    "# Exportar resultados a Excel\n",
    "coincidencias_df1.to_excel('coincidencias_df1.xlsx', index=False)\n",
    "coincidencias_df2.to_excel('coincidencias_df2.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae3ba8-e7c0-42cc-a54c-2f8df7ba47f6",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "print_df_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365175fa-f6da-43e8-a19f-7adba1ed0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Umbral de similitud (ajústalo según los resultados que obtengas)\n",
    "similarity_threshold = 85  \n",
    "\n",
    "# Función para realizar coincidencias complejas con columna de nombre unificado\n",
    "def complex_fuzzy_matching(df1, df2, col1, col2, threshold):\n",
    "    matches = []\n",
    "    for name in tqdm(df1[col1], desc=\"Comparando instituciones...\"):\n",
    "        # Encuentra la coincidencia más cercana en el otro DataFrame usando `token_set_ratio` y `partial_ratio`\n",
    "        match = process.extractOne(name, df2[col2], scorer=fuzz.token_set_ratio)\n",
    "        \n",
    "        if match and match[1] >= threshold:\n",
    "            refined_score = fuzz.partial_ratio(name, match[0])\n",
    "            # Asegúrate de que ambas puntuaciones cumplan el umbral o alguna esté cerca\n",
    "            if refined_score >= threshold or (refined_score + match[1]) / 2 >= threshold:\n",
    "                unified_name = match[0]  # Aquí puedes decidir qué nombre usar como unificado\n",
    "                matches.append((name, match[0], unified_name))  # Añade la tercera columna con el nombre unificado\n",
    "            else:\n",
    "                matches.append((name, \"#N/D\", \"#N/D\"))  # No alcanzó el umbral refinado\n",
    "        else:\n",
    "            matches.append((name, \"#N/D\", \"#N/D\"))  # No alcanzó ningún umbral\n",
    "\n",
    "    return matches\n",
    "\n",
    "# Aplica la función y guarda los resultados en DataFrames\n",
    "coincidencias_df1 = pd.DataFrame(\n",
    "    complex_fuzzy_matching(unique_institutions_df1, unique_institutions_df2, 'institucion', 'nombre_institucion', similarity_threshold),\n",
    "    columns=['institucion', 'coincidencia_en_nombre', 'nombre_unificado']\n",
    ")\n",
    "\n",
    "coincidencias_df2 = pd.DataFrame(\n",
    "    complex_fuzzy_matching(unique_institutions_df2, unique_institutions_df1, 'nombre_institucion', 'institucion', similarity_threshold),\n",
    "    columns=['nombre_institucion', 'coincidencia_en_institucion', 'nombre_unificado']\n",
    ")\n",
    "\n",
    "# Exporta los resultados a Excel\n",
    "coincidencias_df1.to_excel('coincidencias_complejas_df1.xlsx', index=False)\n",
    "coincidencias_df2.to_excel('coincidencias_complejas_df2.xlsx', index=False)\n",
    "\n",
    "print(\"Archivos exportados: 'coincidencias_complejas_df1.xlsx' y 'coincidencias_complejas_df2.xlsx'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41743e76-c48a-4204-8e3d-28d0fe24d6d9",
   "metadata": {},
   "source": [
    "# Reemplazando en ambos dataset por nombre unificado de institucion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69458665-65e0-41f8-9d3c-13d74304db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Merge de los nombres unificados en df1\n",
    "df1 = df1.merge(coincidencias_df1[['institucion', 'nombre_unificado']], on='institucion', how='left')\n",
    "\n",
    "# Reemplaza los nombres en df1 por el nombre unificado, pero sólo si no es #N/D y no es NaN\n",
    "df1['institucion'] = df1.apply(lambda x: x['nombre_unificado'] if pd.notna(x['nombre_unificado']) and x['nombre_unificado'] != '#N/D' else x['institucion'], axis=1)\n",
    "\n",
    "# Elimina la columna 'nombre_unificado' de df1 si ya no es necesaria\n",
    "df1 = df1.drop(columns=['nombre_unificado'])\n",
    "\n",
    "# Merge de los nombres unificados en df2 (utilizando 'coincidencia_en_nombre' para buscar)\n",
    "df2 = df2.merge(coincidencias_df1[['coincidencia_en_nombre', 'nombre_unificado']], \n",
    "                left_on='nombre_institucion', right_on='coincidencia_en_nombre', how='left')\n",
    "\n",
    "# Reemplaza los nombres en df2 por el nombre unificado, pero sólo si no es #N/D y no es NaN\n",
    "df2['nombre_institucion'] = df2.apply(lambda x: x['nombre_unificado'] if pd.notna(x['nombre_unificado']) and x['nombre_unificado'] != '#N/D' else x['nombre_institucion'], axis=1)\n",
    "\n",
    "# Elimina las columnas innecesarias ('nombre_unificado' y 'coincidencia_en_nombre')\n",
    "df2 = df2.drop(columns=['nombre_unificado', 'coincidencia_en_nombre'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316b744-9309-41c3-b532-d47ae9fad547",
   "metadata": {},
   "source": [
    "# TIPO DE INSTITUCION LIMPIEZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e5ea6-bbe1-4bbb-8296-74789eecb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para corregir los tipos de institución según el nombre\n",
    "def corregir_tipo_institucion(nombre, tipo_actual):\n",
    "    # Asegurarse de que el nombre es una cadena de texto\n",
    "    if isinstance(nombre, str):\n",
    "        nombre = nombre.upper()\n",
    "    else:\n",
    "        nombre = \"\"  # Convertir NaN o valores no string en cadena vacía\n",
    "\n",
    "    # Caso especial: INSTITUTO DE FORMACION TECNICA SUPERIOR INFORTES\n",
    "    if 'INSTITUTO DE FORMACION TECNICA SUPERIOR INFORTES DEPENDIENTE DE LA UNIVERSIDAD EVANGELICA DEL PARAGUAY' in nombre:\n",
    "        return 'INSTITUTO TECNICO SUPERIOR'  # Devolver el tipo correcto\n",
    "        \n",
    "    if 'INSTITUTO PEDAGOGICO NIHON GAKKO' in nombre:\n",
    "        return 'INSTITUTO DE FORMACION DOCENTE'\n",
    "    # Lista de posibles tipos de institución en orden de prioridad\n",
    "    tipos_institucion = [\n",
    "        ('INSTITUTO TECNICO SUPERIOR', 'INSTITUTO TECNICO SUPERIOR'),\n",
    "        ('INSTITUTO SUPERIOR', 'INSTITUTO SUPERIOR'),\n",
    "        ('INSTITUTO DE FORMACION DOCENTE', 'INSTITUTO DE FORMACION DOCENTE'),\n",
    "        ('CENTRO REGIONAL DE EDUCACION', 'CENTRO REGIONAL DE EDUCACION'),\n",
    "        ('UNIVERSIDAD', 'UNIVERSIDAD')\n",
    "    ]\n",
    "\n",
    "    # Verificar la primera coincidencia en el nombre\n",
    "    for tipo, keyword in tipos_institucion:\n",
    "        if keyword in nombre:\n",
    "            return tipo  # Devolver el tipo de institución basado en la primera coincidencia\n",
    "\n",
    "    # Si no hay coincidencias, devolver el tipo actual\n",
    "    return tipo_actual\n",
    "\n",
    "# Aplicar la corrección en df1\n",
    "df1['tipo_institucion_corregido'] = df1.apply(lambda x: corregir_tipo_institucion(x['institucion'], x['tipo_institucion']), axis=1)\n",
    "\n",
    "# Aplicar la corrección en df2\n",
    "df2['tipo_institucion_corregido'] = df2.apply(lambda x: corregir_tipo_institucion(x['nombre_institucion'], x['tipo_institucion']), axis=1)\n",
    "\n",
    "# Reemplazar las columnas originales si todo es correcto\n",
    "df1['tipo_institucion'] = df1['tipo_institucion_corregido']\n",
    "df2['tipo_institucion'] = df2['tipo_institucion_corregido']\n",
    "\n",
    "# Eliminar las columnas temporales\n",
    "df1.drop(columns=['tipo_institucion_corregido'], inplace=True)\n",
    "df2.drop(columns=['tipo_institucion_corregido'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f19981-4d41-46ea-81ac-d51bbab00d98",
   "metadata": {},
   "source": [
    "# DUPLICADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4c5dd-c726-41d6-989a-83fe6105aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver el shape de df1 y df2 antes de eliminar duplicados\n",
    "print(\"Shape de df1 antes de eliminar duplicados:\", df1.shape)\n",
    "print(\"Shape de df2 antes de eliminar duplicados:\", df2.shape)\n",
    "\n",
    "# Eliminar duplicados en df1 y df2\n",
    "df1=df1.drop_duplicates()\n",
    "df2=df2.drop_duplicates()\n",
    "\n",
    "# Ver el shape de df1 y df2 después de eliminar duplicados\n",
    "print(\"Shape de df1 después de eliminar duplicados:\", df1.shape)\n",
    "print(\"Shape de df2 después de eliminar duplicados:\", df2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f71706-cd63-4565-9471-f2b3a500b864",
   "metadata": {},
   "source": [
    "# TITULOS DOCUMENTOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb72f9fd-ee8d-4646-af51-10100241e5eb",
   "metadata": {},
   "source": [
    "## Cantidad de documentos con más de un nombre asociado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65f553-05dd-42b0-8fb7-0a935f78cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "# Agrupar por 'documento' y contar la cantidad de nombres únicos asociados a cada documento después de la limpieza\n",
    "conteo_nombres_por_documento_despues = df.groupby('documento')['nombre_completo'].nunique()\n",
    "\n",
    "# Filtrar los documentos que tienen más de un nombre asociado después de la limpieza\n",
    "documentos_con_mas_de_un_nombre_despues = conteo_nombres_por_documento_despues[conteo_nombres_por_documento_despues > 1]\n",
    "\n",
    "# Mostrar la cantidad de documentos con más de un nombre asociado después de la limpieza\n",
    "cantidad_documentos_con_mas_de_un_nombre_despues = len(documentos_con_mas_de_un_nombre_despues)\n",
    "print(\"Cantidad de documentos con más de un nombre asociado después de la limpieza:\", cantidad_documentos_con_mas_de_un_nombre_despues)\n",
    "\n",
    "# Mostrar la lista de documentos con más de un nombre asociado después de la limpieza y la cantidad de nombres diferentes para cada uno\n",
    "print(\"\\nDocumentos con más de un nombre asociado después de la limpieza y cantidad de nombres diferentes:\")\n",
    "print(documentos_con_mas_de_un_nombre_despues)\n",
    "\n",
    "# Obtener los nombres asociados a cada documento con más de un nombre después de la limpieza\n",
    "nombres_por_documento_despues = df[df['documento'].isin(documentos_con_mas_de_un_nombre_despues.index)][['documento', 'nombre_completo']]\n",
    "\n",
    "# Exportar la lista de documentos con más de un nombre asociado después de la limpieza y los nombres asociados a un archivo Excel\n",
    "nombres_por_documento_despues.to_excel(\"nombres_por_documento_despues.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa722e1-ae57-4496-83a2-3968aa81cbc7",
   "metadata": {},
   "source": [
    "## Listar nombres de documentos con mas de un nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a452243-e10b-435b-abd8-8cf23979faa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los nombres únicos asociados a cada documento con más de un nombre después de la limpieza y ordenar por documento\n",
    "nombres_unicos_por_documento_despues = nombres_por_documento_despues.drop_duplicates().sort_values(by='documento')\n",
    "\n",
    "# Mostrar los nombres únicos asociados a cada documento con más de un nombre después de la limpieza\n",
    "print(\"Nombres únicos asociados a cada documento con más de un nombre después de la limpieza:\")\n",
    "print(nombres_unicos_por_documento_despues)\n",
    "\n",
    "# Exportar los nombres únicos asociados a cada documento con más de un nombre a un archivo Excel, ordenado por documento\n",
    "nombres_unicos_por_documento_despues.to_excel(\"nombres_unicos_por_documento_despues.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0c1c66-6ae9-4bc9-80d3-e5a4e3e29592",
   "metadata": {},
   "source": [
    "## Detectar similitudes entre los nombres con el mismo documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919178d-0ed3-4791-985a-9e00bf215d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "\n",
    "# Cargar el dataframe\n",
    "dfx = nombres_unicos_por_documento_despues\n",
    "\n",
    "\n",
    "# Función para calcular la similitud de Levenshtein\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# Función para clasificar nombres\n",
    "def classify_names(group):\n",
    "    results = []\n",
    "    names = group['nombre_completo'].tolist()\n",
    "    for i in range(len(names)):\n",
    "        for j in range(i + 1, len(names)):\n",
    "            similarity = similar(names[i], names[j])\n",
    "            if similarity > 0.8:  # Umbral de similitud\n",
    "                results.append((group['documento'].iloc[0], names[i], names[j], 'misma persona'))\n",
    "            else:\n",
    "                results.append((group['documento'].iloc[0], names[i], names[j], 'distintas personas'))\n",
    "    return results\n",
    "\n",
    "# Aplicar la función a grupos de documentos\n",
    "results = []\n",
    "grouped = dfx.groupby('documento')\n",
    "for name, group in grouped:\n",
    "    if len(group) > 1:\n",
    "        results.extend(classify_names(group))\n",
    "\n",
    "# Convertir los resultados en un DataFrame\n",
    "result_df = pd.DataFrame(results, columns=['documento', 'nombre1', 'nombre2', 'clasificacion'])\n",
    "\n",
    "# Guardar los resultados en un archivo Excel\n",
    "result_df.to_excel('nombres_clasificados.xlsx', index=False)\n",
    "\n",
    "# Imprimir la cantidad de clasificaciones por tipo\n",
    "print(result_df['clasificacion'].value_counts())\n",
    "\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd795f-6a22-4f7f-90c0-95957209ebd1",
   "metadata": {},
   "source": [
    "## Unificar datos para tener una lista de personas iguales o distintos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd91313d-086f-4939-8727-ddaf42c3696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que los dataframes ya están cargados como nombres_unicos_por_documento_despues y result_df\n",
    "\n",
    "# Crear una lista para almacenar los diccionarios\n",
    "aux_list = []\n",
    "\n",
    "for index, row in result_df.iterrows():\n",
    "    aux_list.append({'documento': row['documento'], 'nombre_completo': row['nombre1'], 'clasificacion': row['clasificacion']})\n",
    "    aux_list.append({'documento': row['documento'], 'nombre_completo': row['nombre2'], 'clasificacion': row['clasificacion']})\n",
    "\n",
    "# Convertir la lista en un dataframe\n",
    "aux_df = pd.DataFrame(aux_list)\n",
    "\n",
    "# Eliminar duplicados\n",
    "aux_df = aux_df.drop_duplicates()\n",
    "\n",
    "# Unir nombres_unicos_por_documento_despues con aux_df para agregar la columna de clasificación\n",
    "merged_df = nombres_unicos_por_documento_despues.merge(aux_df, how='left', left_on=['documento', 'nombre_completo'], right_on=['documento', 'nombre_completo'])\n",
    "\n",
    "# Verificar el resultado\n",
    "print(merged_df)\n",
    "\n",
    "# Guardar el resultado en un archivo de Excel\n",
    "merged_df.to_excel('nombres_unicos_con_clasificacion.xlsx', index=False)\n",
    "print(\"Archivo exportado a 'nombres_unicos_con_clasificacion.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329c8f7f-8a2e-4100-8011-fc951e8ba731",
   "metadata": {},
   "source": [
    "## Crear id para documentos con mas de un nombre asociado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68879e57-502e-4c83-b8c9-e60deecf5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Diccionario para contar ocurrencias por documento\n",
    "counter = {}\n",
    "\n",
    "# Función para generar el ID según la clasificación\n",
    "def generar_id(row):\n",
    "    documento = row['documento']\n",
    "    clasificacion = row['clasificacion']\n",
    "\n",
    "    if clasificacion == 'distintas personas':\n",
    "        if documento not in counter:\n",
    "            counter[documento] = 1\n",
    "        else:\n",
    "            counter[documento] += 1\n",
    "        return f\"{documento}_{counter[documento]}\"\n",
    "    else:\n",
    "        return documento\n",
    "\n",
    "# Aplicar la función para generar la columna 'id'\n",
    "merged_df['id'] = merged_df.apply(generar_id, axis=1)\n",
    "\n",
    "# Mostrar el dataframe resultante\n",
    "print(merged_df)\n",
    "merged_df.to_excel('documentos_duplicados_con_id.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6327e2f-cb6b-4ce9-9c2b-c4a7f73c8e94",
   "metadata": {},
   "source": [
    "## Agregar el nuevo campo persona_id a todo el dataset, ordenar y exportar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900ecd5-31aa-42ea-bdd4-b7920aba1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configurar tqdm para que funcione con pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Crear un backup del DataFrame original\n",
    "df_backup = df1.copy()\n",
    "\n",
    "# Hacer un merge entre df y merged_df basado en 'documento' y 'nombre_completo'\n",
    "df_titulos_v2 = pd.merge(df1, merged_df[['documento', 'nombre_completo', 'id']].progress_apply(lambda x: x), on=['documento', 'nombre_completo'], how='left')\n",
    "\n",
    "# Crear la columna 'persona_id' basada en las condiciones especificadas\n",
    "df_titulos_v2['persona_id'] = df_titulos_v2['id'].combine_first(df_titulos_v2['documento'])\n",
    "\n",
    "# Eliminar la columna 'id' ya que no la necesitamos en el DataFrame final\n",
    "df_titulos_v2 = df_titulos_v2.drop(columns=['id'])\n",
    "\n",
    "# Ordenar el DataFrame por 'documento' y 'persona_id'\n",
    "df_titulos_v2 = df_titulos_v2.sort_values(by=['documento', 'persona_id'])\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_titulos_v2.shape)\n",
    "\n",
    "# Exportar todo el DataFrame a un solo archivo CSV\n",
    "df_titulos_v2.to_csv('df_titulos_v2.csv', index=False)\n",
    "\n",
    "print('df exportado a CSV en un solo archivo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16541156-2a7d-4da1-a8a2-3b90a1f08762",
   "metadata": {},
   "source": [
    "# Fragmentando dataset para facilitar trabajar sobre secciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf0897-955d-4daa-aee8-a7c7c4828f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Función para limpiar las variantes de ciclos y espacios dobles\n",
    "def limpiar_ciclos(texto):\n",
    "    if isinstance(texto, str):  # Asegurarse de que el texto sea una cadena\n",
    "        # Reemplazar variantes de \"TERCER CICLO\"\n",
    "        texto = re.sub(r'\\b(3(O|0)?|TERCERO|TERCER|3(DEG)?|30)\\s*CICLO(S)?\\b', 'TERCER CICLO', texto, flags=re.IGNORECASE)\n",
    "\n",
    "        # Reemplazar variantes de \"SEGUNDO CICLO\"\n",
    "        texto = re.sub(r'\\b(2(O|0)?|SEGUNDO|2(DEG)?|20)\\s*CICLO(S)?\\b', 'SEGUNDO CICLO', texto, flags=re.IGNORECASE)\n",
    "\n",
    "        # Reemplazar variantes de \"PRIMER CICLO\"\n",
    "        texto = re.sub(r'\\b(1(O|0)?|PRIMERO|PRIMER|1(DEG)?|10)\\s*CICLO(S)?\\b', 'PRIMER CICLO', texto, flags=re.IGNORECASE)\n",
    "\n",
    "        # Eliminar espacios dobles\n",
    "        texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "\n",
    "    return texto\n",
    "    \n",
    "# Filtrar las columnas necesarias de df1 y df2\n",
    "titulos = df_titulos_v2[['anio', 'mes', 'documento', 'persona_id', 'nombre_completo', 'tipo_institucion', 'institucion', 'carrera', 'titulo', 'sexo']]\n",
    "carreras = df2[['tipo_institucion', 'nombre_institucion', 'denominacion_carrera', 'denominacion_titulo', 'tipo_gestion', 'nivel_titulacion', 'clasificacion_campo_amplio']]\n",
    "\n",
    "carreras.rename(columns={\n",
    "    'nombre_institucion': 'institucion',\n",
    "    'denominacion_carrera': 'carrera',\n",
    "    'denominacion_titulo': 'titulo'\n",
    "}, inplace=True)\n",
    "\n",
    "# Aplicar la función de limpieza a las columnas 'carrera' y 'titulo' en ambos DataFrames\n",
    "titulos.loc[:, 'carrera'] = titulos['carrera'].apply(limpiar_ciclos)\n",
    "titulos.loc[:, 'titulo'] = titulos['titulo'].apply(limpiar_ciclos)\n",
    "carreras.loc[:, 'carrera'] = carreras['carrera'].apply(limpiar_ciclos)\n",
    "carreras.loc[:, 'titulo'] = carreras['titulo'].apply(limpiar_ciclos)\n",
    "# Diccionario para los tipos de institución y sus siglas\n",
    "tipo_institucion_siglas = {\n",
    "    'CENTRO REGIONAL DE EDUCACION': 'CRE',\n",
    "    'INSTITUTO DE FORMACION DOCENTE': 'IFD',\n",
    "    'INSTITUTO SUPERIOR': 'IS',\n",
    "    'INSTITUTO TECNICO SUPERIOR': 'ITS',\n",
    "    'UNIVERSIDAD': 'U'\n",
    "}\n",
    "\n",
    "# Dividir titulos en fragmentos según el tipo de institución\n",
    "for tipo, sigla in tipo_institucion_siglas.items():\n",
    "    fragmento = titulos[titulos['tipo_institucion'] == tipo]\n",
    "    fragmento.to_excel(f'titulos_{sigla}.xlsx', index=False)\n",
    "\n",
    "# Dividir carreras en fragmentos según el tipo de institución\n",
    "for tipo, sigla in tipo_institucion_siglas.items():\n",
    "    fragmento = carreras[carreras['tipo_institucion'] == tipo]\n",
    "    fragmento.to_excel(f'carreras_{sigla}.xlsx', index=False)\n",
    "\n",
    "print(\"Archivos exportados según tipo de institución.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a185d8-ba42-4bec-9ea0-b60ff7349b1d",
   "metadata": {},
   "source": [
    "# CARGAR DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0747d4-f39f-4eb6-8c55-ff93f1668e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los archivos Excel que contienen los DataFrames por tipo de institución\n",
    "titulos_cre = pd.read_excel('titulos_CRE.xlsx')\n",
    "titulos_ifd = pd.read_excel('titulos_IFD.xlsx')\n",
    "titulos_is = pd.read_excel('titulos_IS.xlsx')\n",
    "titulos_its = pd.read_excel('titulos_ITS.xlsx')\n",
    "titulos_u = pd.read_excel('titulos_U.xlsx')\n",
    "\n",
    "carreras_cre = pd.read_excel('carreras_CRE.xlsx')\n",
    "carreras_ifd = pd.read_excel('carreras_IFD.xlsx')\n",
    "carreras_is = pd.read_excel('carreras_IS.xlsx')\n",
    "carreras_its = pd.read_excel('carreras_ITS.xlsx')\n",
    "carreras_u = pd.read_excel('carreras_U.xlsx')\n",
    "\n",
    "# Verificar la carga de los DataFrames\n",
    "print(\"Títulos CRE shape:\", titulos_cre.shape)\n",
    "print(\"Títulos IFD shape:\", titulos_ifd.shape)\n",
    "print(\"Títulos IS shape:\", titulos_is.shape)\n",
    "print(\"Títulos ITS shape:\", titulos_its.shape)\n",
    "print(\"Títulos U shape:\", titulos_u.shape)\n",
    "\n",
    "print(\"Carreras CRE shape:\", carreras_cre.shape)\n",
    "print(\"Carreras IFD shape:\", carreras_ifd.shape)\n",
    "print(\"Carreras IS shape:\", carreras_is.shape)\n",
    "print(\"Carreras ITS shape:\", carreras_its.shape)\n",
    "print(\"Carreras U shape:\", carreras_u.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a41b2-ff07-4c42-b279-f1a554d8c190",
   "metadata": {},
   "source": [
    "# CENTRO REGIONAL DE EDUCACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac66f3f9-fae1-4e0b-bfb8-5ee44cf6f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correcciones realizadas en titulos_cre:\")\n",
    "print(titulos_cre['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n",
    "print(\"\\nCorrecciones realizadas en carreras_cre:\")\n",
    "print(carreras_cre['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415ac25-b959-48bb-9798-ad72fa6fd80a",
   "metadata": {},
   "source": [
    "# instituciones que solo estan en un lugar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e71efa7-563d-4b1f-b626-d55f6443c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores únicos en 'titulos_cre'\n",
    "instituciones_titulos = set(titulos_cre['institucion'].unique())\n",
    "\n",
    "# Valores únicos en 'carreras_cre'\n",
    "instituciones_carreras = set(carreras_cre['institucion'].unique())\n",
    "\n",
    "# Instituciones que están en 'titulos_cre' pero no en 'carreras_cre'\n",
    "solo_en_titulos = instituciones_titulos - instituciones_carreras\n",
    "print(\"Instituciones que están solo en titulos_cre:\")\n",
    "print(solo_en_titulos)\n",
    "\n",
    "# Instituciones que están en 'carreras_cre' pero no en 'titulos_cre'\n",
    "solo_en_carreras = instituciones_carreras - instituciones_titulos\n",
    "print(\"\\nInstituciones que están solo en carreras_cre:\")\n",
    "print(solo_en_carreras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2975929-d2a3-4eae-8a68-f0d1d528f1fa",
   "metadata": {},
   "source": [
    "# limpieza de inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdd49e7-c472-418a-9156-0b49a91af7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Función para limpiar nombres específicos\n",
    "def limpiar_instituciones(nombre, es_carreras=False):\n",
    "    nombre = nombre.upper()\n",
    "    \n",
    "    # Correcciones generales para ambos datasets\n",
    "    if \"DRRAUL PENA\" in nombre:\n",
    "        nombre = nombre.replace(\"DRRAUL PENA\", \"DOCTOR RAUL PENA\")\n",
    "    \n",
    "    # Correcciones específicas para carreras_cre\n",
    "    if es_carreras:\n",
    "        if \"GENERAL PATRICIO ESCOBAR DE ENCARNACION\" in nombre:\n",
    "            nombre = nombre.replace(\"GENERAL PATRICIO ESCOBAR DE ENCARNACION\", \"GENERAL PATRICIO ESCOBAR\")\n",
    "        if \"DOCTOR RAUL PENA DE PEDRO JUAN CABALLERO\" in nombre:\n",
    "            nombre = nombre.replace(\"DOCTOR RAUL PENA DE PEDRO JUAN CABALLERO\", \"DOCTOR RAUL PENA\")\n",
    "    \n",
    "    return nombre\n",
    "\n",
    "# Aplicar la limpieza en ambos datasets\n",
    "titulos_cre['institucion'] = titulos_cre['institucion'].apply(limpiar_instituciones)\n",
    "carreras_cre['institucion'] = carreras_cre['institucion'].apply(lambda x: limpiar_instituciones(x, es_carreras=True))\n",
    "# Limpiar el nombre de la carrera reemplazando solo la parte específica\n",
    "carreras_cre['carrera'] = carreras_cre['carrera'].replace(\n",
    "    'PROFESIONALIZADONANEMOARANDUKE',\n",
    "    'PROFESIONALIZADO',\n",
    "    regex=True  # Esto permite la búsqueda con expresiones regulares\n",
    ")\n",
    "# Limpiar el nombre de la carrera reemplazando solo la parte específica\n",
    "titulos_cre['carrera'] = titulos_cre['carrera'].replace(\n",
    "    'PROFESIONALIZADONANEMOARANDUKE',\n",
    "    'PROFESIONALIZADO',\n",
    "    regex=True  # Esto permite la búsqueda con expresiones regulares\n",
    ")\n",
    "# Mostrar las instituciones corregidas\n",
    "print(\"Instituciones corregidas en titulos_cre:\")\n",
    "print(titulos_cre['institucion'].unique())\n",
    "\n",
    "print(\"\\nInstituciones corregidas en carreras_cre:\")\n",
    "print(carreras_cre['institucion'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0659b8a9-8129-4bf9-aea8-b326460953b4",
   "metadata": {},
   "source": [
    "# verificar valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639b760-71ff-4285-8e0a-3d2cd04c8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar valores nulos en cada columna de titulos_cre\n",
    "print(\"Valores nulos en titulos_cre:\")\n",
    "print(titulos_cre.isnull().sum())\n",
    "\n",
    "# Contar valores nulos en cada columna de carreras_cre\n",
    "print(\"\\nValores nulos en carreras_cre:\")\n",
    "print(carreras_cre.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44b9d9-5599-4b8e-91fc-3fa17a1a2e9d",
   "metadata": {},
   "source": [
    "# campos vacios en carreras cre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340dcc2-98b9-4341-b711-6523aa75c3be",
   "metadata": {},
   "source": [
    "# clasificacion de campo amplio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c11b6dc-df19-43a7-a3cb-06667dc2a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar los valores vacíos (NaN) en cada columna\n",
    "valores_vacios = carreras_cre.isna().sum()\n",
    "\n",
    "# Mostrar el total de valores vacíos por columna antes de completar\n",
    "print(\"Total de valores vacíos por columna antes de completar:\")\n",
    "print(valores_vacios)\n",
    "\n",
    "# Llenar los campos vacíos en clasificacion_campo_amplio con 'EDUCACION'\n",
    "carreras_cre['clasificacion_campo_amplio'] = carreras_cre['clasificacion_campo_amplio'].fillna('EDUCACION')\n",
    "\n",
    "# Volver a contar los valores vacíos después de la operación\n",
    "valores_vacios_actualizados = carreras_cre.isna().sum()\n",
    "\n",
    "# Mostrar el total de valores vacíos por columna después de completar\n",
    "print(\"\\nTotal de valores vacíos por columna después de completar:\")\n",
    "print(valores_vacios_actualizados)\n",
    "\n",
    "# Exportar el dataframe resultante a un archivo Excel\n",
    "carreras_cre.to_excel('carreras_cre_actualizado.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72637656-8b76-4261-a3eb-7b75625f3b46",
   "metadata": {},
   "source": [
    "# tipo de gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4386e3e4-362f-428d-b295-1260b16d97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar el tipo de gestión más frecuente para cada institución\n",
    "def completar_tipo_gestion(grupo):\n",
    "    if grupo['tipo_gestion'].isnull().all():\n",
    "        return grupo\n",
    "    # Obtener el tipo de gestión más frecuente (eliminando los nulos) \n",
    "    tipo_frecuente = grupo['tipo_gestion'].dropna().mode()[0]\n",
    "    # Rellenar los valores nulos con el tipo de gestión más frecuente\n",
    "    grupo['tipo_gestion'] = grupo['tipo_gestion'].fillna(tipo_frecuente)\n",
    "    return grupo\n",
    "\n",
    "# Aplicar la función a cada grupo de instituciones sin convertirlo en índice\n",
    "carreras_cre = carreras_cre.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n",
    "\n",
    "# Guardar el resultado en un archivo Excel\n",
    "carreras_cre.to_excel('carreras_cre_actualizado.xlsx', index=False)\n",
    "\n",
    "# Verificar si aún hay valores nulos en la columna 'tipo_gestion'\n",
    "print(carreras_cre['tipo_gestion'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59614006-3e0b-4ba8-ab8d-49dfa56fc094",
   "metadata": {},
   "source": [
    "# unificacion carreras y titulos cre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d81ca-80d4-4211-8d2d-40ca7228472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_cre_copy = titulos_cre.copy()\n",
    "carreras_cre_copy = carreras_cre.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_cre_copy = titulos_cre_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_cre_copy = carreras_cre_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_cre_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_cre_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_CRE.xlsx', index=False)\n",
    "carreras_cre_copy = carreras_cre_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_cre_copy = carreras_cre_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943840c8-27a9-4bc6-91e9-ce2a07e85bd6",
   "metadata": {},
   "source": [
    "## LIMPIANDO INCONSISTENCIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a07a88-8c3c-42d9-b15a-482b9ebf83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "# Función para extraer la parte posterior a 'AREA'\n",
    "def extract_after_area(text):\n",
    "  \n",
    "    if 'AREA' in text:\n",
    "        return text.split('AREA', 1)[-1].strip()  # Extraer lo que sigue después de 'AREA'\n",
    "    return None  # Si no tiene 'AREA', devolver None\n",
    "\n",
    "# Función de coincidencia difusa optimizada\n",
    "def fuzzy_unify(row, carreras_cre, threshold=75):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    carreras_cre_filtered = carreras_cre[\n",
    "        (carreras_cre['institucion_carrera'] == row['institucion']) &\n",
    "        (carreras_cre['tipo_institucion'] == row['tipo_institucion'])\n",
    "    ]\n",
    "\n",
    "    row['carrera_carreras'] = None\n",
    "    row['titulo_carrera'] = None\n",
    "    row['institucion_carrera'] = None\n",
    "\n",
    "    for _, carrera_row in carreras_cre_filtered.iterrows():\n",
    "        # Extraer partes después de 'AREA'\n",
    "        area_row_1 = extract_after_area(row['carrera'])\n",
    "        area_row_2 = extract_after_area(carrera_row['carrera_carreras'])\n",
    "\n",
    "        if area_row_1 and area_row_2:  # Ambas tienen 'AREA'\n",
    "            area_score = fuzz.ratio(area_row_1, area_row_2)\n",
    "            if area_score < 70:  # Si la parte después de 'AREA' no es similar\n",
    "                avg_score = 60  # Asignar un puntaje bajo\n",
    "            else:\n",
    "                carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "                titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "                avg_score = (carrera_score + titulo_score) / 2\n",
    "        elif area_row_1 or area_row_2:  # Solo una de las partes tiene 'AREA'\n",
    "            avg_score = 60  # Puntaje bajo\n",
    "        else:\n",
    "            carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "            titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "            avg_score = (carrera_score + titulo_score) / 2\n",
    "\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_match = carrera_row\n",
    "\n",
    "    if best_score >= threshold and best_match is not None:\n",
    "        row['carrera_unificada'] = best_match['carrera_carreras']\n",
    "        row['titulo_unificado'] = best_match['titulo_carrera']\n",
    "        row['institucion_unificada'] = best_match['institucion_carrera']\n",
    "        row['carrera_carreras'] = best_match['carrera_carreras']\n",
    "        row['titulo_carrera'] = best_match['titulo_carrera']\n",
    "        row['institucion_carrera'] = best_match['institucion_carrera']\n",
    "    else:\n",
    "        row['carrera_unificada'] = row['carrera']\n",
    "        row['titulo_unificado'] = row['titulo_titulos']\n",
    "        row['institucion_unificada'] = row['institucion']\n",
    "\n",
    "    row['similarity_score'] = best_score\n",
    "    return row\n",
    "\n",
    "# Aplicar la coincidencia difusa\n",
    "left_only_unified = left_only.apply(fuzzy_unify, args=(carreras_cre_copy,), axis=1)\n",
    "left_only_unified = left_only_unified[[\n",
    "    'carrera',\n",
    "    'carrera_carreras',\n",
    "    'carrera_unificada', \n",
    "    'titulo_titulos', # Cambiado de posición\n",
    "    'titulo_carrera',\n",
    "    'titulo_unificado',\n",
    "    'institucion', \n",
    "    'institucion_carrera',\n",
    "    'institucion_unificada',\n",
    "    'similarity_score'\n",
    "]]\n",
    "# Exportar a un archivo Excel\n",
    "left_only_unified.to_excel('unificacion_left_only_cre.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'unificacion_left_only_cre.xlsx'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf3b7a9-a7cb-44ad-b2f6-000edaafdef7",
   "metadata": {},
   "source": [
    "# Reemplazando campos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ce61e-9f86-4b02-a7b5-75601fda6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Filtrar las filas de left_only_unified con un puntaje mayor o igual a 90\n",
    "left_only_unified_filtered = left_only_unified[left_only_unified['similarity_score'] >= 90]\n",
    "\n",
    "# Paso 2: Reemplazar los valores en titulos_cre\n",
    "for _, row in left_only_unified_filtered.iterrows():\n",
    "    # Buscar coincidencias en titulos_cre\n",
    "    condition = (\n",
    "        (titulos_cre['carrera'] == row['carrera']) &\n",
    "        (titulos_cre['titulo'] == row['titulo_titulos']) &\n",
    "        (titulos_cre['institucion'] == row['institucion'])\n",
    "    )\n",
    "    \n",
    "    # Reemplazar los valores en titulos_cre si hay coincidencias\n",
    "    titulos_cre.loc[condition, 'carrera'] = row['carrera_unificada']\n",
    "    titulos_cre.loc[condition, 'titulo'] = row['titulo_unificado']\n",
    "\n",
    "# Puedes guardar el DataFrame actualizado en un archivo Excel o CSV si lo deseas\n",
    "titulos_cre.to_excel('titulos_cre_actualizado.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'titulos_cre_actualizado.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c85bf0-c164-403a-b36f-254e543d0864",
   "metadata": {},
   "source": [
    "# Segunda revision #OPCIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e3c6b-d8f6-490c-a56d-1e39437c68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_cre_copy = titulos_cre.copy()\n",
    "carreras_cre_copy = carreras_cre.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_cre_copy = titulos_cre_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_cre_copy = carreras_cre_copy.rename(columns={'titulo': 'titulo_carreras'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_cre_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_cre_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carreras']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carreras'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_CRE.xlsx', index=False)\n",
    "\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f03541-1140-4628-9c84-644d088a3a0f",
   "metadata": {},
   "source": [
    "## UNIFICACION FINAL CRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554fb5e1-dd47-48bf-8675-20bce4de9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Eliminar duplicados en las columnas clave de carreras\n",
    "df_merged_unique = carreras_cre.drop_duplicates(\n",
    "    subset=['carrera', 'institucion', 'tipo_institucion', 'titulo']\n",
    ")\n",
    "\n",
    "# Paso 2: Realizar el merge con las combinaciones únicas\n",
    "merged_final_CRE = pd.merge(\n",
    "    titulos_cre, \n",
    "    df_merged_unique, \n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    how='left'  # Aquí cambiamos a 'left' para mantener todas las filas de df_titulos_v2_limpio_CRE\n",
    ")\n",
    "\n",
    "# Paso 2: Guardar el DataFrame en un archivo Excel\n",
    "merged_final_CRE.to_excel('CRE_FINAL.xlsx', index=False)\n",
    "# Imprimir la forma y los encabezados de df_titulos_v2_limpio_CRE\n",
    "print(\"Shape del DataFrame TITULOS V2:\", titulos_cre.shape)\n",
    "\n",
    "\n",
    "# Imprimir la forma y los encabezados del DataFrame final\n",
    "print(\"Shape del DataFrame final:\", merged_final_CRE.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d1b7c4-6254-4550-9ea0-6c72f632383d",
   "metadata": {},
   "source": [
    "# INSTITUTO DE FORMACION DOCENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f8282f-7ec4-4027-9eb1-374e99257a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correcciones realizadas en titulos_ifd:\")\n",
    "print(titulos_ifd['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n",
    "print(\"\\nCorrecciones realizadas en carreras_ifd:\")\n",
    "print(carreras_ifd['institucion'].unique())  # Imprime los valores únicos para ver las correcciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fe9c5d-2a6b-4c85-8126-6f4ff242c1dc",
   "metadata": {},
   "source": [
    "# INSTITUCIONES QUE SOLO ESTAN EN UN LUGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daee299-d18d-42b1-b369-beacb2120902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores únicos en 'titulos_cre'\n",
    "instituciones_titulos = set(titulos_ifd['institucion'].unique())\n",
    "\n",
    "# Valores únicos en 'carreras_cre'\n",
    "instituciones_carreras = set(carreras_ifd['institucion'].unique())\n",
    "\n",
    "# Instituciones que están en 'titulos_cre' pero no en 'carreras_cre'\n",
    "solo_en_titulos = instituciones_titulos - instituciones_carreras\n",
    "print(\"Instituciones que están solo en titulos_ifd:\")\n",
    "print(solo_en_titulos)\n",
    "\n",
    "# Instituciones que están en 'carreras_cre' pero no en 'titulos_cre'\n",
    "solo_en_carreras = instituciones_carreras - instituciones_titulos\n",
    "print(\"\\nInstituciones que están solo en carreras_ifd:\")\n",
    "print(solo_en_carreras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f2369d-977d-4e30-91fa-33d6a6e86e27",
   "metadata": {},
   "source": [
    "## VERIFICANDO CAMPOS VACIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99940236-73b0-4bab-9632-98580f498f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar valores nulos en cada columna de titulos_cre\n",
    "print(\"Valores nulos en titulos_ifd:\")\n",
    "print(titulos_ifd.isnull().sum())\n",
    "\n",
    "# Contar valores nulos en cada columna de carreras_cre\n",
    "print(\"\\nValores nulos en carreras_ifd:\")\n",
    "print(carreras_ifd.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37310e26-cb55-4ba9-bc27-888558a8ac12",
   "metadata": {},
   "source": [
    "## campos vacios en ifd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb46c5-f875-4192-ac2b-6565a9dba7aa",
   "metadata": {},
   "source": [
    "### campo amplio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb67311-b7f8-4f2a-9b5c-2bed3b8b368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar los valores vacíos (NaN) en cada columna\n",
    "valores_vacios = carreras_ifd.isna().sum()\n",
    "\n",
    "# Mostrar el total de valores vacíos por columna antes de completar\n",
    "print(\"Total de valores vacíos por columna antes de completar:\")\n",
    "print(valores_vacios)\n",
    "\n",
    "# Llenar los campos vacíos en clasificacion_campo_amplio con 'EDUCACION'\n",
    "carreras_ifd['clasificacion_campo_amplio'] = carreras_ifd['clasificacion_campo_amplio'].fillna('EDUCACION')\n",
    "\n",
    "# Volver a contar los valores vacíos después de la operación\n",
    "valores_vacios_actualizados = carreras_ifd.isna().sum()\n",
    "\n",
    "# Mostrar el total de valores vacíos por columna después de completar\n",
    "print(\"\\nTotal de valores vacíos por columna después de completar:\")\n",
    "print(valores_vacios_actualizados)\n",
    "\n",
    "# Exportar el dataframe resultante a un archivo Excel\n",
    "carreras_ifd.to_excel('carreras_ifd_actualizado.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9bc1fe-958a-44c7-acf2-97d2a1d7d7b8",
   "metadata": {},
   "source": [
    "### tipo de gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed4fb8-6df2-49e6-abeb-615b14c56e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar el tipo de gestión más frecuente para cada institución\n",
    "def completar_tipo_gestion(grupo):\n",
    "    if grupo['tipo_gestion'].isnull().all():\n",
    "        return grupo\n",
    "    # Obtener el tipo de gestión más frecuente (eliminando los nulos) \n",
    "    tipo_frecuente = grupo['tipo_gestion'].dropna().mode()[0]\n",
    "    # Rellenar los valores nulos con el tipo de gestión más frecuente\n",
    "    grupo['tipo_gestion'] = grupo['tipo_gestion'].fillna(tipo_frecuente)\n",
    "    return grupo\n",
    "\n",
    "# Aplicar la función a cada grupo de instituciones sin convertirlo en índice\n",
    "carreras_ifd = carreras_ifd.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n",
    "\n",
    "# Guardar el resultado en un archivo Excel\n",
    "carreras_ifd.to_excel('carreras_ifd_actualizado.xlsx', index=False)\n",
    "\n",
    "# Verificar si aún hay valores nulos en la columna 'tipo_gestion'\n",
    "print(carreras_cre['tipo_gestion'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cfc345-abea-441e-8e78-09147c4749ef",
   "metadata": {},
   "source": [
    "# Verificando inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750614ae-38a2-4ce4-9c04-591787d39db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_ifd_copy = titulos_ifd.copy()\n",
    "carreras_ifd_copy = carreras_ifd.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_ifd_copy = titulos_ifd_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_ifd_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_ifd_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_IFD.xlsx', index=False)\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722223b0-2585-47e5-b6a2-5077e12e51fa",
   "metadata": {},
   "source": [
    "## limpiando inconsistencias ifd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d21e2-ed9b-47c5-9bbf-58f255fc1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "# Función para extraer la parte posterior a 'AREA'\n",
    "def extract_after_area(text):\n",
    "    if 'AREA' in text:\n",
    "        return text.split('AREA', 1)[-1].strip()  # Extraer lo que sigue después de 'AREA'\n",
    "    return None  # Si no tiene 'AREA', devolver None\n",
    "\n",
    "# Función de coincidencia difusa optimizada\n",
    "def fuzzy_unify(row, carreras_ifd, threshold=75):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    carreras_ifd_filtered = carreras_ifd[\n",
    "        (carreras_ifd['institucion_carrera'] == row['institucion']) &\n",
    "        (carreras_ifd['tipo_institucion'] == row['tipo_institucion'])\n",
    "    ]\n",
    "\n",
    "    row['carrera_carreras'] = None\n",
    "    row['titulo_carrera'] = None\n",
    "    row['institucion_carrera'] = None\n",
    "\n",
    "    for _, carrera_row in carreras_ifd_filtered.iterrows():\n",
    "        # Extraer partes después de 'AREA'\n",
    "        area_row_1 = extract_after_area(row['carrera'])\n",
    "        area_row_2 = extract_after_area(carrera_row['carrera_carreras'])\n",
    "\n",
    "        if area_row_1 and area_row_2:  # Ambas tienen 'AREA'\n",
    "            area_score = fuzz.ratio(area_row_1, area_row_2)\n",
    "            if area_score < 70:  # Si la parte después de 'AREA' no es similar\n",
    "                avg_score = 60  # Asignar un puntaje bajo\n",
    "            else:\n",
    "                carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "                titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "                avg_score = (carrera_score + titulo_score) / 2\n",
    "        elif area_row_1 or area_row_2:  # Solo una de las partes tiene 'AREA'\n",
    "            avg_score = 60  # Puntaje bajo\n",
    "        else:\n",
    "            carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "            titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "            avg_score = (carrera_score + titulo_score) / 2\n",
    "\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_match = carrera_row\n",
    "\n",
    "    if best_score >= threshold and best_match is not None:\n",
    "        row['carrera_unificada'] = best_match['carrera_carreras']\n",
    "        row['titulo_unificado'] = best_match['titulo_carrera']\n",
    "        row['institucion_unificada'] = best_match['institucion_carrera']\n",
    "        row['carrera_carreras'] = best_match['carrera_carreras']\n",
    "        row['titulo_carrera'] = best_match['titulo_carrera']\n",
    "        row['institucion_carrera'] = best_match['institucion_carrera']\n",
    "    else:\n",
    "        row['carrera_unificada'] = row['carrera']\n",
    "        row['titulo_unificado'] = row['titulo_titulos']\n",
    "        row['institucion_unificada'] = row['institucion']\n",
    "\n",
    "    row['similarity_score'] = best_score\n",
    "    return row\n",
    "\n",
    "# Aplicar la coincidencia difusa\n",
    "left_only_unified = left_only.apply(fuzzy_unify, args=(carreras_ifd_copy,), axis=1)\n",
    "\n",
    "# Seleccionar las columnas en el orden deseado\n",
    "left_only_unified = left_only_unified[[\n",
    "    'carrera',\n",
    "    'carrera_carreras',\n",
    "    'carrera_unificada', \n",
    "    'titulo_titulos',\n",
    "    'titulo_carrera',\n",
    "    'titulo_unificado',\n",
    "    'institucion', \n",
    "    'institucion_carrera',\n",
    "    'institucion_unificada',\n",
    "    'similarity_score'\n",
    "]]\n",
    "\n",
    "# Exportar a un archivo Excel con el nombre modificado\n",
    "left_only_unified.to_excel('unificacion_left_only_ifd.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'unificacion_left_only_ifd.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b76a00-32ec-4f3b-9d8a-4e41996f516b",
   "metadata": {},
   "source": [
    "# REEMPLAZAR CAMPOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344bbe94-a717-48a8-bf40-3573136c4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Filtrar las filas de left_only_unified con un puntaje mayor o igual a 90\n",
    "left_only_unified_filtered = left_only_unified[left_only_unified['similarity_score'] >= 89.5]\n",
    "\n",
    "# Paso 2: Reemplazar los valores en titulos_cre\n",
    "for _, row in left_only_unified_filtered.iterrows():\n",
    "    # Buscar coincidencias en titulos_cre\n",
    "    condition = (\n",
    "        (titulos_ifd['carrera'] == row['carrera']) &\n",
    "        (titulos_ifd['titulo'] == row['titulo_titulos']) &\n",
    "        (titulos_ifd['institucion'] == row['institucion'])\n",
    "    )\n",
    "    \n",
    "    # Reemplazar los valores en titulos_cre si hay coincidencias\n",
    "    titulos_ifd.loc[condition, 'carrera'] = row['carrera_unificada']\n",
    "    titulos_ifd.loc[condition, 'titulo'] = row['titulo_unificado']\n",
    "\n",
    "# Puedes guardar el DataFrame actualizado en un archivo Excel o CSV si lo deseas\n",
    "titulos_ifd.to_excel('titulos_ifd_actualizado.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'titulos_ifd_actualizado.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb58b8f6-664c-422e-8147-3afe82c1c2b7",
   "metadata": {},
   "source": [
    "# SEGUNDA REVISION #OPCIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6107f17-69df-4be5-8161-8653e891c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_ifd_copy = titulos_ifd.copy()\n",
    "carreras_ifd_copy = carreras_ifd.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_ifd_copy = titulos_ifd_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_ifd_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_ifd_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_IFD.xlsx', index=False)\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5645dda5-fce9-4a9b-921b-079f809310e9",
   "metadata": {},
   "source": [
    "# UNIFICACION FINAL IFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6d8bd-3bdf-462a-b05e-fccd92dd2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Eliminar duplicados en las columnas clave de carreras\n",
    "df_merged_unique = carreras_ifd.drop_duplicates(\n",
    "    subset=['carrera', 'institucion', 'tipo_institucion', 'titulo']\n",
    ")\n",
    "\n",
    "# Paso 2: Realizar el merge con las combinaciones únicas\n",
    "merged_final_IFD = pd.merge(\n",
    "    titulos_ifd, \n",
    "    df_merged_unique, \n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    how='left'  # Aquí cambiamos a 'left' para mantener todas las filas de df_titulos_v2_limpio_CRE\n",
    ")\n",
    "\n",
    "# Paso 2: Guardar el DataFrame en un archivo Excel\n",
    "merged_final_IFD.to_excel('IFD_FINAL.xlsx', index=False)\n",
    "# Imprimir la forma y los encabezados de df_titulos_v2_limpio_CRE\n",
    "print(\"Shape del DataFrame TITULOS V2:\", titulos_ifd.shape)\n",
    "\n",
    "\n",
    "# Imprimir la forma y los encabezados del DataFrame final\n",
    "print(\"Shape del DataFrame final:\", merged_final_IFD.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd62357-c5d4-4d09-acc4-86b8f1a276c8",
   "metadata": {},
   "source": [
    "# INSTITUTO SUPERIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd4e61-5158-41a1-9c55-8628929415e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correcciones realizadas en titulos_is:\")\n",
    "print(titulos_is['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n",
    "print(\"\\nCorrecciones realizadas en carreras_is:\")\n",
    "print(carreras_is['institucion'].unique())  # Imprime los valores únicos para ver las correcciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f6ae4-c46f-4448-98ee-b20c9a1993b9",
   "metadata": {},
   "source": [
    "# INSTITUCIONES QUE ESTAN EN UN SOLO LUGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9575d2-4f65-4e2c-bd87-90e9b8e5ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores únicos en 'titulos_cre'\n",
    "instituciones_titulos = set(titulos_is['institucion'].unique())\n",
    "\n",
    "# Valores únicos en 'carreras_cre'\n",
    "instituciones_carreras = set(carreras_is['institucion'].unique())\n",
    "\n",
    "# Instituciones que están en 'titulos_cre' pero no en 'carreras_cre'\n",
    "solo_en_titulos = instituciones_titulos - instituciones_carreras\n",
    "print(\"Instituciones que están solo en titulos_is:\")\n",
    "print(solo_en_titulos)\n",
    "\n",
    "# Instituciones que están en 'carreras_cre' pero no en 'titulos_cre'\n",
    "solo_en_carreras = instituciones_carreras - instituciones_titulos\n",
    "print(\"\\nInstituciones que están solo en carreras_is:\")\n",
    "print(solo_en_carreras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c58c11-87e1-4b36-aac2-8d1c54fe7a30",
   "metadata": {},
   "source": [
    "## Limpieza general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe00548-f7e2-4c23-83a7-cdfdb7bdd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos_is['institucion'] = titulos_is['institucion'].replace(\n",
    "    'INSTITUTO SUPERIOR VIA PRO DESARROLLO',\n",
    "    'INSTITUTO SUPERIOR DE EDUCACION VIA PRO DESARROLLO'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f3eee-0cca-4af8-9fea-b89cbd340d1f",
   "metadata": {},
   "source": [
    "# campos vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9e19b-67fe-4bba-a827-d05fa981e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar valores nulos en cada columna de titulos_cre\n",
    "print(\"Valores nulos en titulos_is:\")\n",
    "print(titulos_is.isnull().sum())\n",
    "\n",
    "# Contar valores nulos en cada columna de carreras_cre\n",
    "print(\"\\nValores nulos en carreras_is:\")\n",
    "print(carreras_is.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f753a88-2620-4102-bf52-c1d200ec4c9f",
   "metadata": {},
   "source": [
    "# campos vacios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b604b0e0-f58c-414a-bae3-d758800edc6c",
   "metadata": {},
   "source": [
    "# campos amplio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84c9012-5e52-488e-ac76-800ff666bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Concatenar los dataframes\n",
    "df_combined = pd.concat([carreras_is, carreras_ifd, carreras_cre], ignore_index=True)\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio no esté vacío para entrenamiento\n",
    "df_train = df_combined.dropna(subset=['clasificacion_campo_amplio'])\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio esté vacío para predicción\n",
    "df_predict = df_combined[df_combined['clasificacion_campo_amplio'].isna()]\n",
    "\n",
    "# Vectorización de la columna 'carrera' utilizando TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_train['carrera'])\n",
    "X_predict = vectorizer.transform(df_predict['carrera'])\n",
    "\n",
    "# Definir el target\n",
    "y_train = df_train['clasificacion_campo_amplio']\n",
    "\n",
    "# División de los datos de entrenamiento para validación\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Validar el modelo\n",
    "y_val_pred = model.predict(X_val_split)\n",
    "print(\"Reporte de clasificación para datos de validación:\")\n",
    "print(classification_report(y_val_split, y_val_pred, zero_division=0))\n",
    "\n",
    "# Predecir los valores faltantes en df_merged_IS y añadir el asterisco\n",
    "def predecir_y_marcar(row, model, vectorizer):\n",
    "    if pd.isna(row['clasificacion_campo_amplio']):\n",
    "        prediccion = model.predict(vectorizer.transform([row['carrera']]))[0]\n",
    "        return f\"{prediccion}*\"\n",
    "    else:\n",
    "        return row['clasificacion_campo_amplio']\n",
    "\n",
    "carreras_is['clasificacion_campo_amplio'] = carreras_is.apply(\n",
    "    lambda row: predecir_y_marcar(row, model, vectorizer),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Exportar el dataframe resultante a Excel\n",
    "carreras_is.to_excel('carreras_is_actualizado.xlsx', index=False)\n",
    "\n",
    "# Conteo de valores vacíos por columna después de la predicción\n",
    "valores_vacios_post_prediccion = carreras_is.isna().sum()\n",
    "print(\"Total de valores vacíos por columna después de la predicción:\")\n",
    "print(valores_vacios_post_prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad46ac-0bd0-4238-a10a-7441d6efe3b1",
   "metadata": {},
   "source": [
    "# tipo de gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8b07ca-6a26-48d0-8ab4-44a2233be2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar el tipo de gestión más frecuente para cada institución\n",
    "def completar_tipo_gestion(grupo):\n",
    "    if grupo['tipo_gestion'].isnull().all():\n",
    "        return grupo\n",
    "    # Obtener el tipo de gestión más frecuente (eliminando los nulos) \n",
    "    tipo_frecuente = grupo['tipo_gestion'].dropna().mode()[0]\n",
    "    # Rellenar los valores nulos con el tipo de gestión más frecuente\n",
    "    grupo['tipo_gestion'] = grupo['tipo_gestion'].fillna(tipo_frecuente)\n",
    "    return grupo\n",
    "\n",
    "# Aplicar la función a cada grupo de instituciones sin convertirlo en índice\n",
    "carreras_is = carreras_is.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n",
    "\n",
    "# Guardar el resultado en un archivo Excel\n",
    "carreras_is.to_excel('carreras_is_actualizado.xlsx', index=False)\n",
    "\n",
    "# Verificar si aún hay valores nulos en la columna 'tipo_gestion'\n",
    "print(carreras_is['tipo_gestion'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33562513-ce5d-4f17-a45b-1e0d57e7000d",
   "metadata": {},
   "source": [
    "# Verificacion de inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5598124d-4b53-46bb-bdc9-c235156aed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_is_copy = titulos_is.copy()\n",
    "carreras_is_copy = carreras_is.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_is_copy = titulos_is_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_is_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_is_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_IS.xlsx', index=False)\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ae064-1862-48ee-928a-12c7d8afa7e8",
   "metadata": {},
   "source": [
    "# Limpieza de inconsistencias IS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0158a5-b26f-47b6-8f90-b1ae5b9a9f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "# Función para extraer la parte posterior a 'AREA'\n",
    "def extract_after_area(text):\n",
    "    if 'AREA' in text:\n",
    "        return text.split('AREA', 1)[-1].strip()  # Extraer lo que sigue después de 'AREA'\n",
    "    return None  # Si no tiene 'AREA', devolver None\n",
    "\n",
    "# Función para verificar palabras clave\n",
    "def check_keywords(text1, text2):\n",
    "    keywords = ['CIENCIAS BASICAS', 'CIENCIAS SOCIALES', 'FISIOTERAPIA', 'KINESIOLOGIA', 'PSICOLOGIA', 'EDUCACION FISICA']\n",
    "    for keyword in keywords:\n",
    "        if keyword in text1 and keyword not in text2:\n",
    "            return True\n",
    "        if keyword in text2 and keyword not in text1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Función de coincidencia difusa optimizada\n",
    "def fuzzy_unify(row, carreras_is, threshold=75):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    carreras_is_filtered = carreras_is[\n",
    "        (carreras_is['institucion_carrera'] == row['institucion']) &\n",
    "        (carreras_is['tipo_institucion'] == row['tipo_institucion'])\n",
    "    ]\n",
    "\n",
    "    row['carrera_carreras'] = None\n",
    "    row['titulo_carrera'] = None\n",
    "    row['institucion_carrera'] = None\n",
    "\n",
    "    for _, carrera_row in carreras_is_filtered.iterrows():\n",
    "        # Extraer partes después de 'AREA'\n",
    "        area_row_1 = extract_after_area(row['carrera'])\n",
    "        area_row_2 = extract_after_area(carrera_row['carrera_carreras'])\n",
    "\n",
    "        if area_row_1 and area_row_2:  # Ambas tienen 'AREA'\n",
    "            area_score = fuzz.ratio(area_row_1, area_row_2)\n",
    "            if area_score < 70:  # Si la parte después de 'AREA' no es similar\n",
    "                avg_score = 60  # Asignar un puntaje bajo\n",
    "            else:\n",
    "                carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "                titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "                avg_score = (carrera_score + titulo_score) / 2\n",
    "        elif area_row_1 or area_row_2:  # Solo una de las partes tiene 'AREA'\n",
    "            avg_score = 60  # Puntaje bajo\n",
    "        else:\n",
    "            carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "            titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "            avg_score = (carrera_score + titulo_score) / 2\n",
    "\n",
    "        # Verificar palabras clave\n",
    "        if check_keywords(row['carrera'], carrera_row['carrera_carreras']):\n",
    "            avg_score *= 0.5  # Reducir el puntaje a la mitad si hay un desajuste en las palabras clave\n",
    "\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_match = carrera_row\n",
    "\n",
    "    if best_score >= threshold and best_match is not None:\n",
    "        row['carrera_unificada'] = best_match['carrera_carreras']\n",
    "        row['titulo_unificado'] = best_match['titulo_carrera']\n",
    "        row['institucion_unificada'] = best_match['institucion_carrera']\n",
    "        row['carrera_carreras'] = best_match['carrera_carreras']\n",
    "        row['titulo_carrera'] = best_match['titulo_carrera']\n",
    "        row['institucion_carrera'] = best_match['institucion_carrera']\n",
    "    else:\n",
    "        row['carrera_unificada'] = row['carrera']\n",
    "        row['titulo_unificada'] = row['titulo_titulos']\n",
    "        row['institucion_unificada'] = row['institucion']\n",
    "\n",
    "    row['similarity_score'] = best_score\n",
    "    return row\n",
    "\n",
    "# Aplicar la coincidencia difusa\n",
    "left_only_unified = left_only.apply(fuzzy_unify, args=(carreras_is_copy,), axis=1)\n",
    "\n",
    "# Seleccionar las columnas en el orden deseado\n",
    "left_only_unified = left_only_unified[[\n",
    "    'carrera',\n",
    "    'carrera_carreras',\n",
    "    'carrera_unificada', \n",
    "    'titulo_titulos',\n",
    "    'titulo_carrera',\n",
    "    'titulo_unificado',\n",
    "    'institucion', \n",
    "    'institucion_carrera',\n",
    "    'institucion_unificada',\n",
    "    'similarity_score'\n",
    "]]\n",
    "\n",
    "# Exportar a un archivo Excel con el nombre modificado\n",
    "left_only_unified.to_excel('unificacion_left_only_is.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'unificacion_left_only_is.xlsx'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad556a8-f675-4a52-8db0-1b0ba0607992",
   "metadata": {},
   "source": [
    "# REEMPLAZAR CAMPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2e998-858d-4099-8225-b12b8fc10b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Filtrar las filas de left_only_unified con un puntaje mayor o igual a 90\n",
    "left_only_unified_filtered = left_only_unified[left_only_unified['similarity_score'] >= 89.5]\n",
    "\n",
    "# Paso 2: Reemplazar los valores en titulos_cre\n",
    "for _, row in left_only_unified_filtered.iterrows():\n",
    "    # Buscar coincidencias en titulos_cre\n",
    "    condition = (\n",
    "        (titulos_is['carrera'] == row['carrera']) &\n",
    "        (titulos_is['titulo'] == row['titulo_titulos']) &\n",
    "        (titulos_is['institucion'] == row['institucion'])\n",
    "    )\n",
    "    \n",
    "    # Reemplazar los valores en titulos_cre si hay coincidencias\n",
    "    titulos_is.loc[condition, 'carrera'] = row['carrera_unificada']\n",
    "    titulos_is.loc[condition, 'titulo'] = row['titulo_unificado']\n",
    "\n",
    "# Puedes guardar el DataFrame actualizado en un archivo Excel o CSV si lo deseas\n",
    "titulos_is.to_excel('titulos_is_actualizado.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'titulos_is_actualizado.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287f12c-4658-432b-95f8-01177183f85c",
   "metadata": {},
   "source": [
    "# SEGUNDA VERIFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd0a48-d40d-4857-af0d-94af90a2f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_is_copy = titulos_is.copy()\n",
    "carreras_is_copy = carreras_is.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_is_copy = titulos_is_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_is_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_is_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_IS.xlsx', index=False)\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f8c2a-7509-4166-a508-503386e080a6",
   "metadata": {},
   "source": [
    "# UNION FINAL IS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2168073-adbb-48a3-859f-639172c0bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Eliminar duplicados en las columnas clave de carreras\n",
    "df_merged_unique = carreras_is.drop_duplicates(\n",
    "    subset=['carrera', 'institucion', 'tipo_institucion', 'titulo']\n",
    ")\n",
    "\n",
    "# Paso 2: Realizar el merge con las combinaciones únicas\n",
    "merged_final_IS = pd.merge(\n",
    "    titulos_is, \n",
    "    df_merged_unique, \n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    how='left'  # Aquí cambiamos a 'left' para mantener todas las filas de df_titulos_v2_limpio_CRE\n",
    ")\n",
    "\n",
    "# Paso 2: Guardar el DataFrame en un archivo Excel\n",
    "merged_final_IS.to_excel('IS_FINAL.xlsx', index=False)\n",
    "# Imprimir la forma y los encabezados de df_titulos_v2_limpio_CRE\n",
    "print(\"Shape del DataFrame TITULOS V2:\", titulos_is.shape)\n",
    "\n",
    "\n",
    "# Imprimir la forma y los encabezados del DataFrame final\n",
    "print(\"Shape del DataFrame final:\", merged_final_IS.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8bb6b-2855-4e21-96b3-27dd31acd701",
   "metadata": {},
   "source": [
    "# INSTITUTO TECNICO SUPERIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acecb347-2031-4915-be67-e12b121974f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correcciones realizadas en titulos_its:\")\n",
    "print(titulos_its['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n",
    "print(\"\\nCorrecciones realizadas en carreras_its:\")\n",
    "print(carreras_its['institucion'].unique())  # Imprime los valores únicos para ver las correcciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2289b5e2-fb56-4954-93be-22d7bd1fc422",
   "metadata": {},
   "source": [
    "# INSTITUTOS QUE ESTAN EN UN SOLO LUGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f3a97-047b-4570-a017-4814edcf5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores únicos en 'titulos_cre'\n",
    "instituciones_titulos = set(titulos_its['institucion'].unique())\n",
    "\n",
    "# Valores únicos en 'carreras_cre'\n",
    "instituciones_carreras = set(carreras_its['institucion'].unique())\n",
    "\n",
    "# Instituciones que están en 'titulos_cre' pero no en 'carreras_cre'\n",
    "solo_en_titulos = instituciones_titulos - instituciones_carreras\n",
    "print(\"Instituciones que están solo en titulos_its:\")\n",
    "print(solo_en_titulos)\n",
    "\n",
    "# Instituciones que están en 'carreras_cre' pero no en 'titulos_cre'\n",
    "solo_en_carreras = instituciones_carreras - instituciones_titulos\n",
    "print(\"\\nInstituciones que están solo en carreras_its:\")\n",
    "print(solo_en_carreras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580d012-f9de-4975-a5b8-a64341afb13a",
   "metadata": {},
   "source": [
    "# verificar valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a61765-ba16-4e0c-888a-27ae1aee6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar valores nulos en cada columna de titulos_cre\n",
    "print(\"Valores nulos en titulos_its:\")\n",
    "print(titulos_its.isnull().sum())\n",
    "\n",
    "# Contar valores nulos en cada columna de carreras_cre\n",
    "print(\"\\nValores nulos en carreras_its:\")\n",
    "print(carreras_its.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c6a207-f0cd-4657-89a3-4e46d3033083",
   "metadata": {},
   "source": [
    "# campo amplio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81c2c5-be17-4fb9-bda5-1fe01bc44e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Concatenar los dataframes\n",
    "df_combined = pd.concat([carreras_is, carreras_ifd, carreras_cre, carreras_its], ignore_index=True)\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio no esté vacío para entrenamiento\n",
    "df_train = df_combined.dropna(subset=['clasificacion_campo_amplio'])\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio esté vacío para predicción\n",
    "df_predict = df_combined[df_combined['clasificacion_campo_amplio'].isna()]\n",
    "\n",
    "# Vectorización de la columna 'carrera' utilizando TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_train['carrera'])\n",
    "X_predict = vectorizer.transform(df_predict['carrera'])\n",
    "\n",
    "# Definir el target\n",
    "y_train = df_train['clasificacion_campo_amplio']\n",
    "\n",
    "# División de los datos de entrenamiento para validación\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Validar el modelo\n",
    "y_val_pred = model.predict(X_val_split)\n",
    "print(\"Reporte de clasificación para datos de validación:\")\n",
    "print(classification_report(y_val_split, y_val_pred, zero_division=0))\n",
    "\n",
    "# Predecir los valores faltantes en df_merged_IS y añadir el asterisco\n",
    "def predecir_y_marcar(row, model, vectorizer):\n",
    "    if pd.isna(row['clasificacion_campo_amplio']):\n",
    "        prediccion = model.predict(vectorizer.transform([row['carrera']]))[0]\n",
    "        return f\"{prediccion}*\"\n",
    "    else:\n",
    "        return row['clasificacion_campo_amplio']\n",
    "\n",
    "carreras_its['clasificacion_campo_amplio'] = carreras_its.apply(\n",
    "    lambda row: predecir_y_marcar(row, model, vectorizer),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Exportar el dataframe resultante a Excel\n",
    "carreras_its.to_excel('carreras_its_actualizado.xlsx', index=False)\n",
    "\n",
    "# Conteo de valores vacíos por columna después de la predicción\n",
    "valores_vacios_post_prediccion = carreras_its.isna().sum()\n",
    "print(\"Total de valores vacíos por columna después de la predicción:\")\n",
    "print(valores_vacios_post_prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9f2a0-2413-4641-bd3e-44e0de2efafb",
   "metadata": {},
   "source": [
    "# tipo gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5923a-ec2f-476c-9895-7cee2159e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar el tipo de gestión más frecuente para cada institución\n",
    "def completar_tipo_gestion(grupo):\n",
    "    if grupo['tipo_gestion'].isnull().all():\n",
    "        return grupo\n",
    "    # Obtener el tipo de gestión más frecuente (eliminando los nulos) \n",
    "    tipo_frecuente = grupo['tipo_gestion'].dropna().mode()[0]\n",
    "    # Rellenar los valores nulos con el tipo de gestión más frecuente\n",
    "    grupo['tipo_gestion'] = grupo['tipo_gestion'].fillna(tipo_frecuente)\n",
    "    return grupo\n",
    "\n",
    "# Aplicar la función a cada grupo de instituciones sin convertirlo en índice\n",
    "carreras_its = carreras_its.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n",
    "\n",
    "# Guardar el resultado en un archivo Excel\n",
    "carreras_its.to_excel('carreras_its_actualizado.xlsx', index=False)\n",
    "\n",
    "# Verificar si aún hay valores nulos en la columna 'tipo_gestion'\n",
    "print(carreras_is['tipo_gestion'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d85e6a-ffeb-4798-a4f2-faeae01ce00a",
   "metadata": {},
   "source": [
    "# VERIFICACION DE INCONSISTENCIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5772c9d-9439-44e6-8ebb-fcebc69526ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_its_copy = titulos_its.copy()\n",
    "carreras_its_copy = carreras_its.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_its_copy = titulos_its_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_its_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_its_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_ITS.xlsx', index=False)\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b8b464-ea9f-46f6-bb84-959cc7be113a",
   "metadata": {},
   "source": [
    "# LIMPIEZA DE INCONSISTENCIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb385e-802b-4e6c-8de7-a2a2aa8e3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "# Función para extraer la parte posterior a 'AREA'\n",
    "def extract_after_area(text):\n",
    "    if 'AREA' in text:\n",
    "        return text.split('AREA', 1)[-1].strip()  # Extraer lo que sigue después de 'AREA'\n",
    "    return None  # Si no tiene 'AREA', devolver None\n",
    "\n",
    "# Función para verificar palabras clave\n",
    "def check_keywords(text1, text2):\n",
    "    keywords = ['CIENCIAS BASICAS', 'CIENCIAS SOCIALES', 'FISIOTERAPIA', 'KINESIOLOGIA', 'PSICOLOGIA', 'EDUCACION FISICA']\n",
    "    for keyword in keywords:\n",
    "        if keyword in text1 and keyword not in text2:\n",
    "            return True\n",
    "        if keyword in text2 and keyword not in text1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Función de coincidencia difusa optimizada\n",
    "def fuzzy_unify(row, carreras_its, threshold=75):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    carreras_its_filtered = carreras_its[\n",
    "        (carreras_its['institucion_carrera'] == row['institucion']) &\n",
    "        (carreras_its['tipo_institucion'] == row['tipo_institucion'])\n",
    "    ]\n",
    "\n",
    "    row['carrera_carreras'] = None\n",
    "    row['titulo_carrera'] = None\n",
    "    row['institucion_carrera'] = None\n",
    "\n",
    "    for _, carrera_row in carreras_its_filtered.iterrows():\n",
    "        # Extraer partes después de 'AREA'\n",
    "        area_row_1 = extract_after_area(row['carrera'])\n",
    "        area_row_2 = extract_after_area(carrera_row['carrera_carreras'])\n",
    "\n",
    "        if area_row_1 and area_row_2:  # Ambas tienen 'AREA'\n",
    "            area_score = fuzz.ratio(area_row_1, area_row_2)\n",
    "            if area_score < 70:  # Si la parte después de 'AREA' no es similar\n",
    "                avg_score = 60  # Asignar un puntaje bajo\n",
    "            else:\n",
    "                carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "                titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "                avg_score = (carrera_score + titulo_score) / 2\n",
    "        elif area_row_1 or area_row_2:  # Solo una de las partes tiene 'AREA'\n",
    "            avg_score = 60  # Puntaje bajo\n",
    "        else:\n",
    "            carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "            titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "            avg_score = (carrera_score + titulo_score) / 2\n",
    "\n",
    "        # Verificar palabras clave\n",
    "        if check_keywords(row['carrera'], carrera_row['carrera_carreras']):\n",
    "            avg_score *= 0.5  # Reducir el puntaje a la mitad si hay un desajuste en las palabras clave\n",
    "\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_match = carrera_row\n",
    "\n",
    "    if best_score >= threshold and best_match is not None:\n",
    "        row['carrera_unificada'] = best_match['carrera_carreras']\n",
    "        row['titulo_unificado'] = best_match['titulo_carrera']\n",
    "        row['institucion_unificada'] = best_match['institucion_carrera']\n",
    "        row['carrera_carreras'] = best_match['carrera_carreras']\n",
    "        row['titulo_carrera'] = best_match['titulo_carrera']\n",
    "        row['institucion_carrera'] = best_match['institucion_carrera']\n",
    "    else:\n",
    "        row['carrera_unificada'] = row['carrera']\n",
    "        row['titulo_unificada'] = row['titulo_titulos']\n",
    "        row['institucion_unificada'] = row['institucion']\n",
    "\n",
    "    row['similarity_score'] = best_score\n",
    "    return row\n",
    "\n",
    "# Aplicar la coincidencia difusa\n",
    "left_only_unified = left_only.apply(fuzzy_unify, args=(carreras_its_copy,), axis=1)\n",
    "\n",
    "# Seleccionar las columnas en el orden deseado\n",
    "left_only_unified = left_only_unified[[\n",
    "    'carrera',\n",
    "    'carrera_carreras',\n",
    "    'carrera_unificada', \n",
    "    'titulo_titulos',\n",
    "    'titulo_carrera',\n",
    "    'titulo_unificado',\n",
    "    'institucion', \n",
    "    'institucion_carrera',\n",
    "    'institucion_unificada',\n",
    "    'similarity_score'\n",
    "]]\n",
    "\n",
    "# Exportar a un archivo Excel con el nombre modificado\n",
    "left_only_unified.to_excel('unificacion_left_only_its.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'unificacion_left_only_its.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c264e5a-d87a-49cc-9b3d-17eac990a986",
   "metadata": {},
   "source": [
    "# reemplazar campos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11717518-c335-4d47-bee1-8c71a9bad3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Filtrar las filas de left_only_unified con un puntaje mayor o igual a 90\n",
    "left_only_unified_filtered = left_only_unified[left_only_unified['similarity_score'] >= 100]\n",
    "\n",
    "# Paso 2: Reemplazar los valores en titulos_cre\n",
    "for _, row in left_only_unified_filtered.iterrows():\n",
    "    # Buscar coincidencias en titulos_cre\n",
    "    condition = (\n",
    "        (titulos_its['carrera'] == row['carrera']) &\n",
    "        (titulos_its['titulo'] == row['titulo_titulos']) &\n",
    "        (titulos_its['institucion'] == row['institucion'])\n",
    "    )\n",
    "    \n",
    "    # Reemplazar los valores en titulos_cre si hay coincidencias\n",
    "    titulos_its.loc[condition, 'carrera'] = row['carrera_unificada']\n",
    "    titulos_its.loc[condition, 'titulo'] = row['titulo_unificado']\n",
    "\n",
    "# Puedes guardar el DataFrame actualizado en un archivo Excel o CSV si lo deseas\n",
    "titulos_its.to_excel('titulos_its_actualizado.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'titulos_its_actualizado.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e9101-252a-4d4a-bea5-ec9e5c8d8972",
   "metadata": {},
   "source": [
    "# Segunda verificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07aa592-f78e-4b44-a47e-1c14ed7eaad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_its_copy = titulos_its.copy()\n",
    "carreras_its_copy = carreras_its.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_its_copy = titulos_its_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_its_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_its_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_ITS.xlsx', index=False)\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcfa42d-c4cc-4073-af48-25d68374f3f8",
   "metadata": {},
   "source": [
    "# Union final ITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd6d34b-2e4f-4391-8900-cd7cc20eaee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Eliminar duplicados en las columnas clave de carreras\n",
    "df_merged_unique = carreras_its.drop_duplicates(\n",
    "    subset=['carrera', 'institucion', 'tipo_institucion', 'titulo']\n",
    ")\n",
    "\n",
    "# Paso 2: Realizar el merge con las combinaciones únicas\n",
    "merged_final_ITS = pd.merge(\n",
    "    titulos_its, \n",
    "    df_merged_unique, \n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    how='left'  # Aquí cambiamos a 'left' para mantener todas las filas de df_titulos_v2_limpio_CRE\n",
    ")\n",
    "\n",
    "# Paso 2: Guardar el DataFrame en un archivo Excel\n",
    "merged_final_ITS.to_excel('ITS_FINAL.xlsx', index=False)\n",
    "# Imprimir la forma y los encabezados de df_titulos_v2_limpio_CRE\n",
    "print(\"Shape del DataFrame TITULOS V2:\", titulos_its.shape)\n",
    "\n",
    "\n",
    "# Imprimir la forma y los encabezados del DataFrame final\n",
    "print(\"Shape del DataFrame final:\", merged_final_ITS.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fdc29-0a0a-47ba-a6da-841ff258b366",
   "metadata": {},
   "source": [
    "# UNIVERSIDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9cf66-91b7-445e-86c2-fa00cd166469",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correcciones realizadas en titulos_u:\")\n",
    "print(titulos_u['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n",
    "print(\"\\nCorrecciones realizadas en carreras_u:\")\n",
    "print(carreras_u['institucion'].unique())  # Imprime los valores únicos para ver las correcciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdd9bf-9384-4906-9e10-6fca2c8b9d4b",
   "metadata": {},
   "source": [
    "# INSTITUTOS QUE ESTAN EN UN SOLO LUGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08518a0a-6b33-4e75-83ff-7494f0751473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores únicos en 'titulos_cre'\n",
    "instituciones_titulos = set(titulos_u['institucion'].unique())\n",
    "\n",
    "# Valores únicos en 'carreras_cre'\n",
    "instituciones_carreras = set(carreras_u['institucion'].unique())\n",
    "\n",
    "# Instituciones que están en 'titulos_cre' pero no en 'carreras_cre'\n",
    "solo_en_titulos = instituciones_titulos - instituciones_carreras\n",
    "print(\"Instituciones que están solo en titulos_u:\")\n",
    "print(solo_en_titulos)\n",
    "\n",
    "# Instituciones que están en 'carreras_cre' pero no en 'titulos_cre'\n",
    "solo_en_carreras = instituciones_carreras - instituciones_titulos\n",
    "print(\"\\nInstituciones que están solo en carreras_u:\")\n",
    "print(solo_en_carreras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0502071-3432-40c1-a617-a826ca9064d1",
   "metadata": {},
   "source": [
    "# campo amplio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e2e62-1267-4eff-b2a7-cb15f34b2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Concatenar los dataframes\n",
    "df_combined = pd.concat([carreras_is, carreras_ifd, carreras_cre, carreras_its, carreras_u], ignore_index=True)\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio no esté vacío para entrenamiento\n",
    "df_train = df_combined.dropna(subset=['clasificacion_campo_amplio'])\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio esté vacío para predicción\n",
    "df_predict = df_combined[df_combined['clasificacion_campo_amplio'].isna()]\n",
    "\n",
    "# Vectorización de la columna 'carrera' utilizando TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_train['carrera'])\n",
    "X_predict = vectorizer.transform(df_predict['carrera'])\n",
    "\n",
    "# Definir el target\n",
    "y_train = df_train['clasificacion_campo_amplio']\n",
    "\n",
    "# División de los datos de entrenamiento para validación\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Validar el modelo\n",
    "y_val_pred = model.predict(X_val_split)\n",
    "print(\"Reporte de clasificación para datos de validación:\")\n",
    "print(classification_report(y_val_split, y_val_pred, zero_division=0))\n",
    "\n",
    "# Predecir los valores faltantes en df_merged_IS y añadir el asterisco\n",
    "def predecir_y_marcar(row, model, vectorizer):\n",
    "    if pd.isna(row['clasificacion_campo_amplio']):\n",
    "        prediccion = model.predict(vectorizer.transform([row['carrera']]))[0]\n",
    "        return f\"{prediccion}*\"\n",
    "    else:\n",
    "        return row['clasificacion_campo_amplio']\n",
    "\n",
    "carreras_u['clasificacion_campo_amplio'] = carreras_u.apply(\n",
    "    lambda row: predecir_y_marcar(row, model, vectorizer),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Exportar el dataframe resultante a Excel\n",
    "carreras_u.to_excel('carreras_u_actualizado.xlsx', index=False)\n",
    "\n",
    "# Conteo de valores vacíos por columna después de la predicción\n",
    "valores_vacios_post_prediccion = carreras_u.isna().sum()\n",
    "print(\"Total de valores vacíos por columna después de la predicción:\")\n",
    "print(valores_vacios_post_prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8417584-f468-40d4-b4f1-db9845b0ffab",
   "metadata": {},
   "source": [
    "# verificar inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae270e4-95b8-4d80-9c02-e734c3f60a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_u_copy = titulos_u.copy()\n",
    "carreras_u_copy = carreras_u.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_u_copy = titulos_u_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_u_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_u_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_U.xlsx', index=False)\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452c6d6-5bb4-43c7-b19f-d46c56c0fe09",
   "metadata": {},
   "source": [
    "# Limpieza de inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3adf68-3784-4476-8ed2-8a8afe7ad7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from tqdm import tqdm  # Importar tqdm\n",
    "# Lista de palabras clave que quieres analizar\n",
    "\n",
    "keywords = [\n",
    "    'CIENCIAS AMBIENTALES', 'CIENCIAS DE LA COMUNICACION','CIENCIAS DE LA EDUCACION', \n",
    "    'CIENCIAS INFORMATICAS','CIENCIAS ODONTOLOGICAS','CIENCIAS CONTABLES','DIDACTICA SUPERIOR','DIDACTICA UNIVERSITARIA','DOCENCIA UNIVERSITARIA',\n",
    "    'EDUCACION','MATEMATICA','MEDICINA','METODOLOGIA','PSICOLOGIA','ODONTOLOGIA','RELACIONES PUBLICAS',\n",
    "    'ADMINISTRACION', 'INGENIERIA', 'GESTION', 'CIENCIAS', 'TECNOLOGIA',\n",
    "    'DIDACTICA', 'ENFASIS', 'MENCION','CIRUGIA','GERENCIA'\n",
    "]\n",
    "\n",
    "# Función para extraer la parte anterior y posterior a cualquier palabra clave\n",
    "def extract_around_keywords(text, keywords):\n",
    "    text_upper = text.upper()  # Convertir a mayúsculas para comparación\n",
    "    for keyword in keywords:\n",
    "        if keyword in text_upper:\n",
    "            # Dividir el texto en la parte anterior y posterior a la palabra clave\n",
    "            before, after = text_upper.split(keyword, 1)\n",
    "            return before.strip(), after.strip()  # Devolver ambas partes\n",
    "    return None, None  # Si no se encuentra ninguna palabra clave, devolver None para ambas partes\n",
    "\n",
    "# Función para verificar palabras clave\n",
    "def check_keywords(text1, text2):\n",
    "    keywords2 = ['CIENCIAS SOCIALES', 'CIENCIAS NATURALES', 'CIENCIAS BASICAS', 'CIENCIAS DE LA EDUCACION','DIDACTICA UNIVERSITARIA',\n",
    "                 'MARKETING Y PUBLICIDAD','FARMACIA','QUIMICA','ODONTOLOGIA','NEUMOLOGIA','GINECOLOGIA',\n",
    "                  'SOCIAL', 'AGROPECUARIA', 'AGROPECUARIAS','ENFASIS', 'PROFUNDIZADO', 'RECONSTRUCTIVA',\n",
    "                  'FISIOTERAPIA', 'KINESIOLOGIA', 'PSICOLOGIA', 'EDUCACION FISICA','DERECHO','METODOLOGIA']\n",
    "    \n",
    "    for keyword in keywords2:\n",
    "        if keyword in text1 and keyword not in text2:\n",
    "            return True\n",
    "        if keyword in text2 and keyword not in text1:\n",
    "            return True\n",
    "    return False\n",
    "# Función de coincidencia difusa optimizada para múltiples palabras clave 75\n",
    "def fuzzy_unify(row, carreras_u, keywords, threshold=85):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    # Filtrar las filas de carreras_u por institución y tipo de institución\n",
    "    carreras_u_filtered = carreras_u[\n",
    "        (carreras_u['institucion_carrera'] == row['institucion']) &\n",
    "        (carreras_u['tipo_institucion'] == row['tipo_institucion'])\n",
    "    ]\n",
    "\n",
    "    # Inicializar las columnas para las coincidencias\n",
    "    row['carrera_carreras'] = None\n",
    "    row['titulo_carrera'] = None\n",
    "    row['institucion_carrera'] = None\n",
    "\n",
    "    for _, carrera_row in carreras_u_filtered.iterrows():\n",
    "        # Extraer partes antes y después de palabras clave\n",
    "        before_row_1, after_row_1 = extract_around_keywords(row['carrera'], keywords)\n",
    "        before_row_2, after_row_2 = extract_around_keywords(carrera_row['carrera_carreras'], keywords)\n",
    "\n",
    "        if before_row_1 is not None and after_row_1 is not None and before_row_2 is not None and after_row_2 is not None:  # Ambas tienen alguna palabra clave\n",
    "            # Comparar tanto la parte antes como después de la palabra clave\n",
    "            before_score = fuzz.ratio(before_row_1, before_row_2)\n",
    "            after_score = fuzz.ratio(after_row_1, after_row_2)\n",
    "            keyword_score = (before_score + after_score) / 2  # Promedio de ambas partes\n",
    "\n",
    "            if keyword_score < 70:  # Si la parte antes o después de la palabra clave no es similar\n",
    "                avg_score = 50  # Asignar un puntaje bajo\n",
    "            else:\n",
    "                carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "                titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "                avg_score = (carrera_score + titulo_score) / 2\n",
    "        elif before_row_1 or before_row_2 or after_row_1 or after_row_2:  # Solo una de las partes tiene la palabra clave\n",
    "            avg_score = 50  # Puntaje bajo\n",
    "        else:\n",
    "            carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "            titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "            avg_score = (carrera_score + titulo_score) / 2\n",
    "\n",
    "        # Verificar palabras clave\n",
    "        if check_keywords(row['carrera'], carrera_row['carrera_carreras']):\n",
    "            avg_score *= 0.5  # Reducir el puntaje a la mitad si hay un desajuste en las palabras clave\n",
    "\n",
    "        # Guardar la mejor coincidencia\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_match = carrera_row\n",
    "\n",
    "    # Si el mejor puntaje es suficiente, asignar la coincidencia\n",
    "    if best_score >= threshold and best_match is not None:\n",
    "        row['carrera_unificada'] = best_match['carrera_carreras']\n",
    "        row['titulo_unificado'] = best_match['titulo_carrera']\n",
    "        row['institucion_unificada'] = best_match['institucion_carrera']\n",
    "        row['carrera_carreras'] = best_match['carrera_carreras']\n",
    "        row['titulo_carrera'] = best_match['titulo_carrera']\n",
    "        row['institucion_carrera'] = best_match['institucion_carrera']\n",
    "    else:\n",
    "        # Si no hay buena coincidencia, mantener los valores originales\n",
    "        row['carrera_unificada'] = row['carrera']\n",
    "        row['titulo_unificada'] = row['titulo_titulos']\n",
    "        row['institucion_unificada'] = row['institucion']\n",
    "\n",
    "    # Asignar el puntaje de similitud\n",
    "    row['similarity_score'] = best_score\n",
    "    return row\n",
    "\n",
    "\n",
    "# Aplicar la coincidencia difusa con las palabras clave en el DataFrame\n",
    "tqdm.pandas(desc=\"Procesando filas\")  # Inicializar tqdm\n",
    "left_only_unified = left_only.progress_apply(fuzzy_unify, args=(carreras_u_copy, keywords), axis=1)\n",
    "\n",
    "\n",
    "# Seleccionar las columnas en el orden deseado para exportar a Excel\n",
    "left_only_unified = left_only_unified[[\n",
    "    'carrera',\n",
    "    'carrera_carreras',\n",
    "    'carrera_unificada', \n",
    "    'titulo_titulos',\n",
    "    'titulo_carrera',\n",
    "    'titulo_unificado',\n",
    "    'institucion', \n",
    "    'institucion_carrera',\n",
    "    'institucion_unificada',\n",
    "    'similarity_score'\n",
    "]]\n",
    "\n",
    "# Exportar a un archivo Excel\n",
    "left_only_unified.to_excel('unificacion_left_only_u.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'unificacion_left_only_u.xlsx'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39e8ad-65d9-414f-a2e7-f07bac88860d",
   "metadata": {},
   "source": [
    "# reemplazando campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de3346-3424-46d2-8705-b342bbfa04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Filtrar las filas de left_only_unified con un puntaje mayor o igual a 90\n",
    "left_only_unified_filtered = left_only_unified[left_only_unified['similarity_score'] >= 90]\n",
    "\n",
    "# Paso 2: Reemplazar los valores en titulos_cre\n",
    "for _, row in left_only_unified_filtered.iterrows():\n",
    "    # Buscar coincidencias en titulos_cre\n",
    "    condition = (\n",
    "        (titulos_u['carrera'] == row['carrera']) &\n",
    "        (titulos_u['titulo'] == row['titulo_titulos']) &\n",
    "        (titulos_u['institucion'] == row['institucion'])\n",
    "    )\n",
    "    \n",
    "    # Reemplazar los valores en titulos_cre si hay coincidencias\n",
    "    titulos_u.loc[condition, 'carrera'] = row['carrera_unificada']\n",
    "    titulos_u.loc[condition, 'titulo'] = row['titulo_unificado']\n",
    "\n",
    "# Puedes guardar el DataFrame actualizado en un archivo Excel o CSV si lo deseas\n",
    "titulos_u.to_excel('titulos_u_actualizado.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'titulos_u_actualizado.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bce3f1-7b87-4407-b53c-a8a3ca05b81b",
   "metadata": {},
   "source": [
    "# segunda verificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf92f8-7b1f-4ea8-8c04-2de864d1d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_u_copy = titulos_u.copy()\n",
    "carreras_u_copy = carreras_u.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_u_copy = titulos_u_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_u_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_u_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_U.xlsx', index=False)\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be870a4-e526-4f81-af11-2a144e2d1b40",
   "metadata": {},
   "source": [
    "# Union final U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0919bb-6272-44c4-afb6-bb37f6e9f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Eliminar duplicados en las columnas clave de carreras\n",
    "df_merged_unique = carreras_u.drop_duplicates(\n",
    "    subset=['carrera', 'institucion', 'tipo_institucion', 'titulo']\n",
    ")\n",
    "\n",
    "# Paso 2: Realizar el merge con las combinaciones únicas\n",
    "merged_final_U = pd.merge(\n",
    "    titulos_u, \n",
    "    df_merged_unique, \n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    how='left'  # Aquí cambiamos a 'left' para mantener todas las filas de df_titulos_v2_limpio_CRE\n",
    ")\n",
    "\n",
    "# Paso 2: Guardar el DataFrame en un archivo Excel\n",
    "merged_final_U.to_excel('U_FINAL.xlsx', index=False)\n",
    "# Imprimir la forma y los encabezados de df_titulos_v2_limpio_CRE\n",
    "print(\"Shape del DataFrame TITULOS V2:\", titulos_u.shape)\n",
    "\n",
    "\n",
    "# Imprimir la forma y los encabezados del DataFrame final\n",
    "print(\"Shape del DataFrame final:\", merged_final_U.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead3345-c8b9-4bde-b19a-a5e1a46f07ba",
   "metadata": {},
   "source": [
    "# Union final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04d0d3-a70d-4f71-8895-07000ba3cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# merged_final_U, merged_final_CRE, merged_final_IS, merged_final_IFD, merged_final_ITS\n",
    "\n",
    "# Concatenar los DataFrames\n",
    "merged_final_combinado = pd.concat([\n",
    "    merged_final_U,\n",
    "    merged_final_CRE,\n",
    "    merged_final_IS,\n",
    "    merged_final_IFD,\n",
    "    merged_final_ITS\n",
    "], ignore_index=True)\n",
    "\n",
    "# Usar tqdm para mostrar una barra de progreso al exportar a Excel\n",
    "with tqdm(total=1, desc=\"Exportando a Excel\") as pbar:\n",
    "    # Exportar a un archivo Excel\n",
    "    merged_final_combinado.to_excel('DATASET_FINAL.xlsx', index=False)\n",
    "    pbar.update(1)  # Actualizar la barra de progreso\n",
    "\n",
    "print(\"Archivo exportado: 'DATASET_FINAL.xlsx'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "panel-cell-order": [
   "5c3f1771-14f9-4b20-a669-88822641eb6f",
   "2d2db3e8-dc93-4d9e-bf7d-04d7e69c0224",
   "239fdcf2-8cd2-45c3-90ce-a6b28235b1ef",
   "9918ddf7-3925-431d-bc4d-a8d60c80fd90",
   "287f74da-115c-40f8-915c-0923794089ec",
   "86ea1217-bd03-43e9-b06d-93f7fe6aa4db",
   "ebae3ba8-e7c0-42cc-a54c-2f8df7ba47f6",
   "02b154b8-ace2-445c-bbf9-46bee54ff4f8"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
