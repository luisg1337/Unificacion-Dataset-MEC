{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6586356-9ad7-487f-ba29-c8960e737711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar un archivo CSV en un DataFrame\n",
    "df1 = pd.read_csv('registros_titulos.csv',low_memory=False)\n",
    "df2 = pd.read_csv('catastro_carreras_20241009.csv',low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f1771-14f9-4b20-a669-88822641eb6f",
   "metadata": {
    "panel-layout": {
     "height": 60.59375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Función para imprimir los shape de todos los df en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbcc7455-fb30-4d56-90e4-2eefb0709e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_df_shapes():\n",
    "    # Obtener todos los nombres de los DataFrames en memoria\n",
    "    df_names = [name for name in globals() if isinstance(globals()[name], pd.DataFrame)]\n",
    "\n",
    "    # Iterar sobre los nombres de los DataFrames y imprimir su shape\n",
    "    for name in df_names:\n",
    "        df = globals()[name]\n",
    "        print(f\"Shape del DataFrame {name}: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2db3e8-dc93-4d9e-bf7d-04d7e69c0224",
   "metadata": {
    "panel-layout": {
     "height": 60.59375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Función para imprimir los valores únicos de todos los df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be1bca1-c0e3-4dff-b7f1-2baac8f79bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_unique_values():\n",
    "    # Obtener todos los nombres de los DataFrames en memoria\n",
    "    df_names = [name for name in globals() if isinstance(globals()[name], pd.DataFrame)]\n",
    "\n",
    "    # Iterar sobre los nombres de los DataFrames y imprimir los valores únicos de cada columna\n",
    "    for name in df_names:\n",
    "        df = globals()[name]\n",
    "        unique_counts = df.nunique()\n",
    "        print(f\"Valores únicos del DataFrame {name}:\")\n",
    "        print(unique_counts)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239fdcf2-8cd2-45c3-90ce-a6b28235b1ef",
   "metadata": {
    "panel-layout": {
     "height": 60.59375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Función de limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8147163a-24b8-43a4-bbbd-904cc0d1c793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\gimen\\anaconda3\\envs\\pruebas\\lib\\site-packages (1.3.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63409166-00b9-4264-b089-9c39ca267659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import re\n",
    "\n",
    "# Función para limpiar y estandarizar los nombres\n",
    "def clean_and_standardize(name):\n",
    "    if isinstance(name, str):\n",
    "        # Eliminar espacios en blanco al inicio y al final\n",
    "        name = name.strip()\n",
    "        # Convertir a minúsculas\n",
    "        name = name.lower()\n",
    "        # Eliminar acentos\n",
    "        name = unidecode.unidecode(name)\n",
    "        # Eliminar comillas simples, dobles, guiones, barras, puntos, dos puntos, paréntesis y comas\n",
    "        \n",
    "        name = re.sub(r\"['\\\":(),.-]\", \"\", name)\n",
    "\n",
    "\n",
    "        # Eliminar dobles espacios en el medio de los nombres\n",
    "        name = re.sub(r'\\s+', ' ', name)\n",
    "    return name\n",
    "# Diccionario ampliado de abreviaturas comunes en el contexto educativo\n",
    "ABREVIATURAS = {\n",
    "    \"dr\": \"doctor\",\n",
    "    \"dra\": \"doctora\",\n",
    "    \"gral\": \"general\",\n",
    "    \"cnel\": \"coronel\",\n",
    "    \"tte\": \"teniente\",\n",
    "    \"tec\": \"tecnico\",\n",
    "    \"mcal\": \"mariscal\",\n",
    "    \"educ\": \"educacion\",\n",
    "    \"inst\": \"instituto\",\n",
    "    \"nac\": \"nacional\",\n",
    "    \"dir\": \"direccion\",\n",
    "    \"prof\": \"profesor\",\n",
    "    \"priv\": \"privado\",\n",
    "    \"reg\": \"regional\",\n",
    "    \"univ\": \"universidad\",\n",
    "    \"esc\": \"escuela\",\n",
    "    \"adm\": \"administracion\",\n",
    "    # Agrega más términos según las necesidades específicas del dataset\n",
    "}\n",
    "\n",
    "def expand_abbreviations(name):\n",
    "    # Reemplazo de abreviaturas por sus equivalentes completos\n",
    "    for abbr, full in ABREVIATURAS.items():\n",
    "        name = re.sub(rf\"\\b{abbr}\\b\", full, name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918ddf7-3925-431d-bc4d-a8d60c80fd90",
   "metadata": {
    "panel-layout": {
     "height": 60.59375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Aplicar limpieza a todos los campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "287f74da-115c-40f8-915c-0923794089ec",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valores únicos antes de la limpieza\n",
      "Valores únicos del DataFrame df1:\n",
      "anio                       13\n",
      "mes                        12\n",
      "documento              407403\n",
      "nombre_completo        406752\n",
      "carrera_id               1752\n",
      "carrera                  1751\n",
      "titulo_id                 701\n",
      "titulo                    692\n",
      "numero_resolucion       87612\n",
      "fecha_resolucion         2711\n",
      "tipo_institucion_id         5\n",
      "tipo_institucion            5\n",
      "institucion_id            474\n",
      "institucion               452\n",
      "gobierno_actual             2\n",
      "sexo                        2\n",
      "dtype: int64\n",
      "\n",
      "Valores únicos del DataFrame df2:\n",
      "nombre_institucion                  442\n",
      "codigo_institucion                  448\n",
      "tipo_institucion                      5\n",
      "tipo_gestion                          3\n",
      "codigo_departamento                  18\n",
      "departamento                         18\n",
      "codigo_distrito                      29\n",
      "distrito                            179\n",
      "codigo_establecimiento             1208\n",
      "establecimiento                    1174\n",
      "carrera_institucion_id            27359\n",
      "codigo_oferta                      1537\n",
      "codigo_carrera                     2833\n",
      "denominacion_carrera               2833\n",
      "denominacion_titulo                1071\n",
      "nivel_titulacion                     12\n",
      "enfasis_id                          232\n",
      "enfasis_carrera                     232\n",
      "modalidad_asistencia                  4\n",
      "clasificacion_campo_detallado        70\n",
      "clasificacion_campo_especifico       27\n",
      "clasificacion_campo_amplio           11\n",
      "activa                                2\n",
      "dtype: int64\n",
      "\n",
      "valores únicos después de la limpieza\n",
      "Valores únicos del DataFrame df1:\n",
      "anio                       13\n",
      "mes                        12\n",
      "documento              406360\n",
      "nombre_completo        405670\n",
      "carrera_id               1752\n",
      "carrera                  1698\n",
      "titulo_id                 701\n",
      "titulo                    662\n",
      "numero_resolucion       87612\n",
      "fecha_resolucion         2711\n",
      "tipo_institucion_id         5\n",
      "tipo_institucion            5\n",
      "institucion_id            474\n",
      "institucion               389\n",
      "gobierno_actual             2\n",
      "sexo                        2\n",
      "dtype: int64\n",
      "\n",
      "Valores únicos del DataFrame df2:\n",
      "nombre_institucion                  427\n",
      "codigo_institucion                  448\n",
      "tipo_institucion                      5\n",
      "tipo_gestion                          3\n",
      "codigo_departamento                  18\n",
      "departamento                         18\n",
      "codigo_distrito                      29\n",
      "distrito                            179\n",
      "codigo_establecimiento             1208\n",
      "establecimiento                    1159\n",
      "carrera_institucion_id            27359\n",
      "codigo_oferta                      1537\n",
      "codigo_carrera                     2833\n",
      "denominacion_carrera               2742\n",
      "denominacion_titulo                1006\n",
      "nivel_titulacion                     12\n",
      "enfasis_id                          232\n",
      "enfasis_carrera                     232\n",
      "modalidad_asistencia                  4\n",
      "clasificacion_campo_detallado        70\n",
      "clasificacion_campo_especifico       27\n",
      "clasificacion_campo_amplio           11\n",
      "activa                                2\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"valores únicos antes de la limpieza\")\n",
    "print_unique_values()\n",
    "\n",
    "# Aplicar la función de limpieza a todos los valores de df1\n",
    "tqdm.pandas(desc=\"Limpiando df1\")\n",
    "df1 = df1.map(clean_and_standardize)\n",
    "\n",
    "# Expandir abreviaturas solo en columnas de tipo string\n",
    "tqdm.pandas(desc=\"expandiendo abreviaturas en df1\")\n",
    "df1[df1.select_dtypes(include=\"object\").columns] = df1.select_dtypes(include=\"object\").map(\n",
    "    lambda x: expand_abbreviations(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Aplicar la función de limpieza a todos los valores de df2\n",
    "tqdm.pandas(desc=\"Limpiando df2\")\n",
    "df2 = df2.map(clean_and_standardize)\n",
    "\n",
    "# Expandir abreviaturas solo en columnas de tipo string\n",
    "tqdm.pandas(desc=\"expandiendo abreviaturas en df2\")\n",
    "df2[df2.select_dtypes(include=\"object\").columns] = df2.select_dtypes(include=\"object\").map(\n",
    "    lambda x: expand_abbreviations(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "print(\"valores únicos después de la limpieza\")\n",
    "print_unique_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f20193-298b-438f-b24a-b7a708e7e603",
   "metadata": {},
   "source": [
    "# MAYUSCULAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16edcc5a-f779-4bd4-8c12-4672c335db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gimen\\AppData\\Local\\Temp\\ipykernel_1904\\1068132255.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df1 = df1.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anio  mes documento                    nombre_completo  carrera_id  \\\n",
      "0  2012   12   4385636         AIDA LUZ MARTINEZ MARTINEZ         287   \n",
      "1  2012   12   3624681  CRISTINA ELIZABETH GAONA GONZALEZ         111   \n",
      "2  2012   12   2537752         LILIEN RAQUEL PRIETO ARMOA         111   \n",
      "3  2012   12   1843924  LOURDES ISABEL ZEBALLOS DE SURIAN          43   \n",
      "4  2012   12   1417764             MIRTA ELIZABETH CUENCA         111   \n",
      "\n",
      "                                 carrera  titulo_id        titulo  \\\n",
      "0  EDUCACION BILINGUE CASTELLANO GUARANI        791    PROFESOR/A   \n",
      "1                             ENFERMERIA        792  LICENCIADO/A   \n",
      "2                             ENFERMERIA        792  LICENCIADO/A   \n",
      "3         CIENCIAS CONTABLES Y AUDITORIA        792  LICENCIADO/A   \n",
      "4                             ENFERMERIA        792  LICENCIADO/A   \n",
      "\n",
      "  numero_resolucion fecha_resolucion  tipo_institucion_id    tipo_institucion  \\\n",
      "0              1792         20121228                   17  INSTITUTO SUPERIOR   \n",
      "1              1719         20121220                   16         UNIVERSIDAD   \n",
      "2              1689         20121218                   16         UNIVERSIDAD   \n",
      "3              1739         20121221                   16         UNIVERSIDAD   \n",
      "4              1772         20121227                   17  INSTITUTO SUPERIOR   \n",
      "\n",
      "   institucion_id                                        institucion  \\\n",
      "0         1102311  INSTITUTO SUPERIOR EN CIENCIAS LINGUISTICAS ID...   \n",
      "1         1101861                       UNIVERSIDAD AUTONOMA DEL SUR   \n",
      "2         1101714  UNIVERSIDAD CATOLICA NUESTRA SENORA DE LA ASUN...   \n",
      "3          991607                     UNIVERSIDAD PRIVADA DEL GUAIRA   \n",
      "4         1102522            INSTITUTO SUPERIOR PROFESIONAL AVANZADO   \n",
      "\n",
      "  gobierno_actual   sexo  \n",
      "0              NO  MUJER  \n",
      "1              NO  MUJER  \n",
      "2              NO  MUJER  \n",
      "3              NO  MUJER  \n",
      "4              NO  MUJER  \n",
      "                                  nombre_institucion codigo_institucion  \\\n",
      "0             INSTITUTO TECNICO SUPERIOR DEL ROSARIO            *326333   \n",
      "1          INSTITUTO TECNICO SUPERIOR DE AERONAUTICA            *319210   \n",
      "2  INSTITUTO DE FORMACION DOCENTE NUESTRA SENORA ...            *319186   \n",
      "3                                UNIVERSIDAD DEL SOL            *316825   \n",
      "4                   UNIVERSIDAD NACIONAL DE ASUNCION            *316794   \n",
      "\n",
      "                 tipo_institucion tipo_gestion  codigo_departamento  \\\n",
      "0      INSTITUTO TECNICO SUPERIOR      PRIVADO                    7   \n",
      "1      INSTITUTO TECNICO SUPERIOR      OFICIAL                   11   \n",
      "2  INSTITUTO DE FORMACION DOCENTE      OFICIAL                    0   \n",
      "3                     UNIVERSIDAD      PRIVADO                    0   \n",
      "4                     UNIVERSIDAD      OFICIAL                   11   \n",
      "\n",
      "  departamento  codigo_distrito     distrito codigo_establecimiento  \\\n",
      "0       ITAPUA             17.0     OBLIGADO                *235201   \n",
      "1      CENTRAL              9.0        LUQUE                *227025   \n",
      "2      CAPITAL              0.0     ASUNCION                *227001   \n",
      "3      CAPITAL              0.0     ASUNCION                *210069   \n",
      "4      CENTRAL             14.0  SAN LORENZO                *231355   \n",
      "\n",
      "                                     establecimiento  ...  \\\n",
      "0             INSTITUTO TECNICO SUPERIOR DEL ROSARIO  ...   \n",
      "1          INSTITUTO TECNICO SUPERIOR DE AERONAUTICA  ...   \n",
      "2  INSTITUTO DE FORMACION DOCENTE NUESTRA SENORA ...  ...   \n",
      "3                       UNIVERSIDAD DEL SOL ASUNCION  ...   \n",
      "4             UNIVERSIDAD NACIONAL DE ASUNCION FACEN  ...   \n",
      "\n",
      "                     denominacion_carrera  \\\n",
      "0                            AGRONEGOCIOS   \n",
      "1    INTERPRETE DE INSTRUMENTOS MUSICALES   \n",
      "2        PROFESORADO EN EDUCACION INICIAL   \n",
      "3          DOCENCIA EN EDUCACION SUPERIOR   \n",
      "4  CIENCIAS FISICAS DE LA RADIOPROTECCION   \n",
      "\n",
      "                                 denominacion_titulo  \\\n",
      "0                   TECNICO SUPERIOR EN AGRONEGOCIOS   \n",
      "1  TECNICO SUPERIOR EN INTERPRETE DE INSTRUMENTOS...   \n",
      "2                      PROFESOR DE EDUCACION INICIAL   \n",
      "3                                       ESPECIALISTA   \n",
      "4                                           MAGISTER   \n",
      "\n",
      "                                    nivel_titulacion enfasis_id  \\\n",
      "0  EDUCACION DE PREGRADO EDUCACION TECNICA SUPERI...        NaN   \n",
      "1  EDUCACION DE PREGRADO EDUCACION TECNICA SUPERI...        NaN   \n",
      "2    EDUCACION DE PREGRADO FORMACION DOCENTE INICIAL        NaN   \n",
      "3              EDUCACION DE POSGRADO ESPECIALIZACION        NaN   \n",
      "4                     EDUCACION DE POSGRADO MAESTRIA        NaN   \n",
      "\n",
      "  enfasis_carrera modalidad_asistencia   clasificacion_campo_detallado  \\\n",
      "0             NaN           PRESENCIAL  PRODUCCION AGRICOLA Y GANADERA   \n",
      "1             NaN           PRESENCIAL        MUSICA Y ARTES ESCENICAS   \n",
      "2             NaN                  NaN                             NaN   \n",
      "3             NaN           PRESENCIAL        CIENCIAS DE LA EDUCACION   \n",
      "4             NaN           PRESENCIAL                          FISICA   \n",
      "\n",
      "  clasificacion_campo_especifico  \\\n",
      "0                    AGRICULTURA   \n",
      "1                          ARTES   \n",
      "2                            NaN   \n",
      "3                      EDUCACION   \n",
      "4               CIENCIAS FISICAS   \n",
      "\n",
      "                     clasificacion_campo_amplio activa  \n",
      "0  AGRICULTURA SILVICULTURA PESCA Y VETERINARIA     SI  \n",
      "1                           ARTES Y HUMANIDADES     SI  \n",
      "2                                           NaN     NO  \n",
      "3                                     EDUCACION     SI  \n",
      "4  CIENCIAS NATURALES MATEMATICAS Y ESTADISTICA     SI  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gimen\\AppData\\Local\\Temp\\ipykernel_1904\\1068132255.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df2 = df2.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Convertir todos los textos a mayúsculas en df1 y df2\n",
    "df1 = df1.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "df2 = df2.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "\n",
    "# Ahora, revisa si se han convertido correctamente\n",
    "print(df1.head())\n",
    "print(df2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea1217-bd03-43e9-b06d-93f7fe6aa4db",
   "metadata": {
    "panel-layout": {
     "height": 60.59375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Trabajar con valores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e18eef0-518e-4894-b26e-21e6874af422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos exportados: 'unique_institutions_df1.xlsx' y 'unique_institutions_df2.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Obtener valores únicos y ordenados alfabéticamente de las columnas de instituciones en ambos DataFrames\n",
    "unique_institutions_df1 = pd.DataFrame(sorted(df1['institucion'].unique()), columns=['institucion'])\n",
    "unique_institutions_df2 = pd.DataFrame(sorted(df2['nombre_institucion'].unique()), columns=['nombre_institucion'])\n",
    "\n",
    "# Exportar a archivos Excel\n",
    "unique_institutions_df1.to_excel(\"unique_institutions_df1.xlsx\", index=False)\n",
    "unique_institutions_df2.to_excel(\"unique_institutions_df2.xlsx\", index=False)\n",
    "\n",
    "print(\"Archivos exportados: 'unique_institutions_df1.xlsx' y 'unique_institutions_df2.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f84e88be-6ffe-41de-9fa4-d36817fbb4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "\n",
    "# Configuración de coincidencia aproximada con umbral de similitud\n",
    "similarity_threshold = 90  # Nivel de similitud; puedes ajustar este valor según los resultados\n",
    "\n",
    "# Encontrar coincidencias aproximadas\n",
    "def find_fuzzy_matches(df1, df2, col1, col2, threshold):\n",
    "    matches = []\n",
    "    for name in df1[col1]:\n",
    "        match = process.extractOne(name, df2[col2], scorer=fuzz.ratio)\n",
    "        if match and match[1] >= threshold:\n",
    "            matches.append((name, match[0]))\n",
    "        else:\n",
    "            matches.append((name, \"#N/D\"))\n",
    "    return matches\n",
    "\n",
    "# DataFrames con coincidencias\n",
    "coincidencias_df1 = pd.DataFrame(find_fuzzy_matches(unique_institutions_df1, unique_institutions_df2, 'institucion', 'nombre_institucion', similarity_threshold), columns=['institucion', 'coincidencia_en_nombre'])\n",
    "coincidencias_df2 = pd.DataFrame(find_fuzzy_matches(unique_institutions_df2, unique_institutions_df1, 'nombre_institucion', 'institucion', similarity_threshold), columns=['nombre_institucion', 'coincidencia_en_institucion'])\n",
    "\n",
    "# Exportar resultados a Excel\n",
    "coincidencias_df1.to_excel('coincidencias_df1.xlsx', index=False)\n",
    "coincidencias_df2.to_excel('coincidencias_df2.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebae3ba8-e7c0-42cc-a54c-2f8df7ba47f6",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame df1: (553407, 16)\n",
      "Shape del DataFrame df2: (27394, 23)\n",
      "Shape del DataFrame unique_institutions_df1: (389, 1)\n",
      "Shape del DataFrame unique_institutions_df2: (427, 1)\n",
      "Shape del DataFrame coincidencias_df1: (389, 2)\n",
      "Shape del DataFrame coincidencias_df2: (427, 2)\n"
     ]
    }
   ],
   "source": [
    "print_df_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "365175fa-f6da-43e8-a19f-7adba1ed0d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparando instituciones...: 100%|██████████| 389/389 [00:03<00:00, 123.23it/s]\n",
      "Comparando instituciones...: 100%|██████████| 427/427 [00:03<00:00, 128.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos exportados: 'coincidencias_complejas_df1.xlsx' y 'coincidencias_complejas_df2.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unidecode\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Umbral de similitud (ajústalo según los resultados que obtengas)\n",
    "similarity_threshold = 85  \n",
    "\n",
    "# Función para realizar coincidencias complejas con columna de nombre unificado\n",
    "def complex_fuzzy_matching(df1, df2, col1, col2, threshold):\n",
    "    matches = []\n",
    "    for name in tqdm(df1[col1], desc=\"Comparando instituciones...\"):\n",
    "        # Encuentra la coincidencia más cercana en el otro DataFrame usando `token_set_ratio` y `partial_ratio`\n",
    "        match = process.extractOne(name, df2[col2], scorer=fuzz.token_set_ratio)\n",
    "        \n",
    "        if match and match[1] >= threshold:\n",
    "            refined_score = fuzz.partial_ratio(name, match[0])\n",
    "            # Asegúrate de que ambas puntuaciones cumplan el umbral o alguna esté cerca\n",
    "            if refined_score >= threshold or (refined_score + match[1]) / 2 >= threshold:\n",
    "                unified_name = match[0]  # Aquí puedes decidir qué nombre usar como unificado\n",
    "                matches.append((name, match[0], unified_name))  # Añade la tercera columna con el nombre unificado\n",
    "            else:\n",
    "                matches.append((name, \"#N/D\", \"#N/D\"))  # No alcanzó el umbral refinado\n",
    "        else:\n",
    "            matches.append((name, \"#N/D\", \"#N/D\"))  # No alcanzó ningún umbral\n",
    "\n",
    "    return matches\n",
    "\n",
    "# Aplica la función y guarda los resultados en DataFrames\n",
    "coincidencias_df1 = pd.DataFrame(\n",
    "    complex_fuzzy_matching(unique_institutions_df1, unique_institutions_df2, 'institucion', 'nombre_institucion', similarity_threshold),\n",
    "    columns=['institucion', 'coincidencia_en_nombre', 'nombre_unificado']\n",
    ")\n",
    "\n",
    "coincidencias_df2 = pd.DataFrame(\n",
    "    complex_fuzzy_matching(unique_institutions_df2, unique_institutions_df1, 'nombre_institucion', 'institucion', similarity_threshold),\n",
    "    columns=['nombre_institucion', 'coincidencia_en_institucion', 'nombre_unificado']\n",
    ")\n",
    "\n",
    "# Exporta los resultados a Excel\n",
    "coincidencias_df1.to_excel('coincidencias_complejas_df1.xlsx', index=False)\n",
    "coincidencias_df2.to_excel('coincidencias_complejas_df2.xlsx', index=False)\n",
    "\n",
    "print(\"Archivos exportados: 'coincidencias_complejas_df1.xlsx' y 'coincidencias_complejas_df2.xlsx'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41743e76-c48a-4204-8e3d-28d0fe24d6d9",
   "metadata": {},
   "source": [
    "# Reemplazando en ambos dataset por nombre unificado de institucion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69458665-65e0-41f8-9d3c-13d74304db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Merge de los nombres unificados en df1\n",
    "df1 = df1.merge(coincidencias_df1[['institucion', 'nombre_unificado']], on='institucion', how='left')\n",
    "\n",
    "# Reemplaza los nombres en df1 por el nombre unificado, pero sólo si no es #N/D y no es NaN\n",
    "df1['institucion'] = df1.apply(lambda x: x['nombre_unificado'] if pd.notna(x['nombre_unificado']) and x['nombre_unificado'] != '#N/D' else x['institucion'], axis=1)\n",
    "\n",
    "# Elimina la columna 'nombre_unificado' de df1 si ya no es necesaria\n",
    "df1 = df1.drop(columns=['nombre_unificado'])\n",
    "\n",
    "# Merge de los nombres unificados en df2 (utilizando 'coincidencia_en_nombre' para buscar)\n",
    "df2 = df2.merge(coincidencias_df1[['coincidencia_en_nombre', 'nombre_unificado']], \n",
    "                left_on='nombre_institucion', right_on='coincidencia_en_nombre', how='left')\n",
    "\n",
    "# Reemplaza los nombres en df2 por el nombre unificado, pero sólo si no es #N/D y no es NaN\n",
    "df2['nombre_institucion'] = df2.apply(lambda x: x['nombre_unificado'] if pd.notna(x['nombre_unificado']) and x['nombre_unificado'] != '#N/D' else x['nombre_institucion'], axis=1)\n",
    "\n",
    "# Elimina las columnas innecesarias ('nombre_unificado' y 'coincidencia_en_nombre')\n",
    "df2 = df2.drop(columns=['nombre_unificado', 'coincidencia_en_nombre'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316b744-9309-41c3-b532-d47ae9fad547",
   "metadata": {},
   "source": [
    "# TIPO DE INSTITUCION LIMPIEZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "b71e5ea6-bbe1-4bbb-8296-74789eecb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para corregir los tipos de institución según el nombre\n",
    "def corregir_tipo_institucion(nombre, tipo_actual):\n",
    "    # Asegurarse de que el nombre es una cadena de texto\n",
    "    if isinstance(nombre, str):\n",
    "        nombre = nombre.upper()\n",
    "    else:\n",
    "        nombre = \"\"  # Convertir NaN o valores no string en cadena vacía\n",
    "\n",
    "    # Caso especial: INSTITUTO DE FORMACION TECNICA SUPERIOR INFORTES\n",
    "    if 'INSTITUTO DE FORMACION TECNICA SUPERIOR INFORTES DEPENDIENTE DE LA UNIVERSIDAD EVANGELICA DEL PARAGUAY' in nombre:\n",
    "        return 'INSTITUTO TECNICO SUPERIOR'  # Devolver el tipo correcto\n",
    "        \n",
    "    if 'INSTITUTO PEDAGOGICO NIHON GAKKO' in nombre:\n",
    "        return 'INSTITUTO DE FORMACION DOCENTE'\n",
    "    # Lista de posibles tipos de institución en orden de prioridad\n",
    "    tipos_institucion = [\n",
    "        ('INSTITUTO TECNICO SUPERIOR', 'INSTITUTO TECNICO SUPERIOR'),\n",
    "        ('INSTITUTO SUPERIOR', 'INSTITUTO SUPERIOR'),\n",
    "        ('INSTITUTO DE FORMACION DOCENTE', 'INSTITUTO DE FORMACION DOCENTE'),\n",
    "        ('CENTRO REGIONAL DE EDUCACION', 'CENTRO REGIONAL DE EDUCACION'),\n",
    "        ('UNIVERSIDAD', 'UNIVERSIDAD')\n",
    "    ]\n",
    "\n",
    "    # Verificar la primera coincidencia en el nombre\n",
    "    for tipo, keyword in tipos_institucion:\n",
    "        if keyword in nombre:\n",
    "            return tipo  # Devolver el tipo de institución basado en la primera coincidencia\n",
    "\n",
    "    # Si no hay coincidencias, devolver el tipo actual\n",
    "    return tipo_actual\n",
    "\n",
    "# Aplicar la corrección en df1\n",
    "df1['tipo_institucion_corregido'] = df1.apply(lambda x: corregir_tipo_institucion(x['institucion'], x['tipo_institucion']), axis=1)\n",
    "\n",
    "# Aplicar la corrección en df2\n",
    "df2['tipo_institucion_corregido'] = df2.apply(lambda x: corregir_tipo_institucion(x['nombre_institucion'], x['tipo_institucion']), axis=1)\n",
    "\n",
    "# Reemplazar las columnas originales si todo es correcto\n",
    "df1['tipo_institucion'] = df1['tipo_institucion_corregido']\n",
    "df2['tipo_institucion'] = df2['tipo_institucion_corregido']\n",
    "\n",
    "# Eliminar las columnas temporales\n",
    "df1.drop(columns=['tipo_institucion_corregido'], inplace=True)\n",
    "df2.drop(columns=['tipo_institucion_corregido'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f19981-4d41-46ea-81ac-d51bbab00d98",
   "metadata": {},
   "source": [
    "# DUPLICADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "acd4c5dd-c726-41d6-989a-83fe6105aafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de df1 antes de eliminar duplicados: (553407, 16)\n",
      "Shape de df2 antes de eliminar duplicados: (27394, 23)\n",
      "Shape de df1 después de eliminar duplicados: (553407, 16)\n",
      "Shape de df2 después de eliminar duplicados: (27394, 23)\n"
     ]
    }
   ],
   "source": [
    "# Ver el shape de df1 y df2 antes de eliminar duplicados\n",
    "print(\"Shape de df1 antes de eliminar duplicados:\", df1.shape)\n",
    "print(\"Shape de df2 antes de eliminar duplicados:\", df2.shape)\n",
    "\n",
    "# Eliminar duplicados en df1 y df2\n",
    "df1=df1.drop_duplicates()\n",
    "df2=df2.drop_duplicates()\n",
    "\n",
    "# Ver el shape de df1 y df2 después de eliminar duplicados\n",
    "print(\"Shape de df1 después de eliminar duplicados:\", df1.shape)\n",
    "print(\"Shape de df2 después de eliminar duplicados:\", df2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f71706-cd63-4565-9471-f2b3a500b864",
   "metadata": {},
   "source": [
    "# TITULOS DOCUMENTOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb72f9fd-ee8d-4646-af51-10100241e5eb",
   "metadata": {},
   "source": [
    "## Cantidad de documentos con más de un nombre asociado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "2c65f553-05dd-42b0-8fb7-0a935f78cadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de documentos con más de un nombre asociado después de la limpieza: 395\n",
      "\n",
      "Documentos con más de un nombre asociado después de la limpieza y cantidad de nombres diferentes:\n",
      "documento\n",
      "0                 3\n",
      "000570415LA034    2\n",
      "0030296990        2\n",
      "0201442612        2\n",
      "040916181         2\n",
      "                 ..\n",
      "908330            2\n",
      "91017020275       2\n",
      "951929            2\n",
      "979516            2\n",
      "994421            2\n",
      "Name: nombre_completo, Length: 395, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df=df1\n",
    "# Agrupar por 'documento' y contar la cantidad de nombres únicos asociados a cada documento después de la limpieza\n",
    "conteo_nombres_por_documento_despues = df.groupby('documento')['nombre_completo'].nunique()\n",
    "\n",
    "# Filtrar los documentos que tienen más de un nombre asociado después de la limpieza\n",
    "documentos_con_mas_de_un_nombre_despues = conteo_nombres_por_documento_despues[conteo_nombres_por_documento_despues > 1]\n",
    "\n",
    "# Mostrar la cantidad de documentos con más de un nombre asociado después de la limpieza\n",
    "cantidad_documentos_con_mas_de_un_nombre_despues = len(documentos_con_mas_de_un_nombre_despues)\n",
    "print(\"Cantidad de documentos con más de un nombre asociado después de la limpieza:\", cantidad_documentos_con_mas_de_un_nombre_despues)\n",
    "\n",
    "# Mostrar la lista de documentos con más de un nombre asociado después de la limpieza y la cantidad de nombres diferentes para cada uno\n",
    "print(\"\\nDocumentos con más de un nombre asociado después de la limpieza y cantidad de nombres diferentes:\")\n",
    "print(documentos_con_mas_de_un_nombre_despues)\n",
    "\n",
    "# Obtener los nombres asociados a cada documento con más de un nombre después de la limpieza\n",
    "nombres_por_documento_despues = df[df['documento'].isin(documentos_con_mas_de_un_nombre_despues.index)][['documento', 'nombre_completo']]\n",
    "\n",
    "# Exportar la lista de documentos con más de un nombre asociado después de la limpieza y los nombres asociados a un archivo Excel\n",
    "nombres_por_documento_despues.to_excel(\"nombres_por_documento_despues.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa722e1-ae57-4496-83a2-3968aa81cbc7",
   "metadata": {},
   "source": [
    "## Listar nombres de documentos con mas de un nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "1a452243-e10b-435b-abd8-8cf23979faa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombres únicos asociados a cada documento con más de un nombre después de la limpieza:\n",
      "             documento                      nombre_completo\n",
      "13024                0                    ERON PAULO FAVERO\n",
      "153711               0                 YDALINA SMITH COLMAN\n",
      "17562                0               KARINA BEATRIZ ESTECHE\n",
      "360171  000570415LA034           FRANSISCO GASPAR FERNANDES\n",
      "322172  000570415LA034           FRANCISCO GASPAR FERNANDES\n",
      "...                ...                                  ...\n",
      "532080          951929               RAVILLA ALVES DA SILVA\n",
      "228943          979516  FAUSTO NIELSEN VILLALBA BARRIOCANAL\n",
      "11153           979516           MARELISA RODRIGUES VILARGA\n",
      "73027           994421         WALTER ENRIQUE RAMIREZ ROJAS\n",
      "384720          994421            WAGNER RODRIGUES DA SILVA\n",
      "\n",
      "[792 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Obtener los nombres únicos asociados a cada documento con más de un nombre después de la limpieza y ordenar por documento\n",
    "nombres_unicos_por_documento_despues = nombres_por_documento_despues.drop_duplicates().sort_values(by='documento')\n",
    "\n",
    "# Mostrar los nombres únicos asociados a cada documento con más de un nombre después de la limpieza\n",
    "print(\"Nombres únicos asociados a cada documento con más de un nombre después de la limpieza:\")\n",
    "print(nombres_unicos_por_documento_despues)\n",
    "\n",
    "# Exportar los nombres únicos asociados a cada documento con más de un nombre a un archivo Excel, ordenado por documento\n",
    "nombres_unicos_por_documento_despues.to_excel(\"nombres_unicos_por_documento_despues.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0c1c66-6ae9-4bc9-80d3-e5a4e3e29592",
   "metadata": {},
   "source": [
    "## Detectar similitudes entre los nombres con el mismo documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "a919178d-0ed3-4791-985a-9e00bf215d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clasificacion\n",
      "distintas personas    282\n",
      "misma persona         117\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documento</th>\n",
       "      <th>nombre1</th>\n",
       "      <th>nombre2</th>\n",
       "      <th>clasificacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ERON PAULO FAVERO</td>\n",
       "      <td>YDALINA SMITH COLMAN</td>\n",
       "      <td>distintas personas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ERON PAULO FAVERO</td>\n",
       "      <td>KARINA BEATRIZ ESTECHE</td>\n",
       "      <td>distintas personas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>YDALINA SMITH COLMAN</td>\n",
       "      <td>KARINA BEATRIZ ESTECHE</td>\n",
       "      <td>distintas personas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000570415LA034</td>\n",
       "      <td>FRANSISCO GASPAR FERNANDES</td>\n",
       "      <td>FRANCISCO GASPAR FERNANDES</td>\n",
       "      <td>misma persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0030296990</td>\n",
       "      <td>CELSO LUIS SOARES POTSCH</td>\n",
       "      <td>CELSO LUIS SOARES POTSH</td>\n",
       "      <td>misma persona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        documento                     nombre1                     nombre2  \\\n",
       "0               0           ERON PAULO FAVERO        YDALINA SMITH COLMAN   \n",
       "1               0           ERON PAULO FAVERO      KARINA BEATRIZ ESTECHE   \n",
       "2               0        YDALINA SMITH COLMAN      KARINA BEATRIZ ESTECHE   \n",
       "3  000570415LA034  FRANSISCO GASPAR FERNANDES  FRANCISCO GASPAR FERNANDES   \n",
       "4      0030296990    CELSO LUIS SOARES POTSCH     CELSO LUIS SOARES POTSH   \n",
       "\n",
       "        clasificacion  \n",
       "0  distintas personas  \n",
       "1  distintas personas  \n",
       "2  distintas personas  \n",
       "3       misma persona  \n",
       "4       misma persona  "
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "\n",
    "# Cargar el dataframe\n",
    "dfx = nombres_unicos_por_documento_despues\n",
    "\n",
    "\n",
    "# Función para calcular la similitud de Levenshtein\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# Función para clasificar nombres\n",
    "def classify_names(group):\n",
    "    results = []\n",
    "    names = group['nombre_completo'].tolist()\n",
    "    for i in range(len(names)):\n",
    "        for j in range(i + 1, len(names)):\n",
    "            similarity = similar(names[i], names[j])\n",
    "            if similarity > 0.8:  # Umbral de similitud\n",
    "                results.append((group['documento'].iloc[0], names[i], names[j], 'misma persona'))\n",
    "            else:\n",
    "                results.append((group['documento'].iloc[0], names[i], names[j], 'distintas personas'))\n",
    "    return results\n",
    "\n",
    "# Aplicar la función a grupos de documentos\n",
    "results = []\n",
    "grouped = dfx.groupby('documento')\n",
    "for name, group in grouped:\n",
    "    if len(group) > 1:\n",
    "        results.extend(classify_names(group))\n",
    "\n",
    "# Convertir los resultados en un DataFrame\n",
    "result_df = pd.DataFrame(results, columns=['documento', 'nombre1', 'nombre2', 'clasificacion'])\n",
    "\n",
    "# Guardar los resultados en un archivo Excel\n",
    "result_df.to_excel('nombres_clasificados.xlsx', index=False)\n",
    "\n",
    "# Imprimir la cantidad de clasificaciones por tipo\n",
    "print(result_df['clasificacion'].value_counts())\n",
    "\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd795f-6a22-4f7f-90c0-95957209ebd1",
   "metadata": {},
   "source": [
    "## Unificar datos para tener una lista de personas iguales o distintos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "bd91313d-086f-4939-8727-ddaf42c3696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          documento                      nombre_completo       clasificacion\n",
      "0                 0                    ERON PAULO FAVERO  distintas personas\n",
      "1                 0                 YDALINA SMITH COLMAN  distintas personas\n",
      "2                 0               KARINA BEATRIZ ESTECHE  distintas personas\n",
      "3    000570415LA034           FRANSISCO GASPAR FERNANDES       misma persona\n",
      "4    000570415LA034           FRANCISCO GASPAR FERNANDES       misma persona\n",
      "..              ...                                  ...                 ...\n",
      "787          951929               RAVILLA ALVES DA SILVA  distintas personas\n",
      "788          979516  FAUSTO NIELSEN VILLALBA BARRIOCANAL  distintas personas\n",
      "789          979516           MARELISA RODRIGUES VILARGA  distintas personas\n",
      "790          994421         WALTER ENRIQUE RAMIREZ ROJAS  distintas personas\n",
      "791          994421            WAGNER RODRIGUES DA SILVA  distintas personas\n",
      "\n",
      "[792 rows x 3 columns]\n",
      "Archivo exportado a 'nombres_unicos_con_clasificacion.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que los dataframes ya están cargados como nombres_unicos_por_documento_despues y result_df\n",
    "\n",
    "# Crear una lista para almacenar los diccionarios\n",
    "aux_list = []\n",
    "\n",
    "for index, row in result_df.iterrows():\n",
    "    aux_list.append({'documento': row['documento'], 'nombre_completo': row['nombre1'], 'clasificacion': row['clasificacion']})\n",
    "    aux_list.append({'documento': row['documento'], 'nombre_completo': row['nombre2'], 'clasificacion': row['clasificacion']})\n",
    "\n",
    "# Convertir la lista en un dataframe\n",
    "aux_df = pd.DataFrame(aux_list)\n",
    "\n",
    "# Eliminar duplicados\n",
    "aux_df = aux_df.drop_duplicates()\n",
    "\n",
    "# Unir nombres_unicos_por_documento_despues con aux_df para agregar la columna de clasificación\n",
    "merged_df = nombres_unicos_por_documento_despues.merge(aux_df, how='left', left_on=['documento', 'nombre_completo'], right_on=['documento', 'nombre_completo'])\n",
    "\n",
    "# Verificar el resultado\n",
    "print(merged_df)\n",
    "\n",
    "# Guardar el resultado en un archivo de Excel\n",
    "merged_df.to_excel('nombres_unicos_con_clasificacion.xlsx', index=False)\n",
    "print(\"Archivo exportado a 'nombres_unicos_con_clasificacion.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329c8f7f-8a2e-4100-8011-fc951e8ba731",
   "metadata": {},
   "source": [
    "## Crear id para documentos con mas de un nombre asociado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "68879e57-502e-4c83-b8c9-e60deecf5c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          documento                      nombre_completo       clasificacion  \\\n",
      "0                 0                    ERON PAULO FAVERO  distintas personas   \n",
      "1                 0                 YDALINA SMITH COLMAN  distintas personas   \n",
      "2                 0               KARINA BEATRIZ ESTECHE  distintas personas   \n",
      "3    000570415LA034           FRANSISCO GASPAR FERNANDES       misma persona   \n",
      "4    000570415LA034           FRANCISCO GASPAR FERNANDES       misma persona   \n",
      "..              ...                                  ...                 ...   \n",
      "787          951929               RAVILLA ALVES DA SILVA  distintas personas   \n",
      "788          979516  FAUSTO NIELSEN VILLALBA BARRIOCANAL  distintas personas   \n",
      "789          979516           MARELISA RODRIGUES VILARGA  distintas personas   \n",
      "790          994421         WALTER ENRIQUE RAMIREZ ROJAS  distintas personas   \n",
      "791          994421            WAGNER RODRIGUES DA SILVA  distintas personas   \n",
      "\n",
      "                 id  \n",
      "0               0_1  \n",
      "1               0_2  \n",
      "2               0_3  \n",
      "3    000570415LA034  \n",
      "4    000570415LA034  \n",
      "..              ...  \n",
      "787        951929_2  \n",
      "788        979516_1  \n",
      "789        979516_2  \n",
      "790        994421_1  \n",
      "791        994421_2  \n",
      "\n",
      "[792 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Diccionario para contar ocurrencias por documento\n",
    "counter = {}\n",
    "\n",
    "# Función para generar el ID según la clasificación\n",
    "def generar_id(row):\n",
    "    documento = row['documento']\n",
    "    clasificacion = row['clasificacion']\n",
    "\n",
    "    if clasificacion == 'distintas personas':\n",
    "        if documento not in counter:\n",
    "            counter[documento] = 1\n",
    "        else:\n",
    "            counter[documento] += 1\n",
    "        return f\"{documento}_{counter[documento]}\"\n",
    "    else:\n",
    "        return documento\n",
    "\n",
    "# Aplicar la función para generar la columna 'id'\n",
    "merged_df['id'] = merged_df.apply(generar_id, axis=1)\n",
    "\n",
    "# Mostrar el dataframe resultante\n",
    "print(merged_df)\n",
    "merged_df.to_excel('documentos_duplicados_con_id.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6327e2f-cb6b-4ce9-9c2b-c4a7f73c8e94",
   "metadata": {},
   "source": [
    "## Agregar el nuevo campo persona_id a todo el dataset, ordenar y exportar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "5900ecd5-31aa-42ea-bdd4-b7920aba1580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1500.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(553407, 17)\n",
      "df exportado a CSV en un solo archivo\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configurar tqdm para que funcione con pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Crear un backup del DataFrame original\n",
    "df_backup = df1.copy()\n",
    "\n",
    "# Hacer un merge entre df y merged_df basado en 'documento' y 'nombre_completo'\n",
    "df_titulos_v2 = pd.merge(df1, merged_df[['documento', 'nombre_completo', 'id']].progress_apply(lambda x: x), on=['documento', 'nombre_completo'], how='left')\n",
    "\n",
    "# Crear la columna 'persona_id' basada en las condiciones especificadas\n",
    "df_titulos_v2['persona_id'] = df_titulos_v2['id'].combine_first(df_titulos_v2['documento'])\n",
    "\n",
    "# Eliminar la columna 'id' ya que no la necesitamos en el DataFrame final\n",
    "df_titulos_v2 = df_titulos_v2.drop(columns=['id'])\n",
    "\n",
    "# Ordenar el DataFrame por 'documento' y 'persona_id'\n",
    "df_titulos_v2 = df_titulos_v2.sort_values(by=['documento', 'persona_id'])\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_titulos_v2.shape)\n",
    "\n",
    "# Exportar todo el DataFrame a un solo archivo CSV\n",
    "df_titulos_v2.to_csv('df_titulos_v2.csv', index=False)\n",
    "\n",
    "print('df exportado a CSV en un solo archivo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16541156-2a7d-4da1-a8a2-3b90a1f08762",
   "metadata": {},
   "source": [
    "# Fragmentando dataset para facilitar trabajar sobre secciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "14cf0897-955d-4daa-aee8-a7c7c4828f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gimen\\AppData\\Local\\Temp\\ipykernel_1904\\1272164197.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  carreras.rename(columns={\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos exportados según tipo de institución.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Función para limpiar las variantes de ciclos y espacios dobles\n",
    "def limpiar_ciclos(texto):\n",
    "    if isinstance(texto, str):  # Asegurarse de que el texto sea una cadena\n",
    "        # Reemplazar variantes de \"TERCER CICLO\"\n",
    "        texto = re.sub(r'\\b(3(O|0)?|TERCERO|TERCER|3(DEG)?|30)\\s*CICLO(S)?\\b', 'TERCER CICLO', texto, flags=re.IGNORECASE)\n",
    "\n",
    "        # Reemplazar variantes de \"SEGUNDO CICLO\"\n",
    "        texto = re.sub(r'\\b(2(O|0)?|SEGUNDO|2(DEG)?|20)\\s*CICLO(S)?\\b', 'SEGUNDO CICLO', texto, flags=re.IGNORECASE)\n",
    "\n",
    "        # Reemplazar variantes de \"PRIMER CICLO\"\n",
    "        texto = re.sub(r'\\b(1(O|0)?|PRIMERO|PRIMER|1(DEG)?|10)\\s*CICLO(S)?\\b', 'PRIMER CICLO', texto, flags=re.IGNORECASE)\n",
    "\n",
    "        # Eliminar espacios dobles\n",
    "        texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "\n",
    "    return texto\n",
    "    \n",
    "# Filtrar las columnas necesarias de df1 y df2\n",
    "titulos = df_titulos_v2[['anio', 'mes', 'documento', 'persona_id', 'nombre_completo', 'tipo_institucion', 'institucion', 'carrera', 'titulo', 'sexo']]\n",
    "carreras = df2[['tipo_institucion', 'nombre_institucion', 'denominacion_carrera', 'denominacion_titulo', 'tipo_gestion', 'nivel_titulacion', 'clasificacion_campo_amplio']]\n",
    "\n",
    "carreras.rename(columns={\n",
    "    'nombre_institucion': 'institucion',\n",
    "    'denominacion_carrera': 'carrera',\n",
    "    'denominacion_titulo': 'titulo'\n",
    "}, inplace=True)\n",
    "\n",
    "# Aplicar la función de limpieza a las columnas 'carrera' y 'titulo' en ambos DataFrames\n",
    "titulos.loc[:, 'carrera'] = titulos['carrera'].apply(limpiar_ciclos)\n",
    "titulos.loc[:, 'titulo'] = titulos['titulo'].apply(limpiar_ciclos)\n",
    "carreras.loc[:, 'carrera'] = carreras['carrera'].apply(limpiar_ciclos)\n",
    "carreras.loc[:, 'titulo'] = carreras['titulo'].apply(limpiar_ciclos)\n",
    "# Diccionario para los tipos de institución y sus siglas\n",
    "tipo_institucion_siglas = {\n",
    "    'CENTRO REGIONAL DE EDUCACION': 'CRE',\n",
    "    'INSTITUTO DE FORMACION DOCENTE': 'IFD',\n",
    "    'INSTITUTO SUPERIOR': 'IS',\n",
    "    'INSTITUTO TECNICO SUPERIOR': 'ITS',\n",
    "    'UNIVERSIDAD': 'U'\n",
    "}\n",
    "\n",
    "# Dividir titulos en fragmentos según el tipo de institución\n",
    "for tipo, sigla in tipo_institucion_siglas.items():\n",
    "    fragmento = titulos[titulos['tipo_institucion'] == tipo]\n",
    "    fragmento.to_excel(f'titulos_{sigla}.xlsx', index=False)\n",
    "\n",
    "# Dividir carreras en fragmentos según el tipo de institución\n",
    "for tipo, sigla in tipo_institucion_siglas.items():\n",
    "    fragmento = carreras[carreras['tipo_institucion'] == tipo]\n",
    "    fragmento.to_excel(f'carreras_{sigla}.xlsx', index=False)\n",
    "\n",
    "print(\"Archivos exportados según tipo de institución.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a185d8-ba42-4bec-9ea0-b60ff7349b1d",
   "metadata": {},
   "source": [
    "# CARGAR DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "dd0747d4-f39f-4eb6-8c55-ff93f1668e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Títulos CRE shape: (14479, 10)\n",
      "Títulos IFD shape: (52869, 10)\n",
      "Títulos IS shape: (72944, 10)\n",
      "Títulos ITS shape: (32722, 10)\n",
      "Títulos U shape: (380393, 10)\n",
      "Carreras CRE shape: (1526, 7)\n",
      "Carreras IFD shape: (8659, 7)\n",
      "Carreras IS shape: (1721, 7)\n",
      "Carreras ITS shape: (5595, 7)\n",
      "Carreras U shape: (9893, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los archivos Excel que contienen los DataFrames por tipo de institución\n",
    "titulos_cre = pd.read_excel('titulos_CRE.xlsx')\n",
    "titulos_ifd = pd.read_excel('titulos_IFD.xlsx')\n",
    "titulos_is = pd.read_excel('titulos_IS.xlsx')\n",
    "titulos_its = pd.read_excel('titulos_ITS.xlsx')\n",
    "titulos_u = pd.read_excel('titulos_U.xlsx')\n",
    "\n",
    "carreras_cre = pd.read_excel('carreras_CRE.xlsx')\n",
    "carreras_ifd = pd.read_excel('carreras_IFD.xlsx')\n",
    "carreras_is = pd.read_excel('carreras_IS.xlsx')\n",
    "carreras_its = pd.read_excel('carreras_ITS.xlsx')\n",
    "carreras_u = pd.read_excel('carreras_U.xlsx')\n",
    "\n",
    "# Verificar la carga de los DataFrames\n",
    "print(\"Títulos CRE shape:\", titulos_cre.shape)\n",
    "print(\"Títulos IFD shape:\", titulos_ifd.shape)\n",
    "print(\"Títulos IS shape:\", titulos_is.shape)\n",
    "print(\"Títulos ITS shape:\", titulos_its.shape)\n",
    "print(\"Títulos U shape:\", titulos_u.shape)\n",
    "\n",
    "print(\"Carreras CRE shape:\", carreras_cre.shape)\n",
    "print(\"Carreras IFD shape:\", carreras_ifd.shape)\n",
    "print(\"Carreras IS shape:\", carreras_is.shape)\n",
    "print(\"Carreras ITS shape:\", carreras_its.shape)\n",
    "print(\"Carreras U shape:\", carreras_u.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a41b2-ff07-4c42-b279-f1a554d8c190",
   "metadata": {},
   "source": [
    "# CENTRO REGIONAL DE EDUCACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "ac66f3f9-fae1-4e0b-bfb8-5ee44cf6f222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcciones realizadas en titulos_cre:\n",
      "['CENTRO REGIONAL DE EDUCACION SATURIO RIOS'\n",
      " 'CENTRO REGIONAL DE EDUCACION GENERAL PATRICIO ESCOBAR'\n",
      " 'CENTRO REGIONAL DE EDUCACION DOCTOR JOSE GASPAR RODRIGUEZ DE FRANCIA'\n",
      " 'CENTRO REGIONAL DE EDUCACION DRRAUL PENA'\n",
      " 'CENTRO REGIONAL DE EDUCACION NATALICIO TALAVERA'\n",
      " 'CENTRO REGIONAL DE EDUCACION JUAN E OLEARY'\n",
      " 'CENTRO REGIONAL DE EDUCACION MARISCAL FRANCISCO SOLANO LOPEZ'\n",
      " 'CENTRO REGIONAL DE EDUCACION DOCTOR RAUL PENA']\n",
      "\n",
      "Correcciones realizadas en carreras_cre:\n",
      "['CENTRO REGIONAL DE EDUCACION SATURIO RIOS'\n",
      " 'CENTRO REGIONAL DE EDUCACION DOCTOR JOSE GASPAR RODRIGUEZ DE FRANCIA'\n",
      " 'CENTRO REGIONAL DE EDUCACION DRRAUL PENA'\n",
      " 'CENTRO REGIONAL DE EDUCACION NATALICIO TALAVERA'\n",
      " 'CENTRO REGIONAL DE EDUCACION GENERAL PATRICIO ESCOBAR'\n",
      " 'CENTRO REGIONAL DE EDUCACION JUAN E OLEARY'\n",
      " 'CENTRO REGIONAL DE EDUCACION MARISCAL FRANCISCO SOLANO LOPEZ'\n",
      " 'CENTRO REGIONAL DE EDUCACION GENERAL PATRICIO ESCOBAR DE ENCARNACION'\n",
      " 'CENTRO REGIONAL DE EDUCACION DOCTOR RAUL PENA DE PEDRO JUAN CABALLERO'\n",
      " 'CENTRO REGIONAL DE EDUCACION DOCTOR RAUL PENA']\n"
     ]
    }
   ],
   "source": [
    "print(\"Correcciones realizadas en titulos_cre:\")\n",
    "print(titulos_cre['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n",
    "print(\"\\nCorrecciones realizadas en carreras_cre:\")\n",
    "print(carreras_cre['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415ac25-b959-48bb-9798-ad72fa6fd80a",
   "metadata": {},
   "source": [
    "# instituciones que solo estan en un lugar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "8e71efa7-563d-4b1f-b626-d55f6443c2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instituciones que están solo en titulos_cre:\n",
      "set()\n",
      "\n",
      "Instituciones que están solo en carreras_cre:\n",
      "{'CENTRO REGIONAL DE EDUCACION GENERAL PATRICIO ESCOBAR DE ENCARNACION', 'CENTRO REGIONAL DE EDUCACION DOCTOR RAUL PENA DE PEDRO JUAN CABALLERO'}\n"
     ]
    }
   ],
   "source": [
    "# Valores únicos en 'titulos_cre'\n",
    "instituciones_titulos = set(titulos_cre['institucion'].unique())\n",
    "\n",
    "# Valores únicos en 'carreras_cre'\n",
    "instituciones_carreras = set(carreras_cre['institucion'].unique())\n",
    "\n",
    "# Instituciones que están en 'titulos_cre' pero no en 'carreras_cre'\n",
    "solo_en_titulos = instituciones_titulos - instituciones_carreras\n",
    "print(\"Instituciones que están solo en titulos_cre:\")\n",
    "print(solo_en_titulos)\n",
    "\n",
    "# Instituciones que están en 'carreras_cre' pero no en 'titulos_cre'\n",
    "solo_en_carreras = instituciones_carreras - instituciones_titulos\n",
    "print(\"\\nInstituciones que están solo en carreras_cre:\")\n",
    "print(solo_en_carreras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2975929-d2a3-4eae-8a68-f0d1d528f1fa",
   "metadata": {},
   "source": [
    "# limpieza de inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "9bdd49e7-c472-418a-9156-0b49a91af7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instituciones corregidas en titulos_cre:\n",
      "['CENTRO REGIONAL DE EDUCACION SATURIO RIOS'\n",
      " 'CENTRO REGIONAL DE EDUCACION GENERAL PATRICIO ESCOBAR'\n",
      " 'CENTRO REGIONAL DE EDUCACION DOCTOR JOSE GASPAR RODRIGUEZ DE FRANCIA'\n",
      " 'CENTRO REGIONAL DE EDUCACION DOCTOR RAUL PENA'\n",
      " 'CENTRO REGIONAL DE EDUCACION NATALICIO TALAVERA'\n",
      " 'CENTRO REGIONAL DE EDUCACION JUAN E OLEARY'\n",
      " 'CENTRO REGIONAL DE EDUCACION MARISCAL FRANCISCO SOLANO LOPEZ']\n",
      "\n",
      "Instituciones corregidas en carreras_cre:\n",
      "['CENTRO REGIONAL DE EDUCACION SATURIO RIOS'\n",
      " 'CENTRO REGIONAL DE EDUCACION DOCTOR JOSE GASPAR RODRIGUEZ DE FRANCIA'\n",
      " 'CENTRO REGIONAL DE EDUCACION DOCTOR RAUL PENA'\n",
      " 'CENTRO REGIONAL DE EDUCACION NATALICIO TALAVERA'\n",
      " 'CENTRO REGIONAL DE EDUCACION GENERAL PATRICIO ESCOBAR'\n",
      " 'CENTRO REGIONAL DE EDUCACION JUAN E OLEARY'\n",
      " 'CENTRO REGIONAL DE EDUCACION MARISCAL FRANCISCO SOLANO LOPEZ']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Función para limpiar nombres específicos\n",
    "def limpiar_instituciones(nombre, es_carreras=False):\n",
    "    nombre = nombre.upper()\n",
    "    \n",
    "    # Correcciones generales para ambos datasets\n",
    "    if \"DRRAUL PENA\" in nombre:\n",
    "        nombre = nombre.replace(\"DRRAUL PENA\", \"DOCTOR RAUL PENA\")\n",
    "    \n",
    "    # Correcciones específicas para carreras_cre\n",
    "    if es_carreras:\n",
    "        if \"GENERAL PATRICIO ESCOBAR DE ENCARNACION\" in nombre:\n",
    "            nombre = nombre.replace(\"GENERAL PATRICIO ESCOBAR DE ENCARNACION\", \"GENERAL PATRICIO ESCOBAR\")\n",
    "        if \"DOCTOR RAUL PENA DE PEDRO JUAN CABALLERO\" in nombre:\n",
    "            nombre = nombre.replace(\"DOCTOR RAUL PENA DE PEDRO JUAN CABALLERO\", \"DOCTOR RAUL PENA\")\n",
    "    \n",
    "    return nombre\n",
    "\n",
    "# Aplicar la limpieza en ambos datasets\n",
    "titulos_cre['institucion'] = titulos_cre['institucion'].apply(limpiar_instituciones)\n",
    "carreras_cre['institucion'] = carreras_cre['institucion'].apply(lambda x: limpiar_instituciones(x, es_carreras=True))\n",
    "# Limpiar el nombre de la carrera reemplazando solo la parte específica\n",
    "carreras_cre['carrera'] = carreras_cre['carrera'].replace(\n",
    "    'PROFESIONALIZADONANEMOARANDUKE',\n",
    "    'PROFESIONALIZADO',\n",
    "    regex=True  # Esto permite la búsqueda con expresiones regulares\n",
    ")\n",
    "# Limpiar el nombre de la carrera reemplazando solo la parte específica\n",
    "titulos_cre['carrera'] = titulos_cre['carrera'].replace(\n",
    "    'PROFESIONALIZADONANEMOARANDUKE',\n",
    "    'PROFESIONALIZADO',\n",
    "    regex=True  # Esto permite la búsqueda con expresiones regulares\n",
    ")\n",
    "# Mostrar las instituciones corregidas\n",
    "print(\"Instituciones corregidas en titulos_cre:\")\n",
    "print(titulos_cre['institucion'].unique())\n",
    "\n",
    "print(\"\\nInstituciones corregidas en carreras_cre:\")\n",
    "print(carreras_cre['institucion'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0659b8a9-8129-4bf9-aea8-b326460953b4",
   "metadata": {},
   "source": [
    "# verificar valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "c639b760-71ff-4285-8e0a-3d2cd04c8b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en titulos_cre:\n",
      "anio                 0\n",
      "mes                  0\n",
      "documento            0\n",
      "persona_id           0\n",
      "nombre_completo      0\n",
      "tipo_institucion     0\n",
      "institucion          0\n",
      "carrera              0\n",
      "titulo               0\n",
      "sexo                22\n",
      "dtype: int64\n",
      "\n",
      "Valores nulos en carreras_cre:\n",
      "tipo_institucion                 0\n",
      "institucion                      0\n",
      "carrera                          0\n",
      "titulo                           0\n",
      "tipo_gestion                     2\n",
      "nivel_titulacion                 0\n",
      "clasificacion_campo_amplio    1317\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar valores nulos en cada columna de titulos_cre\n",
    "print(\"Valores nulos en titulos_cre:\")\n",
    "print(titulos_cre.isnull().sum())\n",
    "\n",
    "# Contar valores nulos en cada columna de carreras_cre\n",
    "print(\"\\nValores nulos en carreras_cre:\")\n",
    "print(carreras_cre.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44b9d9-5599-4b8e-91fc-3fa17a1a2e9d",
   "metadata": {},
   "source": [
    "# campos vacios en carreras cre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340dcc2-98b9-4341-b711-6523aa75c3be",
   "metadata": {},
   "source": [
    "# clasificacion de campo amplio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "9c11b6dc-df19-43a7-a3cb-06667dc2a0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores vacíos por columna antes de completar:\n",
      "tipo_institucion                 0\n",
      "institucion                      0\n",
      "carrera                          0\n",
      "titulo                           0\n",
      "tipo_gestion                     2\n",
      "nivel_titulacion                 0\n",
      "clasificacion_campo_amplio    1317\n",
      "dtype: int64\n",
      "\n",
      "Total de valores vacíos por columna después de completar:\n",
      "tipo_institucion              0\n",
      "institucion                   0\n",
      "carrera                       0\n",
      "titulo                        0\n",
      "tipo_gestion                  2\n",
      "nivel_titulacion              0\n",
      "clasificacion_campo_amplio    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar los valores vacíos (NaN) en cada columna\n",
    "valores_vacios = carreras_cre.isna().sum()\n",
    "\n",
    "# Mostrar el total de valores vacíos por columna antes de completar\n",
    "print(\"Total de valores vacíos por columna antes de completar:\")\n",
    "print(valores_vacios)\n",
    "\n",
    "# Llenar los campos vacíos en clasificacion_campo_amplio con 'EDUCACION'\n",
    "carreras_cre['clasificacion_campo_amplio'] = carreras_cre['clasificacion_campo_amplio'].fillna('EDUCACION')\n",
    "\n",
    "# Volver a contar los valores vacíos después de la operación\n",
    "valores_vacios_actualizados = carreras_cre.isna().sum()\n",
    "\n",
    "# Mostrar el total de valores vacíos por columna después de completar\n",
    "print(\"\\nTotal de valores vacíos por columna después de completar:\")\n",
    "print(valores_vacios_actualizados)\n",
    "\n",
    "# Exportar el dataframe resultante a un archivo Excel\n",
    "carreras_cre.to_excel('carreras_cre_actualizado.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72637656-8b76-4261-a3eb-7b75625f3b46",
   "metadata": {},
   "source": [
    "# tipo de gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "4386e3e4-362f-428d-b295-1260b16d97a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gimen\\AppData\\Local\\Temp\\ipykernel_1904\\2004155564.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  carreras_cre = carreras_cre.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar el tipo de gestión más frecuente para cada institución\n",
    "def completar_tipo_gestion(grupo):\n",
    "    if grupo['tipo_gestion'].isnull().all():\n",
    "        return grupo\n",
    "    # Obtener el tipo de gestión más frecuente (eliminando los nulos) \n",
    "    tipo_frecuente = grupo['tipo_gestion'].dropna().mode()[0]\n",
    "    # Rellenar los valores nulos con el tipo de gestión más frecuente\n",
    "    grupo['tipo_gestion'] = grupo['tipo_gestion'].fillna(tipo_frecuente)\n",
    "    return grupo\n",
    "\n",
    "# Aplicar la función a cada grupo de instituciones sin convertirlo en índice\n",
    "carreras_cre = carreras_cre.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n",
    "\n",
    "# Guardar el resultado en un archivo Excel\n",
    "carreras_cre.to_excel('carreras_cre_actualizado.xlsx', index=False)\n",
    "\n",
    "# Verificar si aún hay valores nulos en la columna 'tipo_gestion'\n",
    "print(carreras_cre['tipo_gestion'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59614006-3e0b-4ba8-ab8d-49dfa56fc094",
   "metadata": {},
   "source": [
    "# unificacion carreras y titulos cre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "c45d81ca-80d4-4211-8d2d-40ca7228472e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas left_only: 985\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_cre_copy = titulos_cre.copy()\n",
    "carreras_cre_copy = carreras_cre.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_cre_copy = titulos_cre_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_cre_copy = carreras_cre_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_cre_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_cre_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_CRE.xlsx', index=False)\n",
    "carreras_cre_copy = carreras_cre_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_cre_copy = carreras_cre_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943840c8-27a9-4bc6-91e9-ce2a07e85bd6",
   "metadata": {},
   "source": [
    "## LIMPIANDO INCONSISTENCIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "75a07a88-8c3c-42d9-b15a-482b9ebf83dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: 'unificacion_left_only_cre.xlsx'\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "# Función para extraer la parte posterior a 'AREA'\n",
    "def extract_after_area(text):\n",
    "  \n",
    "    if 'AREA' in text:\n",
    "        return text.split('AREA', 1)[-1].strip()  # Extraer lo que sigue después de 'AREA'\n",
    "    return None  # Si no tiene 'AREA', devolver None\n",
    "\n",
    "# Función de coincidencia difusa optimizada\n",
    "def fuzzy_unify(row, carreras_cre, threshold=75):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    carreras_cre_filtered = carreras_cre[\n",
    "        (carreras_cre['institucion_carrera'] == row['institucion']) &\n",
    "        (carreras_cre['tipo_institucion'] == row['tipo_institucion'])\n",
    "    ]\n",
    "\n",
    "    row['carrera_carreras'] = None\n",
    "    row['titulo_carrera'] = None\n",
    "    row['institucion_carrera'] = None\n",
    "\n",
    "    for _, carrera_row in carreras_cre_filtered.iterrows():\n",
    "        # Extraer partes después de 'AREA'\n",
    "        area_row_1 = extract_after_area(row['carrera'])\n",
    "        area_row_2 = extract_after_area(carrera_row['carrera_carreras'])\n",
    "\n",
    "        if area_row_1 and area_row_2:  # Ambas tienen 'AREA'\n",
    "            area_score = fuzz.ratio(area_row_1, area_row_2)\n",
    "            if area_score < 70:  # Si la parte después de 'AREA' no es similar\n",
    "                avg_score = 60  # Asignar un puntaje bajo\n",
    "            else:\n",
    "                carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "                titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "                avg_score = (carrera_score + titulo_score) / 2\n",
    "        elif area_row_1 or area_row_2:  # Solo una de las partes tiene 'AREA'\n",
    "            avg_score = 60  # Puntaje bajo\n",
    "        else:\n",
    "            carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "            titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "            avg_score = (carrera_score + titulo_score) / 2\n",
    "\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_match = carrera_row\n",
    "\n",
    "    if best_score >= threshold and best_match is not None:\n",
    "        row['carrera_unificada'] = best_match['carrera_carreras']\n",
    "        row['titulo_unificado'] = best_match['titulo_carrera']\n",
    "        row['institucion_unificada'] = best_match['institucion_carrera']\n",
    "        row['carrera_carreras'] = best_match['carrera_carreras']\n",
    "        row['titulo_carrera'] = best_match['titulo_carrera']\n",
    "        row['institucion_carrera'] = best_match['institucion_carrera']\n",
    "    else:\n",
    "        row['carrera_unificada'] = row['carrera']\n",
    "        row['titulo_unificado'] = row['titulo_titulos']\n",
    "        row['institucion_unificada'] = row['institucion']\n",
    "\n",
    "    row['similarity_score'] = best_score\n",
    "    return row\n",
    "\n",
    "# Aplicar la coincidencia difusa\n",
    "left_only_unified = left_only.apply(fuzzy_unify, args=(carreras_cre_copy,), axis=1)\n",
    "left_only_unified = left_only_unified[[\n",
    "    'carrera',\n",
    "    'carrera_carreras',\n",
    "    'carrera_unificada', \n",
    "    'titulo_titulos', # Cambiado de posición\n",
    "    'titulo_carrera',\n",
    "    'titulo_unificado',\n",
    "    'institucion', \n",
    "    'institucion_carrera',\n",
    "    'institucion_unificada',\n",
    "    'similarity_score'\n",
    "]]\n",
    "# Exportar a un archivo Excel\n",
    "left_only_unified.to_excel('unificacion_left_only_cre.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'unificacion_left_only_cre.xlsx'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf3b7a9-a7cb-44ad-b2f6-000edaafdef7",
   "metadata": {},
   "source": [
    "# Reemplazando campos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "449ce61e-9f86-4b02-a7b5-75601fda6d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: 'titulos_cre_actualizado.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Filtrar las filas de left_only_unified con un puntaje mayor o igual a 90\n",
    "left_only_unified_filtered = left_only_unified[left_only_unified['similarity_score'] >= 90]\n",
    "\n",
    "# Paso 2: Reemplazar los valores en titulos_cre\n",
    "for _, row in left_only_unified_filtered.iterrows():\n",
    "    # Buscar coincidencias en titulos_cre\n",
    "    condition = (\n",
    "        (titulos_cre['carrera'] == row['carrera']) &\n",
    "        (titulos_cre['titulo'] == row['titulo_titulos']) &\n",
    "        (titulos_cre['institucion'] == row['institucion'])\n",
    "    )\n",
    "    \n",
    "    # Reemplazar los valores en titulos_cre si hay coincidencias\n",
    "    titulos_cre.loc[condition, 'carrera'] = row['carrera_unificada']\n",
    "    titulos_cre.loc[condition, 'titulo'] = row['titulo_unificado']\n",
    "\n",
    "# Puedes guardar el DataFrame actualizado en un archivo Excel o CSV si lo deseas\n",
    "titulos_cre.to_excel('titulos_cre_actualizado.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'titulos_cre_actualizado.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c85bf0-c164-403a-b36f-254e543d0864",
   "metadata": {},
   "source": [
    "# Segunda revision #OPCIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "ec1e3c6b-d8f6-490c-a56d-1e39437c68ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas left_only: 148\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_cre_copy = titulos_cre.copy()\n",
    "carreras_cre_copy = carreras_cre.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_cre_copy = titulos_cre_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_cre_copy = carreras_cre_copy.rename(columns={'titulo': 'titulo_carreras'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_cre_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_cre_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carreras']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carreras'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_CRE.xlsx', index=False)\n",
    "\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f03541-1140-4628-9c84-644d088a3a0f",
   "metadata": {},
   "source": [
    "## UNIFICACION FINAL CRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "554fb5e1-dd47-48bf-8675-20bce4de9d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame TITULOS V2: (14479, 10)\n",
      "Shape del DataFrame final: (14479, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Eliminar duplicados en las columnas clave de carreras\n",
    "df_merged_unique = carreras_cre.drop_duplicates(\n",
    "    subset=['carrera', 'institucion', 'tipo_institucion', 'titulo']\n",
    ")\n",
    "\n",
    "# Paso 2: Realizar el merge con las combinaciones únicas\n",
    "merged_final_CRE = pd.merge(\n",
    "    titulos_cre, \n",
    "    df_merged_unique, \n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    how='left'  # Aquí cambiamos a 'left' para mantener todas las filas de df_titulos_v2_limpio_CRE\n",
    ")\n",
    "\n",
    "# Paso 2: Guardar el DataFrame en un archivo Excel\n",
    "merged_final_CRE.to_excel('CRE_FINAL.xlsx', index=False)\n",
    "# Imprimir la forma y los encabezados de df_titulos_v2_limpio_CRE\n",
    "print(\"Shape del DataFrame TITULOS V2:\", titulos_cre.shape)\n",
    "\n",
    "\n",
    "# Imprimir la forma y los encabezados del DataFrame final\n",
    "print(\"Shape del DataFrame final:\", merged_final_CRE.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d1b7c4-6254-4550-9ea0-6c72f632383d",
   "metadata": {},
   "source": [
    "# INSTITUTO DE FORMACION DOCENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "b3f8282f-7ec4-4027-9eb1-374e99257a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcciones realizadas en titulos_ifd:\n",
      "['INSTITUTO DE FORMACION DOCENTE SANTA CLARA'\n",
      " 'INSTITUTO DE LINGUISTICA GUARANI DEL PARAGUAY PROFESOR DOCTOR REINALDO JULIAN DECOUD LARROSA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PRIVADO SAN JOSE OBRERO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE CPTAN AGUSTIN FERNANDO DE PINEDO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE EL MAESTRO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE NUESTRA SENORA DE LA ASUNCION'\n",
      " 'INSTITUTO DE FORMACION DOCENTE NUESTRA SENORA STELLA MARYS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SANTA TERESITA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE NATALICIO TALAVERA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE YUTY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE SAN JOSE DE LOS ARROYOS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE SAN ESTANISLAO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE EUSEBIO AYALA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE VILLA HAYES'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE HORQUETA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE NUESTRA SENORA DE ALTAGRACIA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE MARISCAL JOSE FELIX ESTIGARRIBIA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE PARAGUARI'\n",
      " 'INSTITUTO DE FORMACION DOCENTE INTERREGIONAL'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE CORONEL OVIEDO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE MAESTRO FERMIN LOPEZ'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SANTO TOMAS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE CAAGUAZU'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE SAN IGNACIO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE JUAN ALBERTO BARRETO VILLALBA DE CURUGUATY'\n",
      " 'ATENEO DE LENGUA Y CULTURA GUARANI' 'INSTITUTO DE FORMACION DOCENTE IDT'\n",
      " 'INSTITUTO PEDAGOGICO NIHON GAKKO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE TEKO PORA REKAVO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAN MARTIN DE PORRES'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PROFESORA MERCEDES BAREIRO FRETES'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DORA GIMENEZ'\n",
      " 'INSTITUTO DE FORMACION DOCENTE CENTRO PARAGUAYO DEL SABER'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PROFESORA LADISLAA LILE GONZALEZ'\n",
      " 'INSTITUTO DE FORMACION DOCENTE MEDALLA MILAGROSA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE SANTA ROSA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE ACADEMO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE EL RENUEVO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE AMANECER'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE SAN PEDRO DE YCUAMANDYYU'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE QUIINDY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE LA PAZ'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE CAAZAPA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE CAPITAN MIRANDA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE GENERAL ELIZARDO AQUINO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE YATYTAY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE LIMA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PROFESOR FRANCISCO GAONA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SANTA MATILDE'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAN NICOLAS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DIOCESANO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PRIVADO DE LA CIUDAD DE AYOLAS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE CARAPEGUA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE ASUNCION ESCALADA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAGRADO CORAZON DE JESUS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE MARIA AUXILIADORA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SANTA RITA DEL MONDAY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE INDEPENDENCIA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE ITACURUBI DE LA CORDILLERA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAN ROQUE'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE GENERAL JOSE EDUVIGIS DIAZ'\n",
      " 'INSTITUTO DE FORMACION DOCENTE CAMBRIDGE'\n",
      " 'INSTITUTO DE FORMACION DOCENTE MAURICIO CARDOZO OCAMPO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE JESUS DE NAZARETH'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PARAGUAYO AMERICANO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE UNISOFT SYSTEM'\n",
      " 'INSTITUTO PRIVADO DE FORMACION DOCENTE DE EDUCACION FISICA ALTO PARANA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE LA COLMENA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE ASOCIACION CULTURAL PARAGUAYO BRITANICA ANGLO ENGLISH'\n",
      " 'INSTITUTO DE FORMACION DOCENTE KYREY SASO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE COMPLEJO EDUCATIVO RAMON INDALECIO CARDOZO'\n",
      " 'ESCUELA DE EDUCACION FISICA DE LAS FUERZAS ARMADAS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAN LORENZO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE EUROSUR'\n",
      " 'INSTITUTO DE FORMACION DOCENTE CARLOS RUBEN CACERES BUSCIO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE LAS COLONIAS MENNONITAS DEL PARAGUAY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE LATINOAMERICANO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE VIRGEN DE SCHOENSTATT']\n",
      "\n",
      "Correcciones realizadas en carreras_ifd:\n",
      "['INSTITUTO DE FORMACION DOCENTE NUESTRA SENORA DE LA ASUNCION'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE EUSEBIO AYALA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE CARAPEGUA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE CORONEL OVIEDO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE CARLOS RUBEN CACERES BUSCIO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE CAAZAPA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE GENERAL JOSE EDUVIGIS DIAZ'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DIOCESANO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE TEKO PORA REKAVO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE SAN JOSE DE LOS ARROYOS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PARAGUARI'\n",
      " 'INSTITUTO DE FORMACION DOCENTE MEDALLA MILAGROSA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE GENERAL ELIZARDO AQUINO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SANTA RITA DEL MONDAY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE COMPLEJO EDUCATIVO RAMON INDALECIO CARDOZO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SANTA TERESITA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PRIVADO SAN JOSE OBRERO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE MAESTRO FERMIN LOPEZ'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE CAAGUAZU'\n",
      " 'INSTITUTO DE FORMACION DOCENTE ACADEMO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE ITACURUBI DE LA CORDILLERA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SANTA CLARA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE JUAN ALBERTO BARRETO VILLALBA DE CURUGUATY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SANTA MATILDE'\n",
      " 'INSTITUTO DE FORMACION DOCENTE ASUNCION ESCALADA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PROFESORA MERCEDES BAREIRO FRETES'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE MARIA AUXILIADORA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE NUESTRA SENORA STELLA MARYS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE YUTY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE QUIINDY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE SAN PEDRO DE YCUAMANDYYU'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE SAN IGNACIO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE CPTAN AGUSTIN FERNANDO DE PINEDO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE EL MAESTRO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PROFESOR FRANCISCO GAONA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE KYREY SASO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE SAN ESTANISLAO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE HORQUETA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE SANTA ROSA'\n",
      " 'INSTITUTO PEDAGOGICO NIHON GAKKO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE LIMA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAN JOSE'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE NATALICIO TALAVERA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAGRADO CORAZON DE JESUS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE INTERREGIONAL'\n",
      " 'INSTITUTO DE FORMACION DOCENTE MARISCAL JOSE FELIX ESTIGARRIBIA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SANTO TOMAS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE LAS COLONIAS MENNONITAS DEL PARAGUAY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DORA GIMENEZ'\n",
      " 'DIRECCION DE INNOVACIONES PEDAGOGICAS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAN MARTIN DE PORRES'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE VILLA HAYES'\n",
      " 'INSTITUTO DE FORMACION DOCENTE CENTRO PARAGUAYO DEL SABER'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PARAGUAYO AMERICANO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE YATYTAY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE NUESTRA SENORA DE ALTAGRACIA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAN NICOLAS'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PROFESORA LADISLAA LILE GONZALEZ'\n",
      " 'INSTITUTO DE FORMACION DOCENTE INDEPENDENCIA'\n",
      " 'INSTITUTO DE LINGUISTICA GUARANI DEL PARAGUAY PROFESOR DOCTOR REINALDO JULIAN DECOUD LARROSA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE CAPITAN MIRANDA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE LA PAZ'\n",
      " 'INSTITUTO DE FORMACION DOCENTE UNISOFT SYSTEM'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAN ROQUE'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAN ROQUE GONZALEZ DE SANTA CRUZ'\n",
      " 'INSTITUTO DE FORMACION DOCENTE AMANECER'\n",
      " 'INSTITUTO DE FORMACION DOCENTE EL RENUEVO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE EUROSUR'\n",
      " 'INSTITUTO DE FORMACION DOCENTE LA COLMENA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE VIRGEN DE LA CANDELARIA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE VIRGEN DE SCHOENSTATT'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PARROQUIAL MEDALLA MILAGROSA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE GIMNASIO DEL SABER'\n",
      " 'INSTITUTO DE FORMACION DOCENTE JESUS DE NAZARETH'\n",
      " 'INSTITUTO DE FORMACION DOCENTE DE PARAGUARI'\n",
      " 'ESCUELA DE EDUCACION FISICA DE LAS FUERZAS ARMADAS'\n",
      " 'INSTITUTO DE FORM DOC MARIANO ROQUE ALONSO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE SAN LORENZO'\n",
      " 'INSTITUTO PRIVADO DE FORMACION DOCENTE DE EDUCACION FISICA ALTO PARANA'\n",
      " 'INSTITUTO DE FORMACION DOCENTE ASOCIACION CULTURAL PARAGUAYO BRITANICA ANGLO ENGLISH'\n",
      " 'INSTITUTO DE FORM DOC MONTERREY'\n",
      " 'INSTITUTO DE FORMACION DOCENTE MAURICIO CARDOZO OCAMPO'\n",
      " 'ATENEO DE LENGUA Y CULTURA GUARANI'\n",
      " 'INSTITUTO DE FORMACION DOCENTE LATINOAMERICANO'\n",
      " 'INSTITUTO DE FORMACION DOCENTE IDT'\n",
      " 'INSTITUTO DE FORMACION DOCENTE CAMBRIDGE'\n",
      " 'INSTITUTO DE FORMACION DOCENTE PRIVADO DE LA CIUDAD DE AYOLAS']\n"
     ]
    }
   ],
   "source": [
    "print(\"Correcciones realizadas en titulos_ifd:\")\n",
    "print(titulos_ifd['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n",
    "print(\"\\nCorrecciones realizadas en carreras_ifd:\")\n",
    "print(carreras_ifd['institucion'].unique())  # Imprime los valores únicos para ver las correcciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fe9c5d-2a6b-4c85-8126-6f4ff242c1dc",
   "metadata": {},
   "source": [
    "# INSTITUCIONES QUE SOLO ESTAN EN UN LUGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "1daee299-d18d-42b1-b369-beacb2120902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instituciones que están solo en titulos_ifd:\n",
      "set()\n",
      "\n",
      "Instituciones que están solo en carreras_ifd:\n",
      "{'INSTITUTO DE FORM DOC MARIANO ROQUE ALONSO', 'INSTITUTO DE FORMACION DOCENTE PARAGUARI', 'INSTITUTO DE FORMACION DOCENTE PARROQUIAL MEDALLA MILAGROSA', 'DIRECCION DE INNOVACIONES PEDAGOGICAS', 'INSTITUTO DE FORMACION DOCENTE SAN JOSE', 'INSTITUTO DE FORMACION DOCENTE VIRGEN DE LA CANDELARIA', 'INSTITUTO DE FORMACION DOCENTE GIMNASIO DEL SABER', 'INSTITUTO DE FORM DOC MONTERREY', 'INSTITUTO DE FORMACION DOCENTE SAN ROQUE GONZALEZ DE SANTA CRUZ'}\n"
     ]
    }
   ],
   "source": [
    "# Valores únicos en 'titulos_cre'\n",
    "instituciones_titulos = set(titulos_ifd['institucion'].unique())\n",
    "\n",
    "# Valores únicos en 'carreras_cre'\n",
    "instituciones_carreras = set(carreras_ifd['institucion'].unique())\n",
    "\n",
    "# Instituciones que están en 'titulos_cre' pero no en 'carreras_cre'\n",
    "solo_en_titulos = instituciones_titulos - instituciones_carreras\n",
    "print(\"Instituciones que están solo en titulos_ifd:\")\n",
    "print(solo_en_titulos)\n",
    "\n",
    "# Instituciones que están en 'carreras_cre' pero no en 'titulos_cre'\n",
    "solo_en_carreras = instituciones_carreras - instituciones_titulos\n",
    "print(\"\\nInstituciones que están solo en carreras_ifd:\")\n",
    "print(solo_en_carreras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f2369d-977d-4e30-91fa-33d6a6e86e27",
   "metadata": {},
   "source": [
    "## VERIFICANDO CAMPOS VACIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "99940236-73b0-4bab-9632-98580f498f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en titulos_ifd:\n",
      "anio                  0\n",
      "mes                   0\n",
      "documento             0\n",
      "persona_id            0\n",
      "nombre_completo       0\n",
      "tipo_institucion      0\n",
      "institucion           0\n",
      "carrera               0\n",
      "titulo                0\n",
      "sexo                101\n",
      "dtype: int64\n",
      "\n",
      "Valores nulos en carreras_ifd:\n",
      "tipo_institucion                 0\n",
      "institucion                      0\n",
      "carrera                          0\n",
      "titulo                           0\n",
      "tipo_gestion                     7\n",
      "nivel_titulacion                 0\n",
      "clasificacion_campo_amplio    7281\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar valores nulos en cada columna de titulos_cre\n",
    "print(\"Valores nulos en titulos_ifd:\")\n",
    "print(titulos_ifd.isnull().sum())\n",
    "\n",
    "# Contar valores nulos en cada columna de carreras_cre\n",
    "print(\"\\nValores nulos en carreras_ifd:\")\n",
    "print(carreras_ifd.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37310e26-cb55-4ba9-bc27-888558a8ac12",
   "metadata": {},
   "source": [
    "## campos vacios en ifd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb46c5-f875-4192-ac2b-6565a9dba7aa",
   "metadata": {},
   "source": [
    "### campo amplio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "3bb67311-b7f8-4f2a-9b5c-2bed3b8b368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores vacíos por columna antes de completar:\n",
      "tipo_institucion                 0\n",
      "institucion                      0\n",
      "carrera                          0\n",
      "titulo                           0\n",
      "tipo_gestion                     7\n",
      "nivel_titulacion                 0\n",
      "clasificacion_campo_amplio    7281\n",
      "dtype: int64\n",
      "\n",
      "Total de valores vacíos por columna después de completar:\n",
      "tipo_institucion              0\n",
      "institucion                   0\n",
      "carrera                       0\n",
      "titulo                        0\n",
      "tipo_gestion                  7\n",
      "nivel_titulacion              0\n",
      "clasificacion_campo_amplio    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar los valores vacíos (NaN) en cada columna\n",
    "valores_vacios = carreras_ifd.isna().sum()\n",
    "\n",
    "# Mostrar el total de valores vacíos por columna antes de completar\n",
    "print(\"Total de valores vacíos por columna antes de completar:\")\n",
    "print(valores_vacios)\n",
    "\n",
    "# Llenar los campos vacíos en clasificacion_campo_amplio con 'EDUCACION'\n",
    "carreras_ifd['clasificacion_campo_amplio'] = carreras_ifd['clasificacion_campo_amplio'].fillna('EDUCACION')\n",
    "\n",
    "# Volver a contar los valores vacíos después de la operación\n",
    "valores_vacios_actualizados = carreras_ifd.isna().sum()\n",
    "\n",
    "# Mostrar el total de valores vacíos por columna después de completar\n",
    "print(\"\\nTotal de valores vacíos por columna después de completar:\")\n",
    "print(valores_vacios_actualizados)\n",
    "\n",
    "# Exportar el dataframe resultante a un archivo Excel\n",
    "carreras_ifd.to_excel('carreras_ifd_actualizado.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9bc1fe-958a-44c7-acf2-97d2a1d7d7b8",
   "metadata": {},
   "source": [
    "### tipo de gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "c7ed4fb8-6df2-49e6-abeb-615b14c56e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gimen\\AppData\\Local\\Temp\\ipykernel_1904\\3049459892.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  carreras_ifd = carreras_ifd.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar el tipo de gestión más frecuente para cada institución\n",
    "def completar_tipo_gestion(grupo):\n",
    "    if grupo['tipo_gestion'].isnull().all():\n",
    "        return grupo\n",
    "    # Obtener el tipo de gestión más frecuente (eliminando los nulos) \n",
    "    tipo_frecuente = grupo['tipo_gestion'].dropna().mode()[0]\n",
    "    # Rellenar los valores nulos con el tipo de gestión más frecuente\n",
    "    grupo['tipo_gestion'] = grupo['tipo_gestion'].fillna(tipo_frecuente)\n",
    "    return grupo\n",
    "\n",
    "# Aplicar la función a cada grupo de instituciones sin convertirlo en índice\n",
    "carreras_ifd = carreras_ifd.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n",
    "\n",
    "# Guardar el resultado en un archivo Excel\n",
    "carreras_ifd.to_excel('carreras_ifd_actualizado.xlsx', index=False)\n",
    "\n",
    "# Verificar si aún hay valores nulos en la columna 'tipo_gestion'\n",
    "print(carreras_cre['tipo_gestion'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cfc345-abea-441e-8e78-09147c4749ef",
   "metadata": {},
   "source": [
    "# Verificando inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "750614ae-38a2-4ce4-9c04-591787d39db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas left_only: 5786\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_ifd_copy = titulos_ifd.copy()\n",
    "carreras_ifd_copy = carreras_ifd.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_ifd_copy = titulos_ifd_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_ifd_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_ifd_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_IFD.xlsx', index=False)\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722223b0-2585-47e5-b6a2-5077e12e51fa",
   "metadata": {},
   "source": [
    "## limpiando inconsistencias ifd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "389d21e2-ed9b-47c5-9bbf-58f255fc1104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: 'unificacion_left_only_ifd.xlsx'\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "# Función para extraer la parte posterior a 'AREA'\n",
    "def extract_after_area(text):\n",
    "    if 'AREA' in text:\n",
    "        return text.split('AREA', 1)[-1].strip()  # Extraer lo que sigue después de 'AREA'\n",
    "    return None  # Si no tiene 'AREA', devolver None\n",
    "\n",
    "# Función de coincidencia difusa optimizada\n",
    "def fuzzy_unify(row, carreras_ifd, threshold=75):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    carreras_ifd_filtered = carreras_ifd[\n",
    "        (carreras_ifd['institucion_carrera'] == row['institucion']) &\n",
    "        (carreras_ifd['tipo_institucion'] == row['tipo_institucion'])\n",
    "    ]\n",
    "\n",
    "    row['carrera_carreras'] = None\n",
    "    row['titulo_carrera'] = None\n",
    "    row['institucion_carrera'] = None\n",
    "\n",
    "    for _, carrera_row in carreras_ifd_filtered.iterrows():\n",
    "        # Extraer partes después de 'AREA'\n",
    "        area_row_1 = extract_after_area(row['carrera'])\n",
    "        area_row_2 = extract_after_area(carrera_row['carrera_carreras'])\n",
    "\n",
    "        if area_row_1 and area_row_2:  # Ambas tienen 'AREA'\n",
    "            area_score = fuzz.ratio(area_row_1, area_row_2)\n",
    "            if area_score < 70:  # Si la parte después de 'AREA' no es similar\n",
    "                avg_score = 60  # Asignar un puntaje bajo\n",
    "            else:\n",
    "                carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "                titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "                avg_score = (carrera_score + titulo_score) / 2\n",
    "        elif area_row_1 or area_row_2:  # Solo una de las partes tiene 'AREA'\n",
    "            avg_score = 60  # Puntaje bajo\n",
    "        else:\n",
    "            carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "            titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "            avg_score = (carrera_score + titulo_score) / 2\n",
    "\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_match = carrera_row\n",
    "\n",
    "    if best_score >= threshold and best_match is not None:\n",
    "        row['carrera_unificada'] = best_match['carrera_carreras']\n",
    "        row['titulo_unificado'] = best_match['titulo_carrera']\n",
    "        row['institucion_unificada'] = best_match['institucion_carrera']\n",
    "        row['carrera_carreras'] = best_match['carrera_carreras']\n",
    "        row['titulo_carrera'] = best_match['titulo_carrera']\n",
    "        row['institucion_carrera'] = best_match['institucion_carrera']\n",
    "    else:\n",
    "        row['carrera_unificada'] = row['carrera']\n",
    "        row['titulo_unificado'] = row['titulo_titulos']\n",
    "        row['institucion_unificada'] = row['institucion']\n",
    "\n",
    "    row['similarity_score'] = best_score\n",
    "    return row\n",
    "\n",
    "# Aplicar la coincidencia difusa\n",
    "left_only_unified = left_only.apply(fuzzy_unify, args=(carreras_ifd_copy,), axis=1)\n",
    "\n",
    "# Seleccionar las columnas en el orden deseado\n",
    "left_only_unified = left_only_unified[[\n",
    "    'carrera',\n",
    "    'carrera_carreras',\n",
    "    'carrera_unificada', \n",
    "    'titulo_titulos',\n",
    "    'titulo_carrera',\n",
    "    'titulo_unificado',\n",
    "    'institucion', \n",
    "    'institucion_carrera',\n",
    "    'institucion_unificada',\n",
    "    'similarity_score'\n",
    "]]\n",
    "\n",
    "# Exportar a un archivo Excel con el nombre modificado\n",
    "left_only_unified.to_excel('unificacion_left_only_ifd.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'unificacion_left_only_ifd.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b76a00-32ec-4f3b-9d8a-4e41996f516b",
   "metadata": {},
   "source": [
    "# REEMPLAZAR CAMPOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "344bbe94-a717-48a8-bf40-3573136c4967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: 'titulos_ifd_actualizado.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Filtrar las filas de left_only_unified con un puntaje mayor o igual a 90\n",
    "left_only_unified_filtered = left_only_unified[left_only_unified['similarity_score'] >= 89.5]\n",
    "\n",
    "# Paso 2: Reemplazar los valores en titulos_cre\n",
    "for _, row in left_only_unified_filtered.iterrows():\n",
    "    # Buscar coincidencias en titulos_cre\n",
    "    condition = (\n",
    "        (titulos_ifd['carrera'] == row['carrera']) &\n",
    "        (titulos_ifd['titulo'] == row['titulo_titulos']) &\n",
    "        (titulos_ifd['institucion'] == row['institucion'])\n",
    "    )\n",
    "    \n",
    "    # Reemplazar los valores en titulos_cre si hay coincidencias\n",
    "    titulos_ifd.loc[condition, 'carrera'] = row['carrera_unificada']\n",
    "    titulos_ifd.loc[condition, 'titulo'] = row['titulo_unificado']\n",
    "\n",
    "# Puedes guardar el DataFrame actualizado en un archivo Excel o CSV si lo deseas\n",
    "titulos_ifd.to_excel('titulos_ifd_actualizado.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'titulos_ifd_actualizado.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb58b8f6-664c-422e-8147-3afe82c1c2b7",
   "metadata": {},
   "source": [
    "# SEGUNDA REVISION #OPCIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "a6107f17-69df-4be5-8161-8653e891c0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas left_only: 3633\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_ifd_copy = titulos_ifd.copy()\n",
    "carreras_ifd_copy = carreras_ifd.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_ifd_copy = titulos_ifd_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_ifd_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_ifd_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_IFD.xlsx', index=False)\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_ifd_copy = carreras_ifd_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5645dda5-fce9-4a9b-921b-079f809310e9",
   "metadata": {},
   "source": [
    "# UNIFICACION FINAL IFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "51f6d8bd-3bdf-462a-b05e-fccd92dd2f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame TITULOS V2: (52869, 10)\n",
      "Shape del DataFrame final: (52869, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Eliminar duplicados en las columnas clave de carreras\n",
    "df_merged_unique = carreras_ifd.drop_duplicates(\n",
    "    subset=['carrera', 'institucion', 'tipo_institucion', 'titulo']\n",
    ")\n",
    "\n",
    "# Paso 2: Realizar el merge con las combinaciones únicas\n",
    "merged_final_IFD = pd.merge(\n",
    "    titulos_ifd, \n",
    "    df_merged_unique, \n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    how='left'  # Aquí cambiamos a 'left' para mantener todas las filas de df_titulos_v2_limpio_CRE\n",
    ")\n",
    "\n",
    "# Paso 2: Guardar el DataFrame en un archivo Excel\n",
    "merged_final_IFD.to_excel('IFD_FINAL.xlsx', index=False)\n",
    "# Imprimir la forma y los encabezados de df_titulos_v2_limpio_CRE\n",
    "print(\"Shape del DataFrame TITULOS V2:\", titulos_ifd.shape)\n",
    "\n",
    "\n",
    "# Imprimir la forma y los encabezados del DataFrame final\n",
    "print(\"Shape del DataFrame final:\", merged_final_IFD.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd62357-c5d4-4d09-acc4-86b8f1a276c8",
   "metadata": {},
   "source": [
    "# INSTITUTO SUPERIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "38fd4e61-5158-41a1-9c55-8628929415e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcciones realizadas en titulos_is:\n",
      "['INSTITUTO SUPERIOR PROFESIONAL AVANZADO'\n",
      " 'INSTITUTO SUPERIOR EN CIENCIAS LINGUISTICAS IDELGUAP'\n",
      " 'COMANDO DE INSTITUTOS MILITARES DE ENSENANZA DEL EJERCITO'\n",
      " 'INSTITUTO SUPERIOR KYREY SASO'\n",
      " 'INSTITUTO NACIONAL DE EDUCACION SUPERIOR DOCTOR RAUL PENA'\n",
      " 'INSTITUTO SUPERIOR DE EDUCACION SANTO TOMAS'\n",
      " 'ATENEO DE LENGUA Y CULTURA GUARANI'\n",
      " 'INSTITUTO SUPERIOR DE EDUCACION POLICIAL'\n",
      " 'INSTITUTO SUPERIOR INTERREGIONAL EN CIENCIAS DE LA SALUD'\n",
      " 'INSTITUTO DE ALTOS ESTUDIOS ESTRATEGICOS'\n",
      " 'INSTITUTO SUPERIOR DE EDUCACION DIVINA ESPERANZA'\n",
      " 'INSTITUTO SUPERIOR EN CIENCIAS JURIDICAS ESCUELA DE DERECHO Y OTRAS UNIDADES PEDAGOGICAS'\n",
      " 'INSTITUTO SUPERIOR EN CIENCIAS DE LA SALUD SANTA ROSA MISTICA'\n",
      " 'INSTITUTO SUPERIOR CENTURIA' 'INSTITUTO NACIONAL DE SALUD'\n",
      " 'INSTITUTO DESARROLLO'\n",
      " 'INSTITUTO SUPERIOR DE FORMACION TRIBUTARIA COMERCIAL Y ADMINISTRATIVA'\n",
      " 'INSTITUTO SUPERIOR DE BELLAS ARTES'\n",
      " 'INSTITUTO SUPERIOR DE FORMACION TRIBUTARIA Y EMPRESARIAL'\n",
      " 'COMANDO DE INSTITUTOS NAVALES DE ENSENANZA DE LA ARMADA'\n",
      " 'INSTITUTO SUPERIOR DE EDUCACION DOCTOR RAUL PENA'\n",
      " 'INSTITUTO SUPERIOR EN CIENCIAS DE LA SALUD JUAN PABLO II'\n",
      " 'INSTITUTO SUPERIOR EN CIENCIAS DE LA SALUD SAN AGUSTIN'\n",
      " 'COMANDO DE INSTITUTOS AERONAUTICOS DE ENSENANZA DE LA FUERZA AEREA'\n",
      " 'INSTITUTO SUPERIOR SALESIANO DE ESTUDIOS FILOSOFICOS DON BOSCO'\n",
      " 'INSTITUTO SUPERIOR PARAGUAYO DE TECNOLOGIA Y CIENCIAS DE LA EDUCACION'\n",
      " 'INSTITUTO SUPERIOR DE EDUCACION DOCTOR IGNACIO A PANE'\n",
      " 'INSTITUTO SUPERIOR EN CIENCIAS DE LA SALUD SAN PATRICIO DE IRLANDA DEL NORTE'\n",
      " 'INSTITUTO SUPERIOR SANTA LIBRADA'\n",
      " 'INSTITUTO SUPERIOR DE ESTUDIOS HUMANISTICOS Y FILOSOFICOS SAN FRANCISCO JAVIER'\n",
      " 'CENTRO EDUCATIVO SUPERIOR EN SALUD'\n",
      " 'INSTITUTO DE EDUCACION SUPERIOR DE ODONTOLOGIA AVANZADA'\n",
      " 'INSTITUTO SUPERIOR VIA PRO DESARROLLO'\n",
      " 'INSTITUTO DE LINGUISTICA GUARANI DEL PARAGUAY PROFESOR DOCTOR REINALDO JULIAN DECOUD LARROSA'\n",
      " 'INSTITUTO SUPERIOR DE ODONTOLOGIA ECO'\n",
      " 'CENTRO DE CIENCIAS PENALES Y POLITICA CRIMINAL'\n",
      " 'INSTITUTO DE EDUCACION SUPERIOR ARCO IRIS'\n",
      " 'INSTITUTO SUPERIOR DE ARTES VISUALES VERONICA KOOP'\n",
      " 'INSTITUTO SUPERIOR DE CIENCIAS LINGUISTICAS PROFESOR DOCTOR REINALDO JULIAN DECOUD LARROSA'\n",
      " 'INSTITUTO SUPERIOR DE ARTES VISUALES VERONIKA KOOP']\n",
      "\n",
      "Correcciones realizadas en carreras_is:\n",
      "['INSTITUTO SUPERIOR EN CIENCIAS DE LA SALUD JUAN PABLO II'\n",
      " 'INSTITUTO NACIONAL DE SALUD'\n",
      " 'INSTITUTO SUPERIOR SALESIANO DE ESTUDIOS FILOSOFICOS DON BOSCO'\n",
      " 'INSTITUTO SUPERIOR SAN PATRICIO DE IRLANDA DEL NORTE'\n",
      " 'INSTITUTO SUPERIOR DE EDUCACION POLICIAL'\n",
      " 'INSTITUTO SUPERIOR PROFESIONAL AVANZADO'\n",
      " 'INSTITUTO SUPERIOR EN CIENCIAS DE LA SALUD SAN AGUSTIN'\n",
      " 'INSTITUTO SUPERIOR EN CIENCIAS DE LA SALUD SANTA ROSA MISTICA'\n",
      " 'INSTITUTO SUPERIOR EN CIENCIAS DE LA SALUD SAN PATRICIO DE IRLANDA DEL NORTE'\n",
      " 'INSTITUTO SUPERIOR KYREY SASO'\n",
      " 'INSTITUTO SUPERIOR DE ESTUDIOS HUMANISTICOS Y FILOSOFICOS SAN FRANCISCO JAVIER'\n",
      " 'INSTITUTO DE LINGUISTICA GUARANI DEL PARAGUAY PROFESOR DOCTOR REINALDO JULIAN DECOUD LARROSA'\n",
      " 'INSTITUTO SUPERIOR EN CIENCIAS DE LA SALUD SAN NICOLAS'\n",
      " 'INSTITUTO SUPERIOR DE EDUCACION DIVINA ESPERANZA'\n",
      " 'INSTITUTO SUPERIOR DE EDUCACION VIA PRO DESARROLLO'\n",
      " 'ATENEO DE LENGUA Y CULTURA GUARANI' 'INSTITUTO SUPERIOR DE BELLAS ARTES'\n",
      " 'CENTRO EDUCATIVO SUPERIOR EN SALUD'\n",
      " 'INSTITUTO SUPERIOR DE FORMACION TRIBUTARIA COMERCIAL Y ADMINISTRATIVA'\n",
      " 'INSTITUTO SUPERIOR DE ODONTOLOGIA ECO'\n",
      " 'INSTITUTO DE ALTOS ESTUDIOS ESTRATEGICOS'\n",
      " 'INSTITUTO SUPERIOR INTERREGIONAL EN CIENCIAS DE LA SALUD'\n",
      " 'INSTITUTO SUPERIOR DE EDUCACION SANTO TOMAS'\n",
      " 'INSTITUTO NACIONAL DE EDUCACION SUPERIOR DOCTOR RAUL PENA'\n",
      " 'INSTITUTO SUPERIOR DE EDUCACION DOCTOR IGNACIO A PANE'\n",
      " 'INSTITUTO SUPERIOR DE FORMACION TRIBUTARIA Y EMPRESARIAL'\n",
      " 'INSTITUTO DESARROLLO'\n",
      " 'COMANDO DE INSTITUTOS AERONAUTICOS DE ENSENANZA DE LA FUERZA AEREA'\n",
      " 'INSTITUTO SUPERIOR CENTURIA'\n",
      " 'INSTITUTO DE EDUCACION SUPERIOR DE ODONTOLOGIA AVANZADA'\n",
      " 'INSTITUTO SUPERIOR EN CIENCIAS JURIDICAS ESCUELA DE DERECHO Y OTRAS UNIDADES PEDAGOGICAS'\n",
      " 'CENTRO DE CIENCIAS PENALES Y POLITICA CRIMINAL'\n",
      " 'COMANDO DE INSTITUTOS NAVALES DE ENSENANZA DE LA ARMADA'\n",
      " 'COMANDO DE INSTITUTOS MILITARES DE ENSENANZA DEL EJERCITO'\n",
      " 'INSTITUTO SUPERIOR PARAGUAYO DE TECNOLOGIA Y CIENCIAS DE LA EDUCACION'\n",
      " 'FACULTAD LATINOAMERICANA DE CIENCIAS SOCIALES'\n",
      " 'INSTITUTO DE EDUCACION SUPERIOR ARCO IRIS']\n"
     ]
    }
   ],
   "source": [
    "print(\"Correcciones realizadas en titulos_is:\")\n",
    "print(titulos_is['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n",
    "print(\"\\nCorrecciones realizadas en carreras_is:\")\n",
    "print(carreras_is['institucion'].unique())  # Imprime los valores únicos para ver las correcciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f6ae4-c46f-4448-98ee-b20c9a1993b9",
   "metadata": {},
   "source": [
    "# INSTITUCIONES QUE ESTAN EN UN SOLO LUGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "8b9575d2-4f65-4e2c-bd87-90e9b8e5ca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instituciones que están solo en titulos_is:\n",
      "{'INSTITUTO SUPERIOR VIA PRO DESARROLLO', 'INSTITUTO SUPERIOR DE ARTES VISUALES VERONICA KOOP', 'INSTITUTO SUPERIOR EN CIENCIAS LINGUISTICAS IDELGUAP', 'INSTITUTO SUPERIOR DE CIENCIAS LINGUISTICAS PROFESOR DOCTOR REINALDO JULIAN DECOUD LARROSA', 'INSTITUTO SUPERIOR DE EDUCACION DOCTOR RAUL PENA', 'INSTITUTO SUPERIOR SANTA LIBRADA', 'INSTITUTO SUPERIOR DE ARTES VISUALES VERONIKA KOOP'}\n",
      "\n",
      "Instituciones que están solo en carreras_is:\n",
      "{'INSTITUTO SUPERIOR SAN PATRICIO DE IRLANDA DEL NORTE', 'INSTITUTO SUPERIOR EN CIENCIAS DE LA SALUD SAN NICOLAS', 'INSTITUTO SUPERIOR DE EDUCACION VIA PRO DESARROLLO', 'FACULTAD LATINOAMERICANA DE CIENCIAS SOCIALES'}\n"
     ]
    }
   ],
   "source": [
    "# Valores únicos en 'titulos_cre'\n",
    "instituciones_titulos = set(titulos_is['institucion'].unique())\n",
    "\n",
    "# Valores únicos en 'carreras_cre'\n",
    "instituciones_carreras = set(carreras_is['institucion'].unique())\n",
    "\n",
    "# Instituciones que están en 'titulos_cre' pero no en 'carreras_cre'\n",
    "solo_en_titulos = instituciones_titulos - instituciones_carreras\n",
    "print(\"Instituciones que están solo en titulos_is:\")\n",
    "print(solo_en_titulos)\n",
    "\n",
    "# Instituciones que están en 'carreras_cre' pero no en 'titulos_cre'\n",
    "solo_en_carreras = instituciones_carreras - instituciones_titulos\n",
    "print(\"\\nInstituciones que están solo en carreras_is:\")\n",
    "print(solo_en_carreras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c58c11-87e1-4b36-aac2-8d1c54fe7a30",
   "metadata": {},
   "source": [
    "## Limpieza general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "afe00548-f7e2-4c23-83a7-cdfdb7bdd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos_is['institucion'] = titulos_is['institucion'].replace(\n",
    "    'INSTITUTO SUPERIOR VIA PRO DESARROLLO',\n",
    "    'INSTITUTO SUPERIOR DE EDUCACION VIA PRO DESARROLLO'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f3eee-0cca-4af8-9fea-b89cbd340d1f",
   "metadata": {},
   "source": [
    "# campos vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "b9f9e19b-67fe-4bba-a827-d05fa981e1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en titulos_is:\n",
      "anio                  0\n",
      "mes                   0\n",
      "documento             0\n",
      "persona_id            0\n",
      "nombre_completo       0\n",
      "tipo_institucion      0\n",
      "institucion           0\n",
      "carrera               0\n",
      "titulo                0\n",
      "sexo                119\n",
      "dtype: int64\n",
      "\n",
      "Valores nulos en carreras_is:\n",
      "tipo_institucion                0\n",
      "institucion                     0\n",
      "carrera                         0\n",
      "titulo                          0\n",
      "tipo_gestion                   25\n",
      "nivel_titulacion                0\n",
      "clasificacion_campo_amplio    727\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar valores nulos en cada columna de titulos_cre\n",
    "print(\"Valores nulos en titulos_is:\")\n",
    "print(titulos_is.isnull().sum())\n",
    "\n",
    "# Contar valores nulos en cada columna de carreras_cre\n",
    "print(\"\\nValores nulos en carreras_is:\")\n",
    "print(carreras_is.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f753a88-2620-4102-bf52-c1d200ec4c9f",
   "metadata": {},
   "source": [
    "# campos vacios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b604b0e0-f58c-414a-bae3-d758800edc6c",
   "metadata": {},
   "source": [
    "# campos amplio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "d84c9012-5e52-488e-ac76-800ff666bd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación para datos de validación:\n",
      "                                                     precision    recall  f1-score   support\n",
      "\n",
      "               ADMINISTRACION DE EMPRESAS Y DERECHO       0.96      0.73      0.83        33\n",
      "                                ARTES Y HUMANIDADES       0.00      0.00      0.00         5\n",
      "         CIENCIAS SOCIALES PERIODISMO E INFORMACION       1.00      0.64      0.78        11\n",
      "                                          EDUCACION       0.98      1.00      0.99      1974\n",
      "                                  SALUD Y BIENESTAR       1.00      0.96      0.98       164\n",
      "                                          SERVICIOS       1.00      0.86      0.92        42\n",
      "TECNOLOGIAS DE LA INFORMACION Y LA COMUNICACION TIC       0.00      0.00      0.00         7\n",
      "\n",
      "                                           accuracy                           0.98      2236\n",
      "                                          macro avg       0.71      0.60      0.64      2236\n",
      "                                       weighted avg       0.98      0.98      0.98      2236\n",
      "\n",
      "Total de valores vacíos por columna después de la predicción:\n",
      "tipo_institucion               0\n",
      "institucion                    0\n",
      "carrera                        0\n",
      "titulo                         0\n",
      "tipo_gestion                  25\n",
      "nivel_titulacion               0\n",
      "clasificacion_campo_amplio     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Concatenar los dataframes\n",
    "df_combined = pd.concat([carreras_is, carreras_ifd, carreras_cre], ignore_index=True)\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio no esté vacío para entrenamiento\n",
    "df_train = df_combined.dropna(subset=['clasificacion_campo_amplio'])\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio esté vacío para predicción\n",
    "df_predict = df_combined[df_combined['clasificacion_campo_amplio'].isna()]\n",
    "\n",
    "# Vectorización de la columna 'carrera' utilizando TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_train['carrera'])\n",
    "X_predict = vectorizer.transform(df_predict['carrera'])\n",
    "\n",
    "# Definir el target\n",
    "y_train = df_train['clasificacion_campo_amplio']\n",
    "\n",
    "# División de los datos de entrenamiento para validación\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Validar el modelo\n",
    "y_val_pred = model.predict(X_val_split)\n",
    "print(\"Reporte de clasificación para datos de validación:\")\n",
    "print(classification_report(y_val_split, y_val_pred, zero_division=0))\n",
    "\n",
    "# Predecir los valores faltantes en df_merged_IS y añadir el asterisco\n",
    "def predecir_y_marcar(row, model, vectorizer):\n",
    "    if pd.isna(row['clasificacion_campo_amplio']):\n",
    "        prediccion = model.predict(vectorizer.transform([row['carrera']]))[0]\n",
    "        return f\"{prediccion}*\"\n",
    "    else:\n",
    "        return row['clasificacion_campo_amplio']\n",
    "\n",
    "carreras_is['clasificacion_campo_amplio'] = carreras_is.apply(\n",
    "    lambda row: predecir_y_marcar(row, model, vectorizer),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Exportar el dataframe resultante a Excel\n",
    "carreras_is.to_excel('carreras_is_actualizado.xlsx', index=False)\n",
    "\n",
    "# Conteo de valores vacíos por columna después de la predicción\n",
    "valores_vacios_post_prediccion = carreras_is.isna().sum()\n",
    "print(\"Total de valores vacíos por columna después de la predicción:\")\n",
    "print(valores_vacios_post_prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad46ac-0bd0-4238-a10a-7441d6efe3b1",
   "metadata": {},
   "source": [
    "# tipo de gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "5d8b07ca-6a26-48d0-8ab4-44a2233be2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gimen\\AppData\\Local\\Temp\\ipykernel_1904\\4002539068.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  carreras_is = carreras_is.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar el tipo de gestión más frecuente para cada institución\n",
    "def completar_tipo_gestion(grupo):\n",
    "    if grupo['tipo_gestion'].isnull().all():\n",
    "        return grupo\n",
    "    # Obtener el tipo de gestión más frecuente (eliminando los nulos) \n",
    "    tipo_frecuente = grupo['tipo_gestion'].dropna().mode()[0]\n",
    "    # Rellenar los valores nulos con el tipo de gestión más frecuente\n",
    "    grupo['tipo_gestion'] = grupo['tipo_gestion'].fillna(tipo_frecuente)\n",
    "    return grupo\n",
    "\n",
    "# Aplicar la función a cada grupo de instituciones sin convertirlo en índice\n",
    "carreras_is = carreras_is.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n",
    "\n",
    "# Guardar el resultado en un archivo Excel\n",
    "carreras_is.to_excel('carreras_is_actualizado.xlsx', index=False)\n",
    "\n",
    "# Verificar si aún hay valores nulos en la columna 'tipo_gestion'\n",
    "print(carreras_is['tipo_gestion'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33562513-ce5d-4f17-a45b-1e0d57e7000d",
   "metadata": {},
   "source": [
    "# Verificacion de inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "5598124d-4b53-46bb-bdc9-c235156aed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas left_only: 11697\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_is_copy = titulos_is.copy()\n",
    "carreras_is_copy = carreras_is.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_is_copy = titulos_is_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_is_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_is_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_IS.xlsx', index=False)\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ae064-1862-48ee-928a-12c7d8afa7e8",
   "metadata": {},
   "source": [
    "# Limpieza de inconsistencias IS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "ac0158a5-b26f-47b6-8f90-b1ae5b9a9f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: 'unificacion_left_only_is.xlsx'\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "# Función para extraer la parte posterior a 'AREA'\n",
    "def extract_after_area(text):\n",
    "    if 'AREA' in text:\n",
    "        return text.split('AREA', 1)[-1].strip()  # Extraer lo que sigue después de 'AREA'\n",
    "    return None  # Si no tiene 'AREA', devolver None\n",
    "\n",
    "# Función para verificar palabras clave\n",
    "def check_keywords(text1, text2):\n",
    "    keywords = ['CIENCIAS BASICAS', 'CIENCIAS SOCIALES', 'FISIOTERAPIA', 'KINESIOLOGIA', 'PSICOLOGIA', 'EDUCACION FISICA']\n",
    "    for keyword in keywords:\n",
    "        if keyword in text1 and keyword not in text2:\n",
    "            return True\n",
    "        if keyword in text2 and keyword not in text1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Función de coincidencia difusa optimizada\n",
    "def fuzzy_unify(row, carreras_is, threshold=75):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    carreras_is_filtered = carreras_is[\n",
    "        (carreras_is['institucion_carrera'] == row['institucion']) &\n",
    "        (carreras_is['tipo_institucion'] == row['tipo_institucion'])\n",
    "    ]\n",
    "\n",
    "    row['carrera_carreras'] = None\n",
    "    row['titulo_carrera'] = None\n",
    "    row['institucion_carrera'] = None\n",
    "\n",
    "    for _, carrera_row in carreras_is_filtered.iterrows():\n",
    "        # Extraer partes después de 'AREA'\n",
    "        area_row_1 = extract_after_area(row['carrera'])\n",
    "        area_row_2 = extract_after_area(carrera_row['carrera_carreras'])\n",
    "\n",
    "        if area_row_1 and area_row_2:  # Ambas tienen 'AREA'\n",
    "            area_score = fuzz.ratio(area_row_1, area_row_2)\n",
    "            if area_score < 70:  # Si la parte después de 'AREA' no es similar\n",
    "                avg_score = 60  # Asignar un puntaje bajo\n",
    "            else:\n",
    "                carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "                titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "                avg_score = (carrera_score + titulo_score) / 2\n",
    "        elif area_row_1 or area_row_2:  # Solo una de las partes tiene 'AREA'\n",
    "            avg_score = 60  # Puntaje bajo\n",
    "        else:\n",
    "            carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "            titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "            avg_score = (carrera_score + titulo_score) / 2\n",
    "\n",
    "        # Verificar palabras clave\n",
    "        if check_keywords(row['carrera'], carrera_row['carrera_carreras']):\n",
    "            avg_score *= 0.5  # Reducir el puntaje a la mitad si hay un desajuste en las palabras clave\n",
    "\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_match = carrera_row\n",
    "\n",
    "    if best_score >= threshold and best_match is not None:\n",
    "        row['carrera_unificada'] = best_match['carrera_carreras']\n",
    "        row['titulo_unificado'] = best_match['titulo_carrera']\n",
    "        row['institucion_unificada'] = best_match['institucion_carrera']\n",
    "        row['carrera_carreras'] = best_match['carrera_carreras']\n",
    "        row['titulo_carrera'] = best_match['titulo_carrera']\n",
    "        row['institucion_carrera'] = best_match['institucion_carrera']\n",
    "    else:\n",
    "        row['carrera_unificada'] = row['carrera']\n",
    "        row['titulo_unificada'] = row['titulo_titulos']\n",
    "        row['institucion_unificada'] = row['institucion']\n",
    "\n",
    "    row['similarity_score'] = best_score\n",
    "    return row\n",
    "\n",
    "# Aplicar la coincidencia difusa\n",
    "left_only_unified = left_only.apply(fuzzy_unify, args=(carreras_is_copy,), axis=1)\n",
    "\n",
    "# Seleccionar las columnas en el orden deseado\n",
    "left_only_unified = left_only_unified[[\n",
    "    'carrera',\n",
    "    'carrera_carreras',\n",
    "    'carrera_unificada', \n",
    "    'titulo_titulos',\n",
    "    'titulo_carrera',\n",
    "    'titulo_unificado',\n",
    "    'institucion', \n",
    "    'institucion_carrera',\n",
    "    'institucion_unificada',\n",
    "    'similarity_score'\n",
    "]]\n",
    "\n",
    "# Exportar a un archivo Excel con el nombre modificado\n",
    "left_only_unified.to_excel('unificacion_left_only_is.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'unificacion_left_only_is.xlsx'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad556a8-f675-4a52-8db0-1b0ba0607992",
   "metadata": {},
   "source": [
    "# REEMPLAZAR CAMPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "5cd2e998-858d-4099-8225-b12b8fc10b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: 'titulos_is_actualizado.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Filtrar las filas de left_only_unified con un puntaje mayor o igual a 90\n",
    "left_only_unified_filtered = left_only_unified[left_only_unified['similarity_score'] >= 89.5]\n",
    "\n",
    "# Paso 2: Reemplazar los valores en titulos_cre\n",
    "for _, row in left_only_unified_filtered.iterrows():\n",
    "    # Buscar coincidencias en titulos_cre\n",
    "    condition = (\n",
    "        (titulos_is['carrera'] == row['carrera']) &\n",
    "        (titulos_is['titulo'] == row['titulo_titulos']) &\n",
    "        (titulos_is['institucion'] == row['institucion'])\n",
    "    )\n",
    "    \n",
    "    # Reemplazar los valores en titulos_cre si hay coincidencias\n",
    "    titulos_is.loc[condition, 'carrera'] = row['carrera_unificada']\n",
    "    titulos_is.loc[condition, 'titulo'] = row['titulo_unificado']\n",
    "\n",
    "# Puedes guardar el DataFrame actualizado en un archivo Excel o CSV si lo deseas\n",
    "titulos_is.to_excel('titulos_is_actualizado.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'titulos_is_actualizado.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287f12c-4658-432b-95f8-01177183f85c",
   "metadata": {},
   "source": [
    "# SEGUNDA VERIFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "22cd0a48-d40d-4857-af0d-94af90a2f225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas left_only: 4939\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_is_copy = titulos_is.copy()\n",
    "carreras_is_copy = carreras_is.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_is_copy = titulos_is_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_is_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_is_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_IS.xlsx', index=False)\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_is_copy = carreras_is_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f8c2a-7509-4166-a508-503386e080a6",
   "metadata": {},
   "source": [
    "# UNION FINAL IS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "c2168073-adbb-48a3-859f-639172c0bfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame TITULOS V2: (72944, 10)\n",
      "Shape del DataFrame final: (72944, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Eliminar duplicados en las columnas clave de carreras\n",
    "df_merged_unique = carreras_is.drop_duplicates(\n",
    "    subset=['carrera', 'institucion', 'tipo_institucion', 'titulo']\n",
    ")\n",
    "\n",
    "# Paso 2: Realizar el merge con las combinaciones únicas\n",
    "merged_final_IS = pd.merge(\n",
    "    titulos_is, \n",
    "    df_merged_unique, \n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    how='left'  # Aquí cambiamos a 'left' para mantener todas las filas de df_titulos_v2_limpio_CRE\n",
    ")\n",
    "\n",
    "# Paso 2: Guardar el DataFrame en un archivo Excel\n",
    "merged_final_IS.to_excel('IS_FINAL.xlsx', index=False)\n",
    "# Imprimir la forma y los encabezados de df_titulos_v2_limpio_CRE\n",
    "print(\"Shape del DataFrame TITULOS V2:\", titulos_is.shape)\n",
    "\n",
    "\n",
    "# Imprimir la forma y los encabezados del DataFrame final\n",
    "print(\"Shape del DataFrame final:\", merged_final_IS.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8bb6b-2855-4e21-96b3-27dd31acd701",
   "metadata": {},
   "source": [
    "# INSTITUTO TECNICO SUPERIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "acecb347-2031-4915-be67-e12b121974f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcciones realizadas en titulos_its:\n",
      "['INSTITUTO TECNICO SUPERIOR LATINOAMERICANO'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO MEDICO BAUTISTA DEPENDIENTE DE LA UNIVERSIDAD CENTRO MEDICO BAUTISTA'\n",
      " 'INSTITUTO TECNICO SUPERIOR MARIA' 'INSTITUTO TECNICO SUPERIOR KOLPING'\n",
      " 'INSTITUTO TECNICO SUPERIOR EUROSUR'\n",
      " 'INSTITUTO TECNICO SUPERIOR CORAZON DE JESUS'\n",
      " 'INSTITUTO TECNICO SUPERIOR MONTERREY'\n",
      " 'ESCUELA NACIONAL DE EDUCACION FISICA'\n",
      " 'INSTITUTO TECNICO SUPERIOR ADUANERO DOCTOR JOSE GASPAR RODRIGUEZ DE FRANCIA'\n",
      " 'CENTRO PRIVADO DE ESTUDIO INTEGRAL ADAMANTINO'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE DESARROLLO Y COOPERATIVISMO DEL PARAGUAY IDECOOP'\n",
      " 'CENTRO DE FORMACION DE TECNICO SUPERIOR FORESTAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE AERONAUTICA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE GASTRONOMIA IGA PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR VIRGEN DE CAACUPE'\n",
      " 'INSTITUTO TECNICO SUPERIOR REGIONAL DE SALUD'\n",
      " 'INSTITUTO TECNICO SUPERIOR TESA PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR DEL ROSARIO'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE ELECTRICIDAD ITC'\n",
      " 'INSTITUTO TECNICO SUPERIOR EN CIENCIAS DE LA SALUD SAN BUENAVENTURA'\n",
      " 'INSTITUTO TECNICO SUPERIOR EL AMANECER'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN ROQUE GONZALEZ DE SANTA CRUZ'\n",
      " 'ESCUELA DE MECANICA DENTAL HORIZONTE'\n",
      " 'INSTITUTO TECNICO SUPERIOR VIRGEN DE LA PAZ'\n",
      " 'INSTITUTO TECNICO SUPERIOR DIVINO NINO JESUS'\n",
      " 'INSTITUTO TECNICO SUPERIOR SARA EGUSQUIZA DE CHAVEZ'\n",
      " 'INSTITUTO TECNICO SUPERIOR MONSENOR EMILIO SOSA GAONA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DEL SERVICIO NACIONAL DE PROMOCION PROFESIONAL SEDE CENTRO TECNOLOGICO DE AVANZADA PARAGUAY COREA'\n",
      " 'INSTITUTO DE FORMACION TECNICA SUPERIOR INFORTES'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO DE FORMACION Y CAPACITACION LABORAL DEL SECTOR ELECTRICO DEL PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN IGNACIO DE LOYOLA'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN FRANCISCO'\n",
      " 'INSTITUTO TECNICO SUPERIOR EN DDHH SILVANO ORTELLADO FLORES'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN MARCOS'\n",
      " 'INSTITUTO TECNICO SUPERIOR PROFESIONAL DE EDUCACION IPES'\n",
      " 'INSTITUTO TECNICO SUPERIOR DORA GIMENEZ'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN BLAS'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR MISION DE AMISTAD' 'COLEGIO TECNICO NACIONAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR MONTECARLO'\n",
      " 'CENTRO DE CAPACITACION TECNICA SUPERIOR GENERAL BERNARDINO CABALLERO'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE SANIDAD MILITAR GENERAL DE SAN DOCTOR VICTOR PASTOR IDOYAGA AYALA'\n",
      " 'INSTITUTO DE FORMACION TECNICA SUPERIOR DEL PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR KOE PYAHU'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE LA IMAGEN'\n",
      " 'INSTITUTO TECNICO SUPERIOR GAMMA'\n",
      " 'INSTITUTO TECNICO SUPERIOR FUNDACION SANTIAGO PEDRO MAINERO'\n",
      " 'PRIMER INSTITUTO PARAGUAYO DE ESTUDIOS DE PROTOCOLO Y CEREMONIAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE AGENTES DE SALUD'\n",
      " 'INSTITUTO TECNICO SUPERIOR EN SALUD'\n",
      " 'ESCUELA DE FORMACION DE ASISTENTES PARA EMPRESAS DE SERVICIO EFAES'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE HOTELERIA Y TURISMO VATELPARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE LA ESCUELA NAUTICA DE LA ARMADA'\n",
      " 'INSTITUTO NACIONAL DE AERONAUTICA CIVIL INAC'\n",
      " 'INSTITUTO TECNICO SUPERIOR EN TELECOMUNICACIONES'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE SALUD YUTY'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN ESTANISLAO'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE FORMACION INTEGRAL PARAGUAYA'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO FAMILIAR DE ADORACION ITSCFA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE ADMINISTRACION PUBLICA'\n",
      " 'INSTITUTO TECNICO SUPERIOR JESUS DE NAZARET'\n",
      " 'INSTITUTO TECNICO SUPERIOR HIPOCRATES'\n",
      " 'INSTITUTO TECNICO SUPERIOR NUESTRA SENORA DE GUADALUPE'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN BERNARDO'\n",
      " 'INSTITUTO TECNICO SUPERIOR EN CIENCIAS GEOGRAFICAS'\n",
      " 'INSTITUTO TECNICO SUPERIOR RAMON INDALECIO CARDOZO'\n",
      " 'INSTITUTO TECNICO SUPERIOR CARRERAS'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN JUAN BAUTISTA'\n",
      " 'INSTITUTO TECNICO SUPERIOR ASUNCION'\n",
      " 'ESCUELA PARAGUAYA DE ENFERMERIA YCIENCIAS DE LA SALUD'\n",
      " 'INSTITUTO TECNICO SUPERIOR LATIN'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE TEOLOGIA SAN CARLOS DUARTE COSTA'\n",
      " 'INSTITUTO TECNICO SUPERIOR ACADEMO'\n",
      " 'INSTITUTO TECNICO SUPERIOR SANTA TERESITA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE LAS CATARATAS'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO PARAGUAYO DEL SABER'\n",
      " 'INSTITUTO TECNICO SUPERIOR VALLE PE'\n",
      " 'INSTITUTO TECNICO SUPERIOR LEGISLATIVO DE LA HONORABLE CAMARA DE DIPUTADOS'\n",
      " 'INSTITUTO TECNICO SUPERIOR NUESTRA SENORA DE FATIMA'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO PARAGUAYO DE PRODUCTIVIDAD Y CALIDAD CEPROCAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR MULTIESPACIO EDUCATIVO INTERNACIONAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO TECNOLOGICO EMANUEL CTE'\n",
      " 'INSTITUTO TECNICO SUPERIOR SANTA ELENA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DEL SERVICIO NACIONAL DE PROMOCION PROFESIONAL SNPP'\n",
      " 'INSTITUTO DE ADMINISTRACION BANCARIA INABANC'\n",
      " 'INSTITUTO TECNICO SUPERIOR LA ESPERANZA'\n",
      " 'INSTITUTO TECNICO SUPERIOR SANTA ROSA'\n",
      " 'INSTITUTO TECNICO SUPERIOR INMACULADO CORAZON DE MARIA'\n",
      " 'INSTITUTO TECNICO SUPERIOR FISIOMEDIC PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR VITAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE ESTUDIOS CULTURALES Y LINGUISTICOS YVY MARAEY'\n",
      " 'INSTITUTO TECNICO SUPERIOR PARAGUAYO DE ESTETICA INTEGRAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR PROFESOR DOMINGO OCAMPOS'\n",
      " 'INSTITUTO TECNICO SUPERIOR NUEVA ESPERANZA'\n",
      " 'INSTITUTO TECNICO SUPERIOR SANTO DOMINGO'\n",
      " 'INSTITUTO TECNICO SUPERIOR OHARA'\n",
      " 'INSTITUTO TECNICO SUPERIOR JESUS DE NAZARETH'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE FORMACION TECNICA SUPERIORINFORTES'\n",
      " 'INSTITUTO TECNICO SUPERIOR INTERNACIONAL DEL DEPORTE'\n",
      " 'INSTITUTO TECNICO SUPERIOR INCOTEC INTERNACIONAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR DEPARTAMENTAL DOCTOR EUSEBIO AYALA'\n",
      " 'ESCUELA NACIONAL DE COMERCIO NDEG 2 PROFESOR PRUDENCIO VIDAL ZELAYA'\n",
      " 'INSTITUTO TECNICO SUPERIOR BUENA MADRE'\n",
      " 'INSTITUTO TECNICO SUPERIOR DOCTOR CARLOS PASTORE'\n",
      " 'INSTITUTO TECNICO SUPERIOR GPE GESTION POLITECNICA EDUCATIVA'\n",
      " 'INSTITUTO TECNICO SUPERIOR ARANDU'\n",
      " 'INSTITUTO TECNICO SUPERIOR MBOE RAITY SAN IGNACIO PARAGUARI'\n",
      " 'INSTITUTO TECNICO SUPERIOR UNE SN'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE ARTE CULINARIO PROFESOR DEYMA DE KERLING'\n",
      " 'INSTITUTO TECNICO SUPERIOR ALAS PARAGUAYAS'\n",
      " 'INSTITUTO TECNICO SUPERIOR SANTA ANA'\n",
      " 'INSTITUTO TECNICO SUPERIOR JUAN PABLO II'\n",
      " 'INSTITUTO TECNICO SUPERIOR COLONIAS UNIDAS'\n",
      " 'INSTITUTO TECNICO SUPERIOR SERMAS'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE OSTEOPATIA Y ESPECIALIDADES DEL PARAGUAY ITSOEP'\n",
      " 'INSTITUTO TECNICO SUPERIOR ARAMI'\n",
      " 'INSTITUTO TECNICO SUPERIOR SALTO DEL GUAIRA'\n",
      " 'INSTITUTO TECNICO SUPERIOR VILLARRICA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DEPARTAMENTAL MUNICIPAL YPACARAI'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE FORMACION EN POLITICA ELECTORAL DE LA JUSTICIA ELECTORAL IPEL'\n",
      " 'INSTITUTO TECNICO SUPERIOR BIOCELL'\n",
      " 'INSTITUTO TECNICO SUPERIOR NUESTRA SENORA STELLA MARIS'\n",
      " 'COLEGIO DE POLICIA SARGENTO AYUDANTE JOSE MERLO SARAVIA'\n",
      " 'INSTITUTO TECNICO SUPERIOR ACADEMIA CREATIVA DEL PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE LA ARMADA TENIENTE JOSE MARIA FARINA'\n",
      " 'INSTITUTO TECNICO SUPERIOR INTERNACIONAL DE ENCARNACION'\n",
      " 'INSTITUTO TECNICO SUPERIOR EL MAESTRO'\n",
      " 'INSTITUTO TECNICO SUPERIOR INVICTUS']\n",
      "\n",
      "Correcciones realizadas en carreras_its:\n",
      "['INSTITUTO TECNICO SUPERIOR DEL ROSARIO'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE AERONAUTICA' nan\n",
      " 'ESCUELA NACIONAL DE EDUCACION FISICA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE LA ARMADA TENIENTE JOSE MARIA FARINA'\n",
      " 'INSTITUTO DE ADMINISTRACION BANCARIA INABANC'\n",
      " 'INSTITUTO TECNICO SUPERIOR VITAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE ELECTRICIDAD ITC'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO PARAGUAYO DEL SABER'\n",
      " 'INSTITUTO TECNICO SUPERIOR DEL SERVICIO NACIONAL DE PROMOCION PROFESIONAL SNPP'\n",
      " 'INSTITUTO TECNICO SUPERIOR SALTO DEL GUAIRA'\n",
      " 'INSTITUTO TECNICO SUPERIOR SANTO DOMINGO'\n",
      " 'INSTITUTO TECNICO SUPERIOR ACADEMO'\n",
      " 'INSTITUTO TECNICO SUPERIOR SANTA TERESITA'\n",
      " 'INSTITUTO TECNICO SUPERIOR MBOE RAITY SAN IGNACIO PARAGUARI'\n",
      " 'INSTITUTO TECNICO SUPERIOR JESUS DE NAZARET'\n",
      " 'INSTITUTO TECNICO SUPERIOR HIPOCRATES'\n",
      " 'ESCUELA NACIONAL DE COMERCIO NDEG 2 PROFESOR PRUDENCIO VIDAL ZELAYA'\n",
      " 'INSTITUTO TECNICO SUPERIOR OHARA'\n",
      " 'INSTITUTO TECNICO SUPERIOR FISIOMEDIC PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE LA ESCUELA NAUTICA DE LA ARMADA'\n",
      " 'INSTITUTO DE FORMACION TECNICA SUPERIOR DEL PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE GASTRONOMIA IGA PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN IGNACIO DE LOYOLA'\n",
      " 'INSTITUTO TECNICO SUPERIOR NUESTRA SENORA DE FATIMA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE FORMACION TECNICA SUPERIORINFORTES'\n",
      " 'INSTITUTO TECNICO SUPERIOR SANTA ELENA'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO FAMILIAR DE ADORACION ITSCFA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE SALUD YUTY'\n",
      " 'INSTITUTO TECNICO SUPERIOR DIVINO NINO JESUS'\n",
      " 'INSTITUTO TECNICO SUPERIOR KOLPING'\n",
      " 'INSTITUTO TECNICO SUPERIOR JESUS DE NAZARETH'\n",
      " 'INSTITUTO TECNICO SUPERIOR BUENA MADRE'\n",
      " 'INSTITUTO TECNICO SUPERIOR DEL SERVICIO NACIONAL DE PROMOCION PROFESIONAL SEDE CENTRO TECNOLOGICO DE AVANZADA PARAGUAY COREA'\n",
      " 'INSTITUTO TECNICO SUPERIOR MULTIESPACIO EDUCATIVO INTERNACIONAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR MONTERREY'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE AGENTES DE SALUD'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN MARCOS'\n",
      " 'INSTITUTO TECNICO SUPERIOR SARA EGUSQUIZA DE CHAVEZ'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO PARAGUAYO DE PRODUCTIVIDAD Y CALIDAD CEPROCAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR SANTA ROSA'\n",
      " 'INSTITUTO TECNICO SUPERIOR GAMMA' 'INSTITUTO TECNICO SUPERIOR ASUNCION'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN ROQUE GONZALEZ DE SANTA CRUZ'\n",
      " 'INSTITUTO TECNICO SUPERIOR PROFESIONAL DE EDUCACION IPES'\n",
      " 'INSTITUTO TECNICO SUPERIOR GPE GESTION POLITECNICA EDUCATIVA'\n",
      " 'INSTITUTO TECNICO SUPERIOR INMACULADO CORAZON DE MARIA'\n",
      " 'INSTITUTO TECNICO SUPERIOR NUEVA ESPERANZA'\n",
      " 'INSTITUTO TECNICO SUPERIOR VIRGEN DE CAACUPE'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE ESTUDIOS CULTURALES Y LINGUISTICOS YVY MARAEY'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN BLAS'\n",
      " 'INSTITUTO TECNICO SUPERIOR MONTECARLO'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE LAS CATARATAS' 'COLEGIO TECNICO NACIONAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO TECNOLOGICO EMANUEL CTE'\n",
      " 'INSTITUTO TECNICO SUPERIOR LEGISLATIVO DE LA HONORABLE CAMARA DE DIPUTADOS'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE FORMACION INTEGRAL PARAGUAYA'\n",
      " 'CENTRO DE CAPACITACION TECNICA SUPERIOR GENERAL BERNARDINO CABALLERO'\n",
      " 'INSTITUTO TECNICO SUPERIOR INTERNACIONAL DEL DEPORTE'\n",
      " 'INSTITUTO TECNICO SUPERIOR DEPARTAMENTAL DOCTOR EUSEBIO AYALA'\n",
      " 'INSTITUTO TECNICO SUPERIOR LA ESPERANZA'\n",
      " 'INSTITUTO TECNICO SUPERIOR ARAMI'\n",
      " 'INSTITUTO TECNICO SUPERIOR PROFESOR DOMINGO OCAMPOS'\n",
      " 'INSTITUTO TECNICO SUPERIOR ARANDU' 'INSTITUTO TECNICO SUPERIOR EUROSUR'\n",
      " 'INSTITUTO TECNICO SUPERIOR UNE SN'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN JUAN BAUTISTA'\n",
      " 'INSTITUTO TECNICO SUPERIOR ALAS PARAGUAYAS'\n",
      " 'INSTITUTO TECNICO SUPERIOR INCOTEC INTERNACIONAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN BERNARDO'\n",
      " 'INSTITUTO TECNICO SUPERIOR DEPARTAMENTAL MUNICIPAL YPACARAI'\n",
      " 'INSTITUTO TECNICO SUPERIOR DOCTOR CARLOS PASTORE'\n",
      " 'INSTITUTO TECNICO SUPERIOR INTERNACIONAL DE ENCARNACION'\n",
      " 'INSTITUTO TECNICO SUPERIOR VALLE PE'\n",
      " 'INSTITUTO TECNICO SUPERIOR EN DDHH SILVANO ORTELLADO FLORES'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE OSTEOPATIA Y ESPECIALIDADES DEL PARAGUAY ITSOEP'\n",
      " 'INSTITUTO DE FORMACION TECNICA SUPERIOR INFORTES'\n",
      " 'INSTITUTO TECNICO SUPERIOR EL AMANECER'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE ARTE CULINARIO PROFESOR DEYMA DE KERLING'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN ESTANISLAO'\n",
      " 'INSTITUTO TECNICO SUPERIOR SAN FRANCISCO'\n",
      " 'INSTITUTO TECNICO SUPERIOR MONSENOR EMILIO SOSA GAONA'\n",
      " 'INSTITUTO TECNICO SUPERIOR BIOCELL'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR KOE PYAHU'\n",
      " 'INSTITUTO TECNICO SUPERIOR VILLARRICA'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO MEDICO BAUTISTA DEPENDIENTE DE LA UNIVERSIDAD CENTRO MEDICO BAUTISTA'\n",
      " 'INSTITUTO TECNICO SUPERIOR EN TELECOMUNICACIONES'\n",
      " 'INSTITUTO TECNICO SUPERIOR COLONIAS UNIDAS'\n",
      " 'INSTITUTO NACIONAL DE AERONAUTICA CIVIL INAC'\n",
      " 'PRIMER INSTITUTO PARAGUAYO DE ESTUDIOS DE PROTOCOLO Y CEREMONIAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR NUESTRA SENORA STELLA MARIS'\n",
      " 'INSTITUTO TECNICO SUPERIOR SANTA ANA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DORA GIMENEZ'\n",
      " 'INSTITUTO TECNICO SUPERIOR SERMAS'\n",
      " 'INSTITUTO TECNICO SUPERIOR JUAN PABLO II'\n",
      " 'INSTITUTO TECNICO SUPERIOR EN CIENCIAS DE LA SALUD SAN BUENAVENTURA'\n",
      " 'INSTITUTO TECNICO SUPERIOR CARRERAS'\n",
      " 'ESCUELA DE MECANICA DENTAL HORIZONTE'\n",
      " 'INSTITUTO TECNICO SUPERIOR CORAZON DE JESUS'\n",
      " 'INSTITUTO TECNICO SUPERIOR CENTRO DE FORMACION Y CAPACITACION LABORAL DEL SECTOR ELECTRICO DEL PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR ACADEMIA CREATIVA DEL PARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR FUNDACION SANTIAGO PEDRO MAINERO'\n",
      " 'INSTITUTO TECNICO SUPERIOR MARIA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE FORMACION EN POLITICA ELECTORAL DE LA JUSTICIA ELECTORAL IPEL'\n",
      " 'INSTITUTO TECNICO SUPERIOR VIRGEN DE LA PAZ'\n",
      " 'INSTITUTO TECNICO SUPERIOR NUESTRA SENORA DE GUADALUPE'\n",
      " 'INSTITUTO TECNICO SUPERIOR PARAGUAYO DE ESTETICA INTEGRAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE SANIDAD MILITAR GENERAL DE SAN DOCTOR VICTOR PASTOR IDOYAGA AYALA'\n",
      " 'INSTITUTO TECNICO SUPERIOR TESA PARAGUAY'\n",
      " 'ESCUELA DE FORMACION DE ASISTENTES PARA EMPRESAS DE SERVICIO EFAES'\n",
      " 'INSTITUTO TECNICO SUPERIOR EL MAESTRO'\n",
      " 'INSTITUTO TECNICO SUPERIOR ADUANERO DOCTOR JOSE GASPAR RODRIGUEZ DE FRANCIA'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE LA IMAGEN'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE TEOLOGIA SAN CARLOS DUARTE COSTA'\n",
      " 'CENTRO DE FORMACION DE TECNICO SUPERIOR FORESTAL'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE HOTELERIA Y TURISMO VATELPARAGUAY'\n",
      " 'INSTITUTO TECNICO SUPERIOR RAMON INDALECIO CARDOZO'\n",
      " 'INSTITUTO TECNICO SUPERIOR MISION DE AMISTAD'\n",
      " 'INSTITUTO TECNICO SUPERIOR DE ADMINISTRACION PUBLICA'\n",
      " 'INSTITUTO TECNICO SUPERIOR EN CIENCIAS GEOGRAFICAS'\n",
      " 'INSTITUTO TECNICO SUPERIOR REGIONAL DE SALUD'\n",
      " 'ESCUELA PARAGUAYA DE ENFERMERIA YCIENCIAS DE LA SALUD'\n",
      " 'INSTITUTO TECNICO SUPERIOR LATINOAMERICANO'\n",
      " 'INSTITUTO TECNICO SUPERIOR INVICTUS'\n",
      " 'INSTITUTO TECNICO SUPERIOR EN SALUD' 'INSTITUTO TECNICO SUPERIOR LATIN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Correcciones realizadas en titulos_its:\")\n",
    "print(titulos_its['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n",
    "print(\"\\nCorrecciones realizadas en carreras_its:\")\n",
    "print(carreras_its['institucion'].unique())  # Imprime los valores únicos para ver las correcciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2289b5e2-fb56-4954-93be-22d7bd1fc422",
   "metadata": {},
   "source": [
    "# INSTITUTOS QUE ESTAN EN UN SOLO LUGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "622f3a97-047b-4570-a017-4814edcf5b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instituciones que están solo en titulos_its:\n",
      "{'COLEGIO DE POLICIA SARGENTO AYUDANTE JOSE MERLO SARAVIA', 'CENTRO PRIVADO DE ESTUDIO INTEGRAL ADAMANTINO'}\n",
      "\n",
      "Instituciones que están solo en carreras_its:\n",
      "{'INSTITUTO TECNICO SUPERIOR DE DISENO Y TECNOLOGIAIDT', 'INSTITUTO TECNICO SUPERIOR MARIA AUXILIADORA REPATRIACION', 'INSTITUTO TECNICO SUPERIOR ICEFA INSTITUTO DE CAPACITACION ECONOMICA FINANCIERA ADMINISTRATIVA Y AMBIENTAL', 'INSTITUTO TECNICO SUPERIOR DE MECANICA AUTOMOTRIZ SOP TRNP LUCIO DE JESUS TORRASCA GALVAN', 'INSTITUTO TECNICO SUPERIOR CENTRO DE EDUCACION PROFESIONAL CEP', 'INSTITUTO TECNICO SUPERIOR PRICEWATERHOUSECOOPERS ACADEMY', 'INSTITUTO TECNICO SUPERIOR CENTRO DE INFORMACION Y RECURSOS PARA EL DESARROLLO CIRD', 'INSTITUTO TECNICO SUPERIOR PARAGUAYO DE EDUCACION PARA EL DESARROLLO', 'INSTITUTO TECNICO SUPERIOR SEMBRADOR', 'INSTITUTO TECNICO SUPERIOR ALIANZA INTEGRAL ARMONIA', 'INSTITUTO TECNICO SUPERIOR CENTRO EDUCATIVO INTEGRAL DE FORMACION TECNICA Y CAPACITACION PROFESIONAL', 'INSTITUTO TECNICO SUPERIOR TRIBUTARIO DE LA SUBSECRETARIA DE ESTADO DE TRIBUTACION', 'INSTITUTO TECNICO SUPERIOR DE FORMACION INTEGRAL Y DESARROLLO PERSONAL CDI', 'INSTITUTO TECNICO SUPERIOR SA DENTAL TRAINING', 'INSTITUTO TECNICO SUPERIOR EN CIENCIAS AGROPECUARIAS DEL SERVICIO AGROPECUARIO COMANDO LOGISTICO DISERAGRO DE LAS FUERZAS ARMADAS DE LA NACION', 'INSTITUTO TECNICO SUPERIOR TEOLOGICO FILADELFIA', 'INSTITUTO TECNICO SUPERIOR ILES', 'INSTITUTO TECNICO SUPERIOR JUAN DE AYOLAS', 'INSTITUTO TECNICO SUPERIOR CENTRO DE FORMACION DE TECNICO SUPERIOR FORESTAL ALTO PARANA FILIAL ITAPUA', 'INSTITUTO NACIONAL DE LA ADMINISTRACION PUBLICA DEL PARAGUAY', 'INSTITUTO TECNICO SUPERIOR DE NINEZ Y ADOLESCENCIA', 'INSTITUTO TECNICO SUPERIOR GLORIA CARDOZO', 'INSTITUTO TECNICO SUPERIOR COLEGIO DE POLICIA SGTO AYDTE JOSE MERLO SARAVIA', 'INSTITUTO TECNICO SUPERIOR ARANDU REKA', 'INSTITUTO TECNICO SUPERIOR DE EDUCACION Y FORMACION PENITENCIARIA', 'INSTITUTO TECNICO SUPERIOR SAGRADA FAMILIA', 'INSTITUTO TECNICO SUPERIOR HENRI FAYOL ITS HF', 'INSTITUTO TECNICO SUPERIOR RENE CASSIN', 'INSTITUTO TECNICO SUPERIOR SAN ANTONIO', 'INSTITUTO TECNICO SUPERIOR SANTA RITA DE CASIA', 'INSTITUTO TECNICO SUPERIOR CENTRO DE ESTUDIOS DE DERECHO ECONOMIA Y POLITICA CEDEP', 'INSTITUO TECNICO SUPERIOR ESCUELA DE GOBIERNO EDYDSI', 'INSTITUTO TECNICO SUPERIOR RURAL DEL PARAGUAY', 'INSTITUTO TECNICO SUPERIOR CAMPUS DE CIENCIAS APLICADAS', 'INSTITUTO TECNICO SUPERIOR ORBIS VERITAS', 'INSTITUTO TECNICO SUPERIOR DE DESARROLLO AVANZADO IDA', 'INSTITUTO TECNICO SUPERIOR CONTINENTAL', 'INSTITUTO TECNICO SUPERIOR ALIANZA EDUCATIVA INTERNACIONAL', 'INSTITUTO TECNICO SUPERIOR DEPENDIENTE DEL SERVICIO NACIONAL DE PROMOCION PROFESIONAL', 'INSTITUTO TECNICO SUPERIOR SANTISIMA TRINIDAD', 'INSTITUTO TECNICO SUPERIOR MARIA AUXILIADORA', 'INSTITUTO TECNICO SUPERIOR ICM', 'INSTITUTO TECNICO SUPERIOR EPO', 'INSTITUTO DE FORMACION TECNICA SUPERIOR INFORTES DEPENDIENTE DE LA UNIVERSIDAD EVANGELICA DEL PARAGUAY', 'INSTITUTO TECNICO SUPERIOR AGROMECANICO DE CAACUPE', 'INSTITUTO TECNICO SUPERIOR DE BANDAS MILITARES TENIENTE 2DEG RVA EMILIANO RIVAROLA FERNANDEZ', 'INSTITUTO TECNICO SUPERIOR WAKE UP NEGOCIOS Y LIDERAZGO', 'INSTITUTO TECNICO SUPERIOR CENTRO CULTURAL PARAGUAYO AMERICANO', 'INSTITUTO TECNICO SUPERIOR INDIRA', 'INSTITUTO TECNICO SUPERIOR ELEVATE TRAINING CENTER', 'INSTITUTO TECNICO SUPERIOR DEL SABER', 'INSTITUTO TECNICO SUPERIOR SAN IGNACIO GUAZU', 'INSTITUTO TECNICO SUPERIOR INTEGRAL DE NEGOCIOS ATHENEA', 'INSTITUTO TECNICO SUPERIOR DE DESARROLLO SUSTENTABLE', 'INSTITUTO TECNICO SUPERIOR DE ESTUDIOS CONTABLES TRIBUTARIOS Y ADMINISTRATIVOS', 'INSTITUTO DE FORMACION Y CULTURA CIUDADANA JOSE PATRICIO GUGGARI', 'INSTITUTO TECNICO SUPERIOR UNIBRAS', 'INSTITUTO TECNICO SUPERIOR SAN BENITO DE NURCIA', 'INSTITUTO TECNICO SUPERIOR CENTRO DE INVESTIGACION Y CAPACITACION PARAGUAY CICAP', 'INSTITUTO TECNICO SUPERIOR SAN NICOLAS', 'INSTITUTO TECNICO SUPERIOR AVALOS TRAINING', 'INSTITUTO TECNICO SUPERIOR VUELVE A SONAR', 'INSTITUTO TECNICO SUPERIOR MARACANA', 'INSTITUTO TECNICO SUPERIOR EN GERENCIAMIENTO Y ADMINISTRACION NEST OF EAGLES', 'INSTITUTO TECNICO SUPERIOR DE ESTETICA INTEGRAL NORMA S GABINETE ESTETICO', 'INSTITUTO TECNICO SUPERIOR CENTRO DE FORMACION Y CAPACITACION LABORAL DEL SECTOR ELECTRICO DEL PARAGUAY CEFOCALE', 'INSTITUTO TECNICO SUPERIOR SANTA MARIA DE FE', 'INSTITUTO TECNICO SUPERIOR DEL SERVICIO NACIONAL DE PROMOCION PROFESIONAL SNPP SEDE CENTRO REGIONAL DE EDUCACION GENERAL PATRICIO ESCOBAR', 'INSTITUTO TECNICO SUPERIOR CENTRO DE ESTUDIOS BANCARIOS', 'INSTITUTO TECNICO SUPERIOR JUANI CENTER', 'INSTITUTO TECNICO SUPERIOR NUESTRA SENORA DE LA ASUNCION', 'INSTITUTO TECNICO SUPERIOR SANTA ROSA DE LIMA', 'INSTITUTO TECNICO SUPERIOR DE ACTIVIDADES EDUCATIVAS Y FISICAS FITNESS FAMILY', 'INSTITUTO TECNICO SUPERIOR DESARROLLO INTEGRAL', 'INSTITUTO TECNICO SUPERIOR HERMINIO GIMENEZ', 'INSTITUTO TECNICO SUPERIOR SAN JUDAS TADEO', 'INSTITUTO TECNICO SUPERIOR AVIADORES DEL CHACO', 'INSTITUTO TECNICO SUPERIOR ESCUELA DE GOBIERNO Y POLITICAS PUBLICAS NORBERTO BOBBIO', 'INSTITUTO TECNICO SUPERIOR DE LA DEFENSA PUBLICA', 'INSTITUTO TECNICO SUPERIOR DEL PARAGUAY', 'INSTITUTO TECNICO SUPERIOR SANTA ROSA MISTICA', 'COLEGIO MILITAR DE SUBOFICIALES DEL EJERCITO TENIENTE PRIMERO INFANTE DE RESERVA MANUEL IRALA FERNANDEZ', 'INSTITUTO TECNICO SUPERIOR CORPORATIVO RENACER', 'INSTITUTO TECNICO SUPERIOR SAGRADO CORAZON DE JESUS', 'INSTITUTO TECNICO SUPERIOR MARITIMO PORTUARIO', 'INSTITUTO TECNICO SUPERIOR EN ADMINISTRACION ADUANERA Y COMERCIO INTERNACIONAL DEL CENTRO DE DESPACHANTES DE ADUANA DEL PARAGUAY', 'INSTITUTO TECNICO SUPERIOR PZ FLIGTH SA', 'INSTITUTO TECNICO SUPERIOR CENTRO DE ESTUDIOS ESTRATEGICOS', 'INSTITUTO TECNICO SUPERIOR ATENEA', 'INSTITUTO TECNICO SUPERIOR CTELL HUMAN TECH', 'INSTITUTO TECNICO SUPERIOR MERCOSUR ITESUMER', 'INSTITUTO TECNICO SUPERIOR FUNAM', 'INSTITUTO TECNICO SUPERIOR KATUPYRY', 'INSTITUTO TECNICO SUPERIOR ESCUELA DE MATERIAL BELICO CAP NAV ING NAVAL Y AERONAUTICO JOSE ALFREDO BOZZANO BAGLIETTO EMABEL', 'INSTITUTO TECNICO SUPERIOR ORGANIZACION ESPECIALIZADA EN CAPACITACION', 'INSTITUTO TECNICO SUPERIOR FINISHING SCHOOL', 'INSTITUTO TECNICO SUPERIOR PROFESOR FRANCISCO GAONA PROFAGA', 'INSTITUTO TECNICO SUPERIOR GAUSSKISH', 'CONSERVATORIO NACIONAL DE MUSICA', 'INSTITUTO TECNICO SUPERIOR ACOMEPA CFP', 'INSTITUTO TECNICO SUPERIOR SAN FRANCISCO SOLANO', 'INSTITUTO TECNICO SUPERIOR MARIA AUXILIADORA CAPIATA', 'INSTITUTO TECNICO SUPERIOR CENTRO DE FORMACION DE TECNICO SUPERIOR FORESTAL ALTO PARANA', 'INSTITUTO TECNICO SUPERIOR SIGMA', 'INSTITUTO TECNICO SUPERIOR TEKOKATU', 'INSTITUTO TECNICO SUPERIOR BALCARCE', 'CENTRO DE EDUCACION DIRECCION ORIENTACION Y CULTURA', 'INSTITUTO TECNICO SUPERIOR LIFE EDUCATIONAL CENTER', 'INSTITUTO TECNICO SUPERIOR SANTA MARIA DEL ROSARIO', 'INSTITUTO TECNICO SUPERIOR DE FORMACION E INVESTIGACION DE LA SECRETARIA NACIONAL ANTIDROGAS SENAD'}\n"
     ]
    }
   ],
   "source": [
    "# Valores únicos en 'titulos_cre'\n",
    "instituciones_titulos = set(titulos_its['institucion'].unique())\n",
    "\n",
    "# Valores únicos en 'carreras_cre'\n",
    "instituciones_carreras = set(carreras_its['institucion'].unique())\n",
    "\n",
    "# Instituciones que están en 'titulos_cre' pero no en 'carreras_cre'\n",
    "solo_en_titulos = instituciones_titulos - instituciones_carreras\n",
    "print(\"Instituciones que están solo en titulos_its:\")\n",
    "print(solo_en_titulos)\n",
    "\n",
    "# Instituciones que están en 'carreras_cre' pero no en 'titulos_cre'\n",
    "solo_en_carreras = instituciones_carreras - instituciones_titulos\n",
    "print(\"\\nInstituciones que están solo en carreras_its:\")\n",
    "print(solo_en_carreras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580d012-f9de-4975-a5b8-a64341afb13a",
   "metadata": {},
   "source": [
    "# verificar valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "a5a61765-ba16-4e0c-888a-27ae1aee6830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en titulos_its:\n",
      "anio                 0\n",
      "mes                  0\n",
      "documento            0\n",
      "persona_id           0\n",
      "nombre_completo      0\n",
      "tipo_institucion     0\n",
      "institucion          0\n",
      "carrera              0\n",
      "titulo               0\n",
      "sexo                70\n",
      "dtype: int64\n",
      "\n",
      "Valores nulos en carreras_its:\n",
      "tipo_institucion                 0\n",
      "institucion                      0\n",
      "carrera                          0\n",
      "titulo                           0\n",
      "tipo_gestion                    20\n",
      "nivel_titulacion                 0\n",
      "clasificacion_campo_amplio    2611\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar valores nulos en cada columna de titulos_cre\n",
    "print(\"Valores nulos en titulos_its:\")\n",
    "print(titulos_its.isnull().sum())\n",
    "\n",
    "# Contar valores nulos en cada columna de carreras_cre\n",
    "print(\"\\nValores nulos en carreras_its:\")\n",
    "print(carreras_its.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c6a207-f0cd-4657-89a3-4e46d3033083",
   "metadata": {},
   "source": [
    "# campo amplio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "7f81c2c5-be17-4fb9-bda5-1fe01bc44e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación para datos de validación:\n",
      "                                                     precision    recall  f1-score   support\n",
      "\n",
      "               ADMINISTRACION DE EMPRESAS Y DERECHO       1.00      0.96      0.98       112\n",
      "       AGRICULTURA SILVICULTURA PESCA Y VETERINARIA       1.00      1.00      1.00        12\n",
      "                                ARTES Y HUMANIDADES       1.00      0.77      0.87        26\n",
      "       CIENCIAS NATURALES MATEMATICAS Y ESTADISTICA       0.00      0.00      0.00         1\n",
      "         CIENCIAS SOCIALES PERIODISMO E INFORMACION       1.00      0.68      0.81        25\n",
      "                                          EDUCACION       0.94      1.00      0.97      2022\n",
      "                                         EDUCACION*       0.84      0.40      0.54       146\n",
      "                INGENIERIA INDUSTRIA Y CONSTRUCCION       1.00      0.97      0.99        39\n",
      "              PROGRAMAS Y CERTIFICACIONES GENERICOS       1.00      1.00      1.00         2\n",
      "                                  SALUD Y BIENESTAR       0.99      0.99      0.99       478\n",
      "                                 SALUD Y BIENESTAR*       0.00      0.00      0.00         6\n",
      "                                          SERVICIOS       0.97      0.97      0.97        78\n",
      "                                         SERVICIOS*       0.00      0.00      0.00         1\n",
      "TECNOLOGIAS DE LA INFORMACION Y LA COMUNICACION TIC       1.00      0.73      0.85        30\n",
      "\n",
      "                                           accuracy                           0.95      2978\n",
      "                                          macro avg       0.77      0.68      0.71      2978\n",
      "                                       weighted avg       0.95      0.95      0.95      2978\n",
      "\n",
      "Total de valores vacíos por columna después de la predicción:\n",
      "tipo_institucion               0\n",
      "institucion                    0\n",
      "carrera                        0\n",
      "titulo                         0\n",
      "tipo_gestion                  20\n",
      "nivel_titulacion               0\n",
      "clasificacion_campo_amplio     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Concatenar los dataframes\n",
    "df_combined = pd.concat([carreras_is, carreras_ifd, carreras_cre, carreras_its], ignore_index=True)\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio no esté vacío para entrenamiento\n",
    "df_train = df_combined.dropna(subset=['clasificacion_campo_amplio'])\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio esté vacío para predicción\n",
    "df_predict = df_combined[df_combined['clasificacion_campo_amplio'].isna()]\n",
    "\n",
    "# Vectorización de la columna 'carrera' utilizando TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_train['carrera'])\n",
    "X_predict = vectorizer.transform(df_predict['carrera'])\n",
    "\n",
    "# Definir el target\n",
    "y_train = df_train['clasificacion_campo_amplio']\n",
    "\n",
    "# División de los datos de entrenamiento para validación\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Validar el modelo\n",
    "y_val_pred = model.predict(X_val_split)\n",
    "print(\"Reporte de clasificación para datos de validación:\")\n",
    "print(classification_report(y_val_split, y_val_pred, zero_division=0))\n",
    "\n",
    "# Predecir los valores faltantes en df_merged_IS y añadir el asterisco\n",
    "def predecir_y_marcar(row, model, vectorizer):\n",
    "    if pd.isna(row['clasificacion_campo_amplio']):\n",
    "        prediccion = model.predict(vectorizer.transform([row['carrera']]))[0]\n",
    "        return f\"{prediccion}*\"\n",
    "    else:\n",
    "        return row['clasificacion_campo_amplio']\n",
    "\n",
    "carreras_its['clasificacion_campo_amplio'] = carreras_its.apply(\n",
    "    lambda row: predecir_y_marcar(row, model, vectorizer),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Exportar el dataframe resultante a Excel\n",
    "carreras_its.to_excel('carreras_its_actualizado.xlsx', index=False)\n",
    "\n",
    "# Conteo de valores vacíos por columna después de la predicción\n",
    "valores_vacios_post_prediccion = carreras_its.isna().sum()\n",
    "print(\"Total de valores vacíos por columna después de la predicción:\")\n",
    "print(valores_vacios_post_prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9f2a0-2413-4641-bd3e-44e0de2efafb",
   "metadata": {},
   "source": [
    "# tipo gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "65b5923a-ec2f-476c-9895-7cee2159e9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gimen\\AppData\\Local\\Temp\\ipykernel_1904\\1695378727.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  carreras_its = carreras_its.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contar el tipo de gestión más frecuente para cada institución\n",
    "def completar_tipo_gestion(grupo):\n",
    "    if grupo['tipo_gestion'].isnull().all():\n",
    "        return grupo\n",
    "    # Obtener el tipo de gestión más frecuente (eliminando los nulos) \n",
    "    tipo_frecuente = grupo['tipo_gestion'].dropna().mode()[0]\n",
    "    # Rellenar los valores nulos con el tipo de gestión más frecuente\n",
    "    grupo['tipo_gestion'] = grupo['tipo_gestion'].fillna(tipo_frecuente)\n",
    "    return grupo\n",
    "\n",
    "# Aplicar la función a cada grupo de instituciones sin convertirlo en índice\n",
    "carreras_its = carreras_its.groupby('institucion', as_index=False).apply(completar_tipo_gestion)\n",
    "\n",
    "# Guardar el resultado en un archivo Excel\n",
    "carreras_its.to_excel('carreras_its_actualizado.xlsx', index=False)\n",
    "\n",
    "# Verificar si aún hay valores nulos en la columna 'tipo_gestion'\n",
    "print(carreras_is['tipo_gestion'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d85e6a-ffeb-4798-a4f2-faeae01ce00a",
   "metadata": {},
   "source": [
    "# VERIFICACION DE INCONSISTENCIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "c5772c9d-9439-44e6-8ebb-fcebc69526ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas left_only: 11492\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_its_copy = titulos_its.copy()\n",
    "carreras_its_copy = carreras_its.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_its_copy = titulos_its_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_its_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_its_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_ITS.xlsx', index=False)\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b8b464-ea9f-46f6-bb84-959cc7be113a",
   "metadata": {},
   "source": [
    "# LIMPIEZA DE INCONSISTENCIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "e4bb385e-802b-4e6c-8de7-a2a2aa8e3f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: 'unificacion_left_only_its.xlsx'\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "# Función para extraer la parte posterior a 'AREA'\n",
    "def extract_after_area(text):\n",
    "    if 'AREA' in text:\n",
    "        return text.split('AREA', 1)[-1].strip()  # Extraer lo que sigue después de 'AREA'\n",
    "    return None  # Si no tiene 'AREA', devolver None\n",
    "\n",
    "# Función para verificar palabras clave\n",
    "def check_keywords(text1, text2):\n",
    "    keywords = ['CIENCIAS BASICAS', 'CIENCIAS SOCIALES', 'FISIOTERAPIA', 'KINESIOLOGIA', 'PSICOLOGIA', 'EDUCACION FISICA']\n",
    "    for keyword in keywords:\n",
    "        if keyword in text1 and keyword not in text2:\n",
    "            return True\n",
    "        if keyword in text2 and keyword not in text1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Función de coincidencia difusa optimizada\n",
    "def fuzzy_unify(row, carreras_its, threshold=75):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    carreras_its_filtered = carreras_its[\n",
    "        (carreras_its['institucion_carrera'] == row['institucion']) &\n",
    "        (carreras_its['tipo_institucion'] == row['tipo_institucion'])\n",
    "    ]\n",
    "\n",
    "    row['carrera_carreras'] = None\n",
    "    row['titulo_carrera'] = None\n",
    "    row['institucion_carrera'] = None\n",
    "\n",
    "    for _, carrera_row in carreras_its_filtered.iterrows():\n",
    "        # Extraer partes después de 'AREA'\n",
    "        area_row_1 = extract_after_area(row['carrera'])\n",
    "        area_row_2 = extract_after_area(carrera_row['carrera_carreras'])\n",
    "\n",
    "        if area_row_1 and area_row_2:  # Ambas tienen 'AREA'\n",
    "            area_score = fuzz.ratio(area_row_1, area_row_2)\n",
    "            if area_score < 70:  # Si la parte después de 'AREA' no es similar\n",
    "                avg_score = 60  # Asignar un puntaje bajo\n",
    "            else:\n",
    "                carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "                titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "                avg_score = (carrera_score + titulo_score) / 2\n",
    "        elif area_row_1 or area_row_2:  # Solo una de las partes tiene 'AREA'\n",
    "            avg_score = 60  # Puntaje bajo\n",
    "        else:\n",
    "            carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "            titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "            avg_score = (carrera_score + titulo_score) / 2\n",
    "\n",
    "        # Verificar palabras clave\n",
    "        if check_keywords(row['carrera'], carrera_row['carrera_carreras']):\n",
    "            avg_score *= 0.5  # Reducir el puntaje a la mitad si hay un desajuste en las palabras clave\n",
    "\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_match = carrera_row\n",
    "\n",
    "    if best_score >= threshold and best_match is not None:\n",
    "        row['carrera_unificada'] = best_match['carrera_carreras']\n",
    "        row['titulo_unificado'] = best_match['titulo_carrera']\n",
    "        row['institucion_unificada'] = best_match['institucion_carrera']\n",
    "        row['carrera_carreras'] = best_match['carrera_carreras']\n",
    "        row['titulo_carrera'] = best_match['titulo_carrera']\n",
    "        row['institucion_carrera'] = best_match['institucion_carrera']\n",
    "    else:\n",
    "        row['carrera_unificada'] = row['carrera']\n",
    "        row['titulo_unificada'] = row['titulo_titulos']\n",
    "        row['institucion_unificada'] = row['institucion']\n",
    "\n",
    "    row['similarity_score'] = best_score\n",
    "    return row\n",
    "\n",
    "# Aplicar la coincidencia difusa\n",
    "left_only_unified = left_only.apply(fuzzy_unify, args=(carreras_its_copy,), axis=1)\n",
    "\n",
    "# Seleccionar las columnas en el orden deseado\n",
    "left_only_unified = left_only_unified[[\n",
    "    'carrera',\n",
    "    'carrera_carreras',\n",
    "    'carrera_unificada', \n",
    "    'titulo_titulos',\n",
    "    'titulo_carrera',\n",
    "    'titulo_unificado',\n",
    "    'institucion', \n",
    "    'institucion_carrera',\n",
    "    'institucion_unificada',\n",
    "    'similarity_score'\n",
    "]]\n",
    "\n",
    "# Exportar a un archivo Excel con el nombre modificado\n",
    "left_only_unified.to_excel('unificacion_left_only_its.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'unificacion_left_only_its.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c264e5a-d87a-49cc-9b3d-17eac990a986",
   "metadata": {},
   "source": [
    "# reemplazar campos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "11717518-c335-4d47-bee1-8c71a9bad3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: 'titulos_its_actualizado.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Filtrar las filas de left_only_unified con un puntaje mayor o igual a 90\n",
    "left_only_unified_filtered = left_only_unified[left_only_unified['similarity_score'] >= 100]\n",
    "\n",
    "# Paso 2: Reemplazar los valores en titulos_cre\n",
    "for _, row in left_only_unified_filtered.iterrows():\n",
    "    # Buscar coincidencias en titulos_cre\n",
    "    condition = (\n",
    "        (titulos_its['carrera'] == row['carrera']) &\n",
    "        (titulos_its['titulo'] == row['titulo_titulos']) &\n",
    "        (titulos_its['institucion'] == row['institucion'])\n",
    "    )\n",
    "    \n",
    "    # Reemplazar los valores en titulos_cre si hay coincidencias\n",
    "    titulos_its.loc[condition, 'carrera'] = row['carrera_unificada']\n",
    "    titulos_its.loc[condition, 'titulo'] = row['titulo_unificado']\n",
    "\n",
    "# Puedes guardar el DataFrame actualizado en un archivo Excel o CSV si lo deseas\n",
    "titulos_its.to_excel('titulos_its_actualizado.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'titulos_its_actualizado.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e9101-252a-4d4a-bea5-ec9e5c8d8972",
   "metadata": {},
   "source": [
    "# Segunda verificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "a07aa592-f78e-4b44-a47e-1c14ed7eaad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas left_only: 10963\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_its_copy = titulos_its.copy()\n",
    "carreras_its_copy = carreras_its.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_its_copy = titulos_its_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_its_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_its_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_ITS.xlsx', index=False)\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_its_copy = carreras_its_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcfa42d-c4cc-4073-af48-25d68374f3f8",
   "metadata": {},
   "source": [
    "# Union final ITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "7dd6d34b-2e4f-4391-8900-cd7cc20eaee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame TITULOS V2: (32722, 10)\n",
      "Shape del DataFrame final: (32722, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Eliminar duplicados en las columnas clave de carreras\n",
    "df_merged_unique = carreras_its.drop_duplicates(\n",
    "    subset=['carrera', 'institucion', 'tipo_institucion', 'titulo']\n",
    ")\n",
    "\n",
    "# Paso 2: Realizar el merge con las combinaciones únicas\n",
    "merged_final_ITS = pd.merge(\n",
    "    titulos_its, \n",
    "    df_merged_unique, \n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    how='left'  # Aquí cambiamos a 'left' para mantener todas las filas de df_titulos_v2_limpio_CRE\n",
    ")\n",
    "\n",
    "# Paso 2: Guardar el DataFrame en un archivo Excel\n",
    "merged_final_ITS.to_excel('ITS_FINAL.xlsx', index=False)\n",
    "# Imprimir la forma y los encabezados de df_titulos_v2_limpio_CRE\n",
    "print(\"Shape del DataFrame TITULOS V2:\", titulos_its.shape)\n",
    "\n",
    "\n",
    "# Imprimir la forma y los encabezados del DataFrame final\n",
    "print(\"Shape del DataFrame final:\", merged_final_ITS.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fdc29-0a0a-47ba-a6da-841ff258b366",
   "metadata": {},
   "source": [
    "# UNIVERSIDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "98f9cf66-91b7-445e-86c2-fa00cd166469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcciones realizadas en titulos_u:\n",
      "['UNIVERSIDAD AUTONOMA DE ASUNCION' 'UNIVERSIDAD POLITECNICA Y ARTISTICA'\n",
      " 'UNIVERSIDAD CATOLICA NUESTRA SENORA DE LA ASUNCION'\n",
      " 'UNIVERSIDAD DEL SOL'\n",
      " 'UNIVERSIDAD TECNICA DE COMERCIALIZACION Y DESARROLLO'\n",
      " 'UNIVERSIDAD AUTONOMA SAN SEBASTIAN' 'UNIVERSIDAD CENTRAL DEL PARAGUAY'\n",
      " 'UNIVERSIDAD AMERICANA' 'UNIVERSIDAD SUDAMERICANA'\n",
      " 'UNIVERSIDAD DEL NORTE' 'UNIVERSIDAD INTERNACIONAL TRES FRONTERAS'\n",
      " 'UNIVERSIDAD MARIA AUXILIADORA' 'UNIVERSIDAD DE DESARROLLO SUSTENTABLE'\n",
      " 'UNIVERSIDAD SAN LORENZO' 'UNIVERSIDAD SANTA CLARA DE ASIS'\n",
      " 'UNIVERSIDAD TECNOLOGICA INTERCONTINENTAL' 'UNIVERSIDAD NIHON GAKKO'\n",
      " 'UNIVERSIDAD MARIA SERRANA' 'UNIVERSIDAD PRIVADA DEL ESTE'\n",
      " 'UNIVERSIDAD DEL PACIFICO' 'UNIVERSIDAD INTERAMERICANA'\n",
      " 'UNIVERSIDAD NACIONAL DEL ESTE' 'UNIVERSIDAD METROPOLITANA DE ASUNCION'\n",
      " 'UNIVERSIDAD COLUMBIA DEL PARAGUAY' 'UNIVERSIDAD SAN CARLOS'\n",
      " 'UNIVERSIDAD DE INTEGRACION DE LAS AMERICAS'\n",
      " 'UNIVERSIDAD LEONARDO DA VINCI' 'UNIVERSIDAD GRAN ASUNCION'\n",
      " 'UNIVERSIDAD IBEROAMERICANA' 'UNIVERSIDAD NACIONAL DE CONCEPCION'\n",
      " 'UNIVERSIDAD AUTONOMA DEL PARAGUAY' 'UNIVERSIDAD AUTONOMA DEL SUR'\n",
      " 'UNIVERSIDAD NACIONAL DE ASUNCION' 'UNIVERSIDAD PRIVADA DEL GUAIRA'\n",
      " 'UNIVERSIDAD HISPANOGUARANI PARA EL DESARROLLO HUMANO'\n",
      " 'UNIVERSIDAD DEL CONO SUR DE LAS AMERICAS' 'UNIVERSIDAD COMUNERA'\n",
      " 'UNIVERSIDAD NACIONAL DE PILAR'\n",
      " 'UNIVERSIDAD NACIONAL DE VILLARRICA DEL ESPIRITU SANTO'\n",
      " 'UNIVERSIDAD AUTONOMA DE LUQUE' 'UNIVERSIDAD AUTONOMA DE ENCARNACION'\n",
      " 'UNIVERSIDAD SAN IGNACIO DE LOYOLA' 'UNIVERSIDAD NACIONAL DE CAAGUAZU'\n",
      " 'UNIVERSIDAD NACIONAL DE ITAPUA' 'UNIVERSIDAD LA PAZ'\n",
      " 'CENTRO EDUCATIVO SUPERIOR EN SALUD' 'UNIVERSIDAD NORDESTE DEL PARAGUAY'\n",
      " 'UNIVERSIDAD DEL CHACO' 'UNIVERSIDAD ADVENTISTA DEL PARAGUAY'\n",
      " 'UNIVERSIDAD NACIONAL DE CANINDEYU' 'UNIVERSIDAD ESPANOLA'\n",
      " 'UNIVERSIDAD PARAGUAYOALEMANA DE CIENCIAS APLICADAS'\n",
      " 'UNIVERSIDAD POLITECNICA TAIWAN PARAGUAY']\n",
      "\n",
      "Correcciones realizadas en carreras_u:\n",
      "['UNIVERSIDAD DEL SOL' 'UNIVERSIDAD NACIONAL DE ASUNCION'\n",
      " 'UNIVERSIDAD CATOLICA NUESTRA SENORA DE LA ASUNCION'\n",
      " 'UNIVERSIDAD AUTONOMA DEL SUR' 'UNIVERSIDAD LEONARDO DA VINCI'\n",
      " 'UNIVERSIDAD TECNOLOGICA INTERCONTINENTAL'\n",
      " 'UNIVERSIDAD SAN IGNACIO DE LOYOLA'\n",
      " 'UNIVERSIDAD DEL CONO SUR DE LAS AMERICAS' 'UNIVERSIDAD DEL NORTE'\n",
      " 'UNIVERSIDAD PRIVADA DEL GUAIRA' 'UNIVERSIDAD NACIONAL DE CONCEPCION'\n",
      " 'UNIVERSIDAD INTERNACIONAL TRES FRONTERAS' 'UNIVERSIDAD SAN LORENZO'\n",
      " 'UNIVERSIDAD POLITECNICA Y ARTISTICA' 'UNIVERSIDAD NACIONAL DEL ESTE'\n",
      " 'UNIVERSIDAD NIHON GAKKO' 'UNIVERSIDAD NACIONAL DE PILAR'\n",
      " 'UNIVERSIDAD IBEROAMERICANA' 'UNIVERSIDAD EVANGELICA DEL PARAGUAY'\n",
      " 'UNIVERSIDAD LA PAZ' 'UNIVERSIDAD DE INTEGRACION DE LAS AMERICAS'\n",
      " 'UNIVERSIDAD AUTONOMA DEL PARAGUAY' 'UNIVERSIDAD AUTONOMA DE ENCARNACION'\n",
      " 'UNIVERSIDAD SAN CARLOS' 'UNIVERSIDAD AUTONOMA SAN SEBASTIAN'\n",
      " 'UNIVERSIDAD PRIVADA DEL ESTE' 'UNIVERSIDAD INTERAMERICANA'\n",
      " 'UNIVERSIDAD DE DESARROLLO SUSTENTABLE'\n",
      " 'UNIVERSIDAD AUTONOMA DE ASUNCION'\n",
      " 'UNIVERSIDAD TECNICA DE COMERCIALIZACION Y DESARROLLO'\n",
      " 'UNIVERSIDAD AMERICANA'\n",
      " 'UNIVERSIDAD CATOLICA NUESTRA SENORA DE LA ASUNCION CAMPUS UNIVERSITARIO ALTO PARANA'\n",
      " 'UNIVERSIDAD DEL PACIFICO' 'UNIVERSIDAD CENTRO MEDICO BAUTISTA'\n",
      " 'UNIVERSIDAD NACIONAL DE ITAPUA' 'UNIVERSIDAD COLUMBIA DEL PARAGUAY'\n",
      " 'UNIVERSIDAD DEL CHACO' 'UNIVERSIDAD ADVENTISTA DEL PARAGUAY'\n",
      " 'UNIVERSIDAD COMUNERA' 'UNIVERSIDAD METROPOLITANA DE ASUNCION'\n",
      " 'UNIVERSIDAD HISPANOGUARANI PARA EL DESARROLLO HUMANO'\n",
      " 'UNIVERSIDAD NACIONAL DE VILLARRICA DEL ESPIRITU SANTO'\n",
      " 'UNIVERSIDAD NACIONAL DE CAAGUAZU' 'UNIVERSIDAD CENTRAL DEL PARAGUAY'\n",
      " 'UNIVERSIDAD NORDESTE DEL PARAGUAY' 'UNIVERSIDAD NACIONAL DE CANINDEYU'\n",
      " 'UNIVERSIDAD GRAN ASUNCION' 'UNIVERSIDAD MARIA AUXILIADORA'\n",
      " 'UNIVERSIDAD NACIONAL DE ASUNCION FACULTAD DE CIENCIAS MEDICAS'\n",
      " 'UNIVERSIDAD SUDAMERICANA' 'UNIVERSIDAD JESUITA DEL PARAGUAY'\n",
      " 'UNIVERSIDAD POLITECNICA TAIWAN PARAGUAY' 'UNIVERSIDAD MARIA SERRANA'\n",
      " 'UNIVERSIDAD PARAGUAYOALEMANA DE CIENCIAS APLICADAS'\n",
      " 'UNIVERSIDAD SUPERIOR HERNANDO ARIAS DE SAAVEDRA'\n",
      " 'UNIVERSIDAD AUTONOMA DE LUQUE' 'UNIVERSIDAD ESPANOLA'\n",
      " 'UNIVERSIDAD SANTA CLARA DE ASIS']\n"
     ]
    }
   ],
   "source": [
    "print(\"Correcciones realizadas en titulos_u:\")\n",
    "print(titulos_u['institucion'].unique())  # Imprime los valores únicos para ver las correcciones\n",
    "\n",
    "print(\"\\nCorrecciones realizadas en carreras_u:\")\n",
    "print(carreras_u['institucion'].unique())  # Imprime los valores únicos para ver las correcciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdd9bf-9384-4906-9e10-6fca2c8b9d4b",
   "metadata": {},
   "source": [
    "# INSTITUTOS QUE ESTAN EN UN SOLO LUGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "08518a0a-6b33-4e75-83ff-7494f0751473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instituciones que están solo en titulos_u:\n",
      "{'CENTRO EDUCATIVO SUPERIOR EN SALUD'}\n",
      "\n",
      "Instituciones que están solo en carreras_u:\n",
      "{'UNIVERSIDAD CENTRO MEDICO BAUTISTA', 'UNIVERSIDAD NACIONAL DE ASUNCION FACULTAD DE CIENCIAS MEDICAS', 'UNIVERSIDAD SUPERIOR HERNANDO ARIAS DE SAAVEDRA', 'UNIVERSIDAD JESUITA DEL PARAGUAY', 'UNIVERSIDAD EVANGELICA DEL PARAGUAY', 'UNIVERSIDAD CATOLICA NUESTRA SENORA DE LA ASUNCION CAMPUS UNIVERSITARIO ALTO PARANA'}\n"
     ]
    }
   ],
   "source": [
    "# Valores únicos en 'titulos_cre'\n",
    "instituciones_titulos = set(titulos_u['institucion'].unique())\n",
    "\n",
    "# Valores únicos en 'carreras_cre'\n",
    "instituciones_carreras = set(carreras_u['institucion'].unique())\n",
    "\n",
    "# Instituciones que están en 'titulos_cre' pero no en 'carreras_cre'\n",
    "solo_en_titulos = instituciones_titulos - instituciones_carreras\n",
    "print(\"Instituciones que están solo en titulos_u:\")\n",
    "print(solo_en_titulos)\n",
    "\n",
    "# Instituciones que están en 'carreras_cre' pero no en 'titulos_cre'\n",
    "solo_en_carreras = instituciones_carreras - instituciones_titulos\n",
    "print(\"\\nInstituciones que están solo en carreras_u:\")\n",
    "print(solo_en_carreras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0502071-3432-40c1-a617-a826ca9064d1",
   "metadata": {},
   "source": [
    "# campo amplio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "745e2e62-1267-4eff-b2a7-cb15f34b2393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación para datos de validación:\n",
      "                                                      precision    recall  f1-score   support\n",
      "\n",
      "                ADMINISTRACION DE EMPRESAS Y DERECHO       0.90      0.96      0.93       574\n",
      "               ADMINISTRACION DE EMPRESAS Y DERECHO*       0.80      0.48      0.60        81\n",
      "        AGRICULTURA SILVICULTURA PESCA Y VETERINARIA       0.98      0.88      0.93        58\n",
      "                                 ARTES Y HUMANIDADES       0.98      0.83      0.90        54\n",
      "                                ARTES Y HUMANIDADES*       1.00      0.67      0.80         3\n",
      "        CIENCIAS NATURALES MATEMATICAS Y ESTADISTICA       0.97      0.74      0.84        38\n",
      "          CIENCIAS SOCIALES PERIODISMO E INFORMACION       0.94      0.86      0.90        72\n",
      "         CIENCIAS SOCIALES PERIODISMO E INFORMACION*       0.00      0.00      0.00         1\n",
      "                                           EDUCACION       0.95      0.99      0.97      2345\n",
      "                                          EDUCACION*       0.86      0.74      0.80       437\n",
      "                                         EDUCACION**       0.91      0.64      0.75        33\n",
      "                 INGENIERIA INDUSTRIA Y CONSTRUCCION       0.97      0.95      0.96       118\n",
      "                INGENIERIA INDUSTRIA Y CONSTRUCCION*       1.00      0.97      0.98        29\n",
      "               PROGRAMAS Y CERTIFICACIONES GENERICOS       0.86      0.67      0.75         9\n",
      "              PROGRAMAS Y CERTIFICACIONES GENERICOS*       0.00      0.00      0.00         1\n",
      "                                   SALUD Y BIENESTAR       0.97      0.98      0.98       895\n",
      "                                  SALUD Y BIENESTAR*       1.00      0.58      0.74        12\n",
      "                                           SERVICIOS       1.00      0.94      0.97        80\n",
      "                                          SERVICIOS*       0.97      0.97      0.97        37\n",
      " TECNOLOGIAS DE LA INFORMACION Y LA COMUNICACION TIC       0.89      0.99      0.94        68\n",
      "TECNOLOGIAS DE LA INFORMACION Y LA COMUNICACION TIC*       1.00      0.90      0.95        10\n",
      "\n",
      "                                            accuracy                           0.94      4955\n",
      "                                           macro avg       0.85      0.75      0.79      4955\n",
      "                                        weighted avg       0.94      0.94      0.94      4955\n",
      "\n",
      "Total de valores vacíos por columna después de la predicción:\n",
      "tipo_institucion              0\n",
      "institucion                   0\n",
      "carrera                       0\n",
      "titulo                        0\n",
      "tipo_gestion                  0\n",
      "nivel_titulacion              0\n",
      "clasificacion_campo_amplio    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Concatenar los dataframes\n",
    "df_combined = pd.concat([carreras_is, carreras_ifd, carreras_cre, carreras_its, carreras_u], ignore_index=True)\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio no esté vacío para entrenamiento\n",
    "df_train = df_combined.dropna(subset=['clasificacion_campo_amplio'])\n",
    "\n",
    "# Filtrar filas donde clasificacion_campo_amplio esté vacío para predicción\n",
    "df_predict = df_combined[df_combined['clasificacion_campo_amplio'].isna()]\n",
    "\n",
    "# Vectorización de la columna 'carrera' utilizando TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_train['carrera'])\n",
    "X_predict = vectorizer.transform(df_predict['carrera'])\n",
    "\n",
    "# Definir el target\n",
    "y_train = df_train['clasificacion_campo_amplio']\n",
    "\n",
    "# División de los datos de entrenamiento para validación\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Validar el modelo\n",
    "y_val_pred = model.predict(X_val_split)\n",
    "print(\"Reporte de clasificación para datos de validación:\")\n",
    "print(classification_report(y_val_split, y_val_pred, zero_division=0))\n",
    "\n",
    "# Predecir los valores faltantes en df_merged_IS y añadir el asterisco\n",
    "def predecir_y_marcar(row, model, vectorizer):\n",
    "    if pd.isna(row['clasificacion_campo_amplio']):\n",
    "        prediccion = model.predict(vectorizer.transform([row['carrera']]))[0]\n",
    "        return f\"{prediccion}*\"\n",
    "    else:\n",
    "        return row['clasificacion_campo_amplio']\n",
    "\n",
    "carreras_u['clasificacion_campo_amplio'] = carreras_u.apply(\n",
    "    lambda row: predecir_y_marcar(row, model, vectorizer),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Exportar el dataframe resultante a Excel\n",
    "carreras_u.to_excel('carreras_u_actualizado.xlsx', index=False)\n",
    "\n",
    "# Conteo de valores vacíos por columna después de la predicción\n",
    "valores_vacios_post_prediccion = carreras_u.isna().sum()\n",
    "print(\"Total de valores vacíos por columna después de la predicción:\")\n",
    "print(valores_vacios_post_prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8417584-f468-40d4-b4f1-db9845b0ffab",
   "metadata": {},
   "source": [
    "# verificar inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "3ae270e4-95b8-4d80-9c02-e734c3f60a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas left_only: 28493\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_u_copy = titulos_u.copy()\n",
    "carreras_u_copy = carreras_u.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_u_copy = titulos_u_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_u_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_u_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_U.xlsx', index=False)\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452c6d6-5bb4-43c7-b19f-d46c56c0fe09",
   "metadata": {},
   "source": [
    "# Limpieza de inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "0c3adf68-3784-4476-8ed2-8a8afe7ad7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando filas: 100%|██████████| 28493/28493 [10:40<00:00, 44.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: 'unificacion_left_only_u.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from tqdm import tqdm  # Importar tqdm\n",
    "# Lista de palabras clave que quieres analizar\n",
    "\n",
    "keywords = [\n",
    "    'CIENCIAS AMBIENTALES', 'CIENCIAS DE LA COMUNICACION','CIENCIAS DE LA EDUCACION', \n",
    "    'CIENCIAS INFORMATICAS','CIENCIAS ODONTOLOGICAS','CIENCIAS CONTABLES','DIDACTICA SUPERIOR','DIDACTICA UNIVERSITARIA','DOCENCIA UNIVERSITARIA',\n",
    "    'EDUCACION','MATEMATICA','MEDICINA','METODOLOGIA','PSICOLOGIA','ODONTOLOGIA','RELACIONES PUBLICAS',\n",
    "    'ADMINISTRACION', 'INGENIERIA', 'GESTION', 'CIENCIAS', 'TECNOLOGIA',\n",
    "    'DIDACTICA', 'ENFASIS', 'MENCION','CIRUGIA','GERENCIA'\n",
    "]\n",
    "\n",
    "# Función para extraer la parte anterior y posterior a cualquier palabra clave\n",
    "def extract_around_keywords(text, keywords):\n",
    "    text_upper = text.upper()  # Convertir a mayúsculas para comparación\n",
    "    for keyword in keywords:\n",
    "        if keyword in text_upper:\n",
    "            # Dividir el texto en la parte anterior y posterior a la palabra clave\n",
    "            before, after = text_upper.split(keyword, 1)\n",
    "            return before.strip(), after.strip()  # Devolver ambas partes\n",
    "    return None, None  # Si no se encuentra ninguna palabra clave, devolver None para ambas partes\n",
    "\n",
    "# Función para verificar palabras clave\n",
    "def check_keywords(text1, text2):\n",
    "    keywords2 = ['CIENCIAS SOCIALES', 'CIENCIAS NATURALES', 'CIENCIAS BASICAS', 'CIENCIAS DE LA EDUCACION','DIDACTICA UNIVERSITARIA',\n",
    "                 'MARKETING Y PUBLICIDAD','FARMACIA','QUIMICA','ODONTOLOGIA','NEUMOLOGIA','GINECOLOGIA',\n",
    "                  'SOCIAL', 'AGROPECUARIA', 'AGROPECUARIAS','ENFASIS', 'PROFUNDIZADO', 'RECONSTRUCTIVA',\n",
    "                  'FISIOTERAPIA', 'KINESIOLOGIA', 'PSICOLOGIA', 'EDUCACION FISICA','DERECHO','METODOLOGIA']\n",
    "    \n",
    "    for keyword in keywords2:\n",
    "        if keyword in text1 and keyword not in text2:\n",
    "            return True\n",
    "        if keyword in text2 and keyword not in text1:\n",
    "            return True\n",
    "    return False\n",
    "# Función de coincidencia difusa optimizada para múltiples palabras clave 75\n",
    "def fuzzy_unify(row, carreras_u, keywords, threshold=85):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    # Filtrar las filas de carreras_u por institución y tipo de institución\n",
    "    carreras_u_filtered = carreras_u[\n",
    "        (carreras_u['institucion_carrera'] == row['institucion']) &\n",
    "        (carreras_u['tipo_institucion'] == row['tipo_institucion'])\n",
    "    ]\n",
    "\n",
    "    # Inicializar las columnas para las coincidencias\n",
    "    row['carrera_carreras'] = None\n",
    "    row['titulo_carrera'] = None\n",
    "    row['institucion_carrera'] = None\n",
    "\n",
    "    for _, carrera_row in carreras_u_filtered.iterrows():\n",
    "        # Extraer partes antes y después de palabras clave\n",
    "        before_row_1, after_row_1 = extract_around_keywords(row['carrera'], keywords)\n",
    "        before_row_2, after_row_2 = extract_around_keywords(carrera_row['carrera_carreras'], keywords)\n",
    "\n",
    "        if before_row_1 is not None and after_row_1 is not None and before_row_2 is not None and after_row_2 is not None:  # Ambas tienen alguna palabra clave\n",
    "            # Comparar tanto la parte antes como después de la palabra clave\n",
    "            before_score = fuzz.ratio(before_row_1, before_row_2)\n",
    "            after_score = fuzz.ratio(after_row_1, after_row_2)\n",
    "            keyword_score = (before_score + after_score) / 2  # Promedio de ambas partes\n",
    "\n",
    "            if keyword_score < 70:  # Si la parte antes o después de la palabra clave no es similar\n",
    "                avg_score = 50  # Asignar un puntaje bajo\n",
    "            else:\n",
    "                carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "                titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "                avg_score = (carrera_score + titulo_score) / 2\n",
    "        elif before_row_1 or before_row_2 or after_row_1 or after_row_2:  # Solo una de las partes tiene la palabra clave\n",
    "            avg_score = 50  # Puntaje bajo\n",
    "        else:\n",
    "            carrera_score = fuzz.partial_ratio(row['carrera'], carrera_row['carrera_carreras'])\n",
    "            titulo_score = fuzz.partial_ratio(row['titulo_titulos'], carrera_row['titulo_carrera'])\n",
    "            avg_score = (carrera_score + titulo_score) / 2\n",
    "\n",
    "        # Verificar palabras clave\n",
    "        if check_keywords(row['carrera'], carrera_row['carrera_carreras']):\n",
    "            avg_score *= 0.5  # Reducir el puntaje a la mitad si hay un desajuste en las palabras clave\n",
    "\n",
    "        # Guardar la mejor coincidencia\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_match = carrera_row\n",
    "\n",
    "    # Si el mejor puntaje es suficiente, asignar la coincidencia\n",
    "    if best_score >= threshold and best_match is not None:\n",
    "        row['carrera_unificada'] = best_match['carrera_carreras']\n",
    "        row['titulo_unificado'] = best_match['titulo_carrera']\n",
    "        row['institucion_unificada'] = best_match['institucion_carrera']\n",
    "        row['carrera_carreras'] = best_match['carrera_carreras']\n",
    "        row['titulo_carrera'] = best_match['titulo_carrera']\n",
    "        row['institucion_carrera'] = best_match['institucion_carrera']\n",
    "    else:\n",
    "        # Si no hay buena coincidencia, mantener los valores originales\n",
    "        row['carrera_unificada'] = row['carrera']\n",
    "        row['titulo_unificada'] = row['titulo_titulos']\n",
    "        row['institucion_unificada'] = row['institucion']\n",
    "\n",
    "    # Asignar el puntaje de similitud\n",
    "    row['similarity_score'] = best_score\n",
    "    return row\n",
    "\n",
    "\n",
    "# Aplicar la coincidencia difusa con las palabras clave en el DataFrame\n",
    "tqdm.pandas(desc=\"Procesando filas\")  # Inicializar tqdm\n",
    "left_only_unified = left_only.progress_apply(fuzzy_unify, args=(carreras_u_copy, keywords), axis=1)\n",
    "\n",
    "\n",
    "# Seleccionar las columnas en el orden deseado para exportar a Excel\n",
    "left_only_unified = left_only_unified[[\n",
    "    'carrera',\n",
    "    'carrera_carreras',\n",
    "    'carrera_unificada', \n",
    "    'titulo_titulos',\n",
    "    'titulo_carrera',\n",
    "    'titulo_unificado',\n",
    "    'institucion', \n",
    "    'institucion_carrera',\n",
    "    'institucion_unificada',\n",
    "    'similarity_score'\n",
    "]]\n",
    "\n",
    "# Exportar a un archivo Excel\n",
    "left_only_unified.to_excel('unificacion_left_only_u.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'unificacion_left_only_u.xlsx'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39e8ad-65d9-414f-a2e7-f07bac88860d",
   "metadata": {},
   "source": [
    "# reemplazando campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "f6de3346-3424-46d2-8705-b342bbfa04bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: 'titulos_u_actualizado.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Filtrar las filas de left_only_unified con un puntaje mayor o igual a 90\n",
    "left_only_unified_filtered = left_only_unified[left_only_unified['similarity_score'] >= 90]\n",
    "\n",
    "# Paso 2: Reemplazar los valores en titulos_cre\n",
    "for _, row in left_only_unified_filtered.iterrows():\n",
    "    # Buscar coincidencias en titulos_cre\n",
    "    condition = (\n",
    "        (titulos_u['carrera'] == row['carrera']) &\n",
    "        (titulos_u['titulo'] == row['titulo_titulos']) &\n",
    "        (titulos_u['institucion'] == row['institucion'])\n",
    "    )\n",
    "    \n",
    "    # Reemplazar los valores en titulos_cre si hay coincidencias\n",
    "    titulos_u.loc[condition, 'carrera'] = row['carrera_unificada']\n",
    "    titulos_u.loc[condition, 'titulo'] = row['titulo_unificado']\n",
    "\n",
    "# Puedes guardar el DataFrame actualizado en un archivo Excel o CSV si lo deseas\n",
    "titulos_u.to_excel('titulos_u_actualizado.xlsx', index=False)\n",
    "print(\"Archivo exportado: 'titulos_u_actualizado.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bce3f1-7b87-4407-b53c-a8a3ca05b81b",
   "metadata": {},
   "source": [
    "# segunda verificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "5bbf92f8-7b1f-4ea8-8c04-2de864d1d200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas left_only: 14056\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear copias de los DataFrames originales\n",
    "titulos_u_copy = titulos_u.copy()\n",
    "carreras_u_copy = carreras_u.copy()\n",
    "\n",
    "# Renombrar la columna 'titulo' en cada copia para diferenciarlas\n",
    "titulos_u_copy = titulos_u_copy.rename(columns={'titulo': 'titulo_titulos'})\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'titulo': 'titulo_carrera'})\n",
    "\n",
    "# Paso 1: Crear un DataFrame combinado que indica de dónde provienen las filas\n",
    "merged_df = pd.merge(\n",
    "    titulos_u_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos']],\n",
    "    carreras_u_copy[['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera']],\n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_titulos'],\n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo_carrera'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Paso 2: Filtrar las filas que están solo en uno de los DataFrames\n",
    "not_matching = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "# Paso 3: Exportar a Excel\n",
    "not_matching.to_excel('valores_no_coincidentes_U.xlsx', index=False)\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'institucion': 'institucion_carrera'})\n",
    "carreras_u_copy = carreras_u_copy.rename(columns={'carrera': 'carrera_carreras'})\n",
    "\n",
    "# Filtrar el DataFrame para obtener solo las filas donde _merge es 'left_only'\n",
    "left_only = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Imprimir el número de filas left_only\n",
    "print(\"Número de filas left_only:\", left_only.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be870a4-e526-4f81-af11-2a144e2d1b40",
   "metadata": {},
   "source": [
    "# Union final U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "7c0919bb-6272-44c4-afb6-bb37f6e9f4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame TITULOS V2: (380393, 10)\n",
      "Shape del DataFrame final: (380393, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Eliminar duplicados en las columnas clave de carreras\n",
    "df_merged_unique = carreras_u.drop_duplicates(\n",
    "    subset=['carrera', 'institucion', 'tipo_institucion', 'titulo']\n",
    ")\n",
    "\n",
    "# Paso 2: Realizar el merge con las combinaciones únicas\n",
    "merged_final_U = pd.merge(\n",
    "    titulos_u, \n",
    "    df_merged_unique, \n",
    "    left_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    right_on=['carrera', 'institucion', 'tipo_institucion', 'titulo'], \n",
    "    how='left'  # Aquí cambiamos a 'left' para mantener todas las filas de df_titulos_v2_limpio_CRE\n",
    ")\n",
    "\n",
    "# Paso 2: Guardar el DataFrame en un archivo Excel\n",
    "merged_final_U.to_excel('U_FINAL.xlsx', index=False)\n",
    "# Imprimir la forma y los encabezados de df_titulos_v2_limpio_CRE\n",
    "print(\"Shape del DataFrame TITULOS V2:\", titulos_u.shape)\n",
    "\n",
    "\n",
    "# Imprimir la forma y los encabezados del DataFrame final\n",
    "print(\"Shape del DataFrame final:\", merged_final_U.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead3345-c8b9-4bde-b19a-a5e1a46f07ba",
   "metadata": {},
   "source": [
    "# Union final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "aa04d0d3-a70d-4f71-8895-07000ba3cb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exportando a Excel: 100%|██████████| 1/1 [04:20<00:00, 260.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: 'DATASET_FINAL.xlsx'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Supongamos que ya tienes los DataFrames definidos:\n",
    "# merged_final_U, merged_final_CRE, merged_final_IS, merged_final_IFD, merged_final_ITS\n",
    "\n",
    "# Concatenar los DataFrames\n",
    "merged_final_combinado = pd.concat([\n",
    "    merged_final_U,\n",
    "    merged_final_CRE,\n",
    "    merged_final_IS,\n",
    "    merged_final_IFD,\n",
    "    merged_final_ITS\n",
    "], ignore_index=True)\n",
    "\n",
    "# Usar tqdm para mostrar una barra de progreso al exportar a Excel\n",
    "with tqdm(total=1, desc=\"Exportando a Excel\") as pbar:\n",
    "    # Exportar a un archivo Excel\n",
    "    merged_final_combinado.to_excel('DATASET_FINAL.xlsx', index=False)\n",
    "    pbar.update(1)  # Actualizar la barra de progreso\n",
    "\n",
    "print(\"Archivo exportado: 'DATASET_FINAL.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1115db-8d4d-4fef-b619-c4e80f1b4870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "panel-cell-order": [
   "5c3f1771-14f9-4b20-a669-88822641eb6f",
   "2d2db3e8-dc93-4d9e-bf7d-04d7e69c0224",
   "239fdcf2-8cd2-45c3-90ce-a6b28235b1ef",
   "9918ddf7-3925-431d-bc4d-a8d60c80fd90",
   "287f74da-115c-40f8-915c-0923794089ec",
   "86ea1217-bd03-43e9-b06d-93f7fe6aa4db",
   "ebae3ba8-e7c0-42cc-a54c-2f8df7ba47f6",
   "02b154b8-ace2-445c-bbf9-46bee54ff4f8"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
